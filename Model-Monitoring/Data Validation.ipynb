{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIS7i5hkEMM-"
   },
   "source": [
    "# Data Validation for Spark Dataframes with whylogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imgT_wtKEMNB"
   },
   "source": [
    "## About the Dataset - üõèÔ∏è Airbnb Listings in Rio de Janeiro, Brazil\n",
    "\n",
    "We will read data made available from Airbnb. It's a listing dataset from the city of Rio de Janeiro, Brazil. We'll access data that was adapted from the following location: \"http://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2021-01-26/data/listings.csv.gz\"\n",
    "\n",
    "In this example, we want to do some basic data validation. Let's define those:\n",
    "\n",
    "- Completeness Checks\n",
    "    - `id` (long): should not contain any missing values\n",
    "    - `listing_url` (string): should not contain any missing values\n",
    "    - `last_review` (string): should not contain any missing values\n",
    "- Consistency Checks\n",
    "    - `last_review` (string): date should be in the format YYYY-MM-DD\n",
    "    - `listing_url` (string): should be an url from airbnb (starting with https://www.airbnb.com/rooms/)\n",
    "    - `latitude` and `longitude` (double): should be within the range of -24 to -22 and -44 to -43 respectively\n",
    "    - `room_type` (string): frequent strings should be in the set of expected values\n",
    "- Statistics Checks\n",
    "    - `reviews_per_month` (double): standard deviation should be in expected range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7X1jXAaEMNJ",
    "tags": []
   },
   "source": [
    "## Initializing a SparkSession\n",
    "\n",
    "### Execute the cell below and:\n",
    "\n",
    "- Select Add Endpoint\n",
    "- Select Single Sign-On\n",
    "- Select Create Session, selecting language as Python and in properties use \"spark.kubernetes.container.image\": \"gcr.io/mapr-252711/spark-3.4.1:202309170405R\" the whylogs -integerated spark image in properties.\n",
    "- Click Create Session\n",
    "\n",
    "When your session is ready the Manage Sessions pane will become active, providing you the session ID. The session state will become idle which means that you are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6b87b7803340a089c0e8bee54dfa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MagicsControllerWidget(children=(Tab(children=(ManageSessionWidget(children=(HTML(value='<br/>'), HBox(childre‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = \"http://hpeproxy.its.hpecorp.net:443\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://hpeproxy.its.hpecorp.net:443\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "yWhIyVdmEMNJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('whylogs-testing').getOrCreate()\n",
    "arrow_config_key = \"spark.sql.execution.arrow.pyspark.enabled\"\n",
    "spark.conf.set(arrow_config_key, \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HF1aa0iOEMNK"
   },
   "source": [
    "## Creating the PySpark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "dKxGJ8elEMNL",
    "outputId": "3ec26cae-8035-42ed-ba96-52e8aea74508"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "spark_dataframe = spark.read.format('parquet').load(\"file:///mounts/shared-volume/shared/airbnb_listings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Nw0DbogyEMNM",
    "outputId": "d8779448-4d53-4d63-b218-7f01eac1ed84"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------\n",
      " name                   | Very Nice 2Br in ... \n",
      " description            | Discounts for lon... \n",
      " listing_url            | https://www.airbn... \n",
      " last_review            | 2020-12-26           \n",
      " number_of_reviews_ltm  | 13                   \n",
      " number_of_reviews_l30d | 0                    \n",
      " id                     | 17878                \n",
      " latitude               | -22.96592            \n",
      " longitude              | -43.17896            \n",
      " availability_365       | 286                  \n",
      " bedrooms               | 2.0                  \n",
      " bathrooms              | null                 \n",
      " reviews_per_month      | 2.01                 \n",
      " room_type              | Entire home/apt      \n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "spark_dataframe.show(n=1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "_409gnFJEMNM",
    "outputId": "aa2d912e-5c1e-4700-9338-a9b5f78b577f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- listing_url: string (nullable = true)\n",
      " |-- last_review: string (nullable = true)\n",
      " |-- number_of_reviews_ltm: long (nullable = true)\n",
      " |-- number_of_reviews_l30d: long (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- availability_365: long (nullable = true)\n",
      " |-- bedrooms: double (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- reviews_per_month: double (nullable = true)\n",
      " |-- room_type: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "spark_dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb4PrnKXEMNN"
   },
   "source": [
    "## Creating the Condition Count Metrics\n",
    "\n",
    "To create a profile with the standard metrics, we can simply call `collect_dataset_profile_view` from whylog's PySpark extra module. However, if we look at our defined set of constraints, there are two of those that need to checked agains individual values:\n",
    "\n",
    "- `last_review` (string): date should be in the format YYYY-MM-DD\n",
    "- `listing_url` (string): should be an url from airbnb (starting with https://www.airbnb.com/rooms/)\n",
    "\n",
    "As opposed to the other constraints, that can be checked against aggregate metrics, these two need to be checked against individual values. For that, we will create two condition count metrics. Later on, we will create metric constraints based on these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Q4O5WpVPEMNN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "from whylogs.core.relations import Predicate\n",
    "from typing import Any\n",
    "from whylogs.core.metrics.condition_count_metric import Condition\n",
    "from whylogs.core.schema import DeclarativeSchema\n",
    "from whylogs.core.resolvers import STANDARD_RESOLVER\n",
    "from whylogs.core.specialized_resolvers import ConditionCountMetricSpec\n",
    "\n",
    "def date_format(x: Any) -> bool:\n",
    "    date_format = '%Y-%m-%d'\n",
    "    try:\n",
    "        datetime.datetime.strptime(x, date_format)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "last_review_conditions = {\"is_date_format\": Condition(Predicate().is_(date_format))}\n",
    "listing_url_conditions = {\"url_matches_airbnb_domain\": Condition(Predicate().matches(\"^https:\\/\\/www.airbnb.com\\/rooms\"))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfcBc7wOEMNN"
   },
   "source": [
    "Now that we have the our set of conditions for both columns, we can create the condition count metrics. We can do so by creating a Standard Schema and then extending it by adding the condition count metrics with `add_condition_count_metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "C9P8TBx6EMNN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema = DeclarativeSchema(STANDARD_RESOLVER)\n",
    "\n",
    "schema.add_resolver_spec(column_name=\"last_review\", metrics=[ConditionCountMetricSpec(last_review_conditions)])\n",
    "schema.add_resolver_spec(column_name=\"listing_url\", metrics=[ConditionCountMetricSpec(listing_url_conditions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElWEdtq0EMNO"
   },
   "source": [
    "## Profiling the PySpark DataFrame\n",
    "\n",
    "Now, we can use the schema to pass to our logger through `collect_dataset_profile_view`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "qRm46DHWEMNO",
    "outputId": "539700f3-73e8-44d1-a577-ad01769f5f28"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from whylogs.api.pyspark.experimental import collect_dataset_profile_view\n",
    "\n",
    "dataset_profile_view = collect_dataset_profile_view(input_df=spark_dataframe, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UctByqZ2EMNP"
   },
   "source": [
    "This will create a profile with the standard metrics, as well as the two condition count metrics that we created. As a sanity check, let's see the metrics for the `last_review` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "t369rIm8EMNP",
    "outputId": "3197f9b7-bf8e-48c3-fe4f-696fa514652c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['types', 'cardinality', 'counts', 'distribution', 'frequent_items', 'condition_count']"
     ]
    }
   ],
   "source": [
    "dataset_profile_view.get_column(\"last_review\").get_metric_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3kjXR7zEMNQ",
    "tags": []
   },
   "source": [
    "## Creating and Visualizing Metric Constraints\n",
    "\n",
    "We have all that we need to build our set of constraints. We will use out-of-the-box factory constraints to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "tHOLuyXNEMNQ",
    "outputId": "796d08f1-9784-4d93-9efc-e5be4e916809"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ReportResult(name='last_review meets condition is_date_format', passed=1, failed=0, summary=None), ReportResult(name='last_review has no missing values', passed=0, failed=1, summary=None), ReportResult(name='listing_url meets condition url_matches_airbnb_domain', passed=1, failed=0, summary=None), ReportResult(name='listing_url has no missing values', passed=1, failed=0, summary=None), ReportResult(name='latitude is in range [-24,-22]', passed=1, failed=0, summary=None), ReportResult(name='longitude is in range [-44,-43]', passed=1, failed=0, summary=None), ReportResult(name='id has no missing values', passed=1, failed=0, summary=None), ReportResult(name='reviews_per_month standard deviation between 0.8 and 1.1 (inclusive)', passed=1, failed=0, summary=None), ReportResult(name=\"room_type values in set {'Hotel room', 'Entire home/apt', 'Shared room', 'Private room'}\", passed=1, failed=0, summary=None)]"
     ]
    }
   ],
   "source": [
    "from whylogs.core.constraints.factories import condition_meets\n",
    "from whylogs.core.constraints import ConstraintsBuilder\n",
    "from whylogs.core.constraints.factories import no_missing_values\n",
    "from whylogs.core.constraints.factories import is_in_range\n",
    "from whylogs.core.constraints.factories import stddev_between_range\n",
    "from whylogs.core.constraints.factories import frequent_strings_in_reference_set\n",
    "\n",
    "builder = ConstraintsBuilder(dataset_profile_view=dataset_profile_view)\n",
    "reference_set = {\"Entire home/apt\", \"Private room\", \"Shared room\", \"Hotel room\"}\n",
    "\n",
    "builder.add_constraint(condition_meets(column_name=\"last_review\", condition_name=\"is_date_format\"))\n",
    "builder.add_constraint(condition_meets(column_name=\"listing_url\", condition_name=\"url_matches_airbnb_domain\"))\n",
    "builder.add_constraint(no_missing_values(column_name=\"last_review\"))\n",
    "builder.add_constraint(no_missing_values(column_name=\"listing_url\"))\n",
    "builder.add_constraint(is_in_range(column_name=\"latitude\",lower=-24,upper=-22))\n",
    "builder.add_constraint(is_in_range(column_name=\"longitude\",lower=-44,upper=-43))\n",
    "builder.add_constraint(no_missing_values(column_name=\"id\"))\n",
    "builder.add_constraint(stddev_between_range(column_name=\"reviews_per_month\", lower=0.8, upper=1.1))\n",
    "builder.add_constraint(frequent_strings_in_reference_set(column_name=\"room_type\", reference_set=reference_set))\n",
    "\n",
    "constraints = builder.build()\n",
    "constraints.generate_constraints_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1qxKc90EMNR"
   },
   "source": [
    "Now, we can visualize the constraints report using the __Notebook Profile Visualizer__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "6rnfh4wBEMNR",
    "outputId": "413add67-9400-44df-b7b2-7c5b6fddc0b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>"
     ]
    }
   ],
   "source": [
    "from whylogs.viz import NotebookProfileVisualizer\n",
    "visualization = NotebookProfileVisualizer()\n",
    "visualization.constraints_report(constraints, cell_height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgqO76WeEMNR"
   },
   "source": [
    "Looks like we have some missing values for `last_review`. Other than that, the data looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "'module' object is not callable\n",
      "Traceback (most recent call last):\n",
      "TypeError: 'module' object is not callable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd() \n",
    "visualization.set_profiles(target_profile_view=dataset_profile_view)\n",
    "visualization.write( rendered_html=visualization.profile_summary(), html_file_name=\"/mounts/shared-volume/shared/data_validation\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can now load the html from the EZAU platform."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
