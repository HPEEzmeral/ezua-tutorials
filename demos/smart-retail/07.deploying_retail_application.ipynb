{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23297498-83e8-459b-a96f-70d9258d66c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/logo.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32190ff-5766-48f0-9b3c-debaee8eabd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Exercise 7:** Deploying Custom Applications on HPE Ezmeral Unified Analytics \n",
    "\n",
    "In the final exercise of this series, you will import and deploy a custom retail application on **HPE Ezmeral Unified Analytics**. \n",
    "\n",
    "This application will use your webcam to scan items as if you were at the checkout, detecting produce in the image using the model you created and served!\n",
    "\n",
    "In this exercise, you will learn how to:\n",
    "\n",
    "- Import applications and frameworks into Unified Analytics.\n",
    "- predict objects!\n",
    "\n",
    "By the end of this exercise, you will have deployed an application that demonstrates what a next-generation retail experience could look like. \n",
    "\n",
    "Following this, you will have completed the Smart Retail Experience technical demonstration. \n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4de5d3-103b-499f-b1cb-4e66d3fb1671",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Important:</b> This exercise requires the completion of Exercises 6: Serving your Model with KServe <b>and</b> a running Kubeflow Endpoint of your model!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d4cfd-c046-447e-912a-b366be25b0d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **1. Importing Applications into HPE Ezmeral Unified Analytics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abbbd7-a290-4e9c-9991-13e90296ec08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing the Smart Retail Experience application\n",
    "\n",
    "1. Navigate back to the Unified Analytics dashboard.\n",
    "1. In the sidebar navigation menu, select `Tools & Frameworks`.\n",
    "1. Click `Import New Framework`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae793d-a180-401a-993c-6004edf7316c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/exercise7/frameworks.png\" alt=\"Drawing\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5f725-0f69-4623-ba6f-80d22a803f91",
   "metadata": {
    "tags": []
   },
   "source": [
    "4. Under **Framework Details**, you will see the following:\n",
    "- **Framework Name**: This will be the name of your application/framework that will appear in the `Tools and Frameworks` page. It is case sensitive. Default for this demonstraton: `Smart Retail Experience`.\n",
    "- **Version**: The version of your application/framework that will appear in the `Tools and Frameworks` page. Best practice is to set it to the same version as the imported software. Default for this demonstration: `1.0.2`.\n",
    "- **Description***: A general description of your application/framework that will appear as you write it here in the `Tools and Frameworks` page. Describe the function of the software (not 'MATLAB' as depicted above!). Write your own description for the Smart Retail Experience.\n",
    "- **Category***: Applications/frameworks in HPE Ezmeral Unified Analytics fall under one of three categories: *Data Engineering*, *Analytics* and *Data Science*. Applications/frameworks under these categories are sorted into tabs in `Tools and Frameworks` page. For this demonstration, select `Data Science`.\n",
    "\n",
    "5. Upload the `icon.png` located under the **images** folder of this demonstration directory to the **Framework Icon**.\n",
    "6. Click `Framework Chart` to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60966e45-f2b8-4756-913e-0c6389afde75",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/exercise7/details.png\" alt=\"Drawing\" style=\"width: 40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a26be1-efee-4fd3-9922-3b65b97a583b",
   "metadata": {
    "tags": []
   },
   "source": [
    "7. Under **Helm Chart** is where previously uploaded Helm charts stored by HPE Ezmeral Unified Analytics can be selected. As we are going to upload a new Helm Chart, leave the option as `Upload New Chart`\n",
    "8. Upload the `retail-experience.tgz` located under the **retail_application** folder of this demonstration directory into the  **Upload Helm Package tar.gz file** field. The Framework Chart window will now look like this.\n",
    "\n",
    "The **Namespace** field will dictate under what Kubernetes namespace your application will exist. The application **must** be in the same namespace as your Kubeflow Endpoints, which will exist in the namespace that is your Unified Analytics **username**. If you are unsure, navigate back to the Unified Analytics dashboard - you will see your **username** in the top-right corner.\n",
    "\n",
    "9. Enter **your Unified Analytics username** into the **Namespace** field.\n",
    "10. Click `Framework Values` to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd9f3e-7e31-4ddf-84be-8b17ccacc1ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/exercise7/chart2.png\" alt=\"Drawing\" style=\"width: 40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47812859-aa76-4c9e-a251-2a9bb96fdb62",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the **Framework Values** page, you will find a preview of the Helm Values YAML (values.yaml). For a Helm chart to be uploaded to Unified Analytics, it must contain an `ezua` field which you can find below. This field will declare to the application where to find Unified Analytics security credentials for itself.\n",
    "\n",
    "No changes are required to the YAML for this demonstration.\n",
    "\n",
    "11. Click `Review` to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80054a-1769-4716-aa60-7a7cae5e59b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/exercise7/values.png\" alt=\"Drawing\" style=\"width: 40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f633c80-35a6-426e-912d-179fcaa14fcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "12. In the **Review** window, click `Submit`.\n",
    "\n",
    "With that, you have successfully uploaded **your own application to Unified Analytics!**\n",
    "\n",
    "Navigate to the `Data Science` tab to view your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888f221-1b0d-4537-a801-d25d133207c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/exercise7/imported.png\" alt=\"Drawing\" style=\"width: 30%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50486e7c-818d-4ca7-a207-55cafd886719",
   "metadata": {
    "tags": []
   },
   "source": [
    "**It will take several minutes to initialize even after the status changes to** `Ready`. **Please wait up to 5 minutes.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb61556-3a31-4a94-8b44-2b40b7750e87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **2. Smart Retail Experience**\n",
    "\n",
    "You are now ready to run the Smart Retail Experience application - leveraging \n",
    "\n",
    "To learn more about building Docker and Helm applications and creating your own Smart Retail Experience from scratch, keep an eye out on the **HPE Ezmeral GitHub repository** for the latest tutorials, demos and feature showcases!\n",
    "\n",
    "### Remember EzPresto?\n",
    "\n",
    "It now seems like so long ago, but recall the delta tables you turned into a Data Source in Unified Analytics using Apache Hive in [Exercises 1](./01.exploring_data_with_spark.ipynb) and [2](./02.query_with_ezpreso.ipynb). Instead of having to manually load prices into our self-serve checkout application, which will differ from store to store, would it not be best to **pull from a centeralized table to always have the latest prices**? \n",
    "\n",
    "Like in [Exercise 3](./03.visualizing_data_superset), where we pulled data into Apache Superset, we can once again leverage **EzPresto** to query our datasets that we create from our connected Data Sources - no matter where that data came from or happens to reside! \n",
    "\n",
    "\n",
    "The Smart Retail Experience application uses EzPresto to query the delta tables we connected through Hive. If you recall, we had **three** sales data tables - one each for our German, Swiss and Czech stores. \n",
    "\n",
    "Given the variance in pricing and currency, in order to test our Smart Retail Experience, you can **select which country you wish to get sales data for** from inside the Smart Retail Experience Application. \n",
    "\n",
    "Whenever an item is scanned, both the image frame and the selected `country` are parsed to the backend of the application. The frame will be sent to the model endpoint, where a prediction of what item is in the image will be returned. If a confidence threshold is met, that prediction (e.g. *orange*) is parsed as the `product` variable along with the `country` variable into an SQL query. This query is then made using EzPresto to our Cached Asset tables to get the last price of that item from that given country. \n",
    "\n",
    "```python\n",
    "\n",
    "table_name = f'retail.default.{country}\"\n",
    "\n",
    "PRICE = f\"SELECT unitprice FROM {table_name} WHERE PRODUCT = '{product}' LIMIT 1\"\n",
    "```\n",
    "\n",
    "The prediction and retrieved price are then parsed back to the application, where the item is added to the cart!\n",
    "\n",
    "**Note:** Given that no single in-store self-serve checkout will be needing to start a cart in two countries, when the country is changed in the application **the shopping cart will reset**. \n",
    "\n",
    "\n",
    "### Using the application\n",
    "\n",
    "Before you get started, grab some items to scan! The only items that will be detected by the application are those that were trained on in [Exercise 4](./04.model_training.ipynb). \n",
    "\n",
    "For the `Quick` dataset, detected items will be:\n",
    "\n",
    "- Apples\n",
    "- Bananas\n",
    "- Carrots\n",
    "- Cucumbers\n",
    "- Lemons\n",
    "- Oranges\n",
    "\n",
    "1. Click `Open` on your application. This will open the application in a new browser tab.\n",
    "2. A browser pop-up should appear to allow for your access to your webcam.\n",
    "\n",
    "Take a moment to play with the application. Most of the below steps you will explore on your own.\n",
    "\n",
    "3. Place or hold an item from the list above in front of your webcam.\n",
    "4. Click `Scan Item`. The image will now be processed.\n",
    "5. The detected item will retrieve its price from the Presto database of the currently selected country. \n",
    "6. Switch the Scanning Mode to `Auto`.\n",
    "7. When prompted by the status indicator, hold an item from the list above in front of your webcam.\n",
    "\n",
    "\n",
    "### Detection Considerations\n",
    "\n",
    "The detection threshold for any object is set to **80%**. That is, unless the model's predicted value for any given object is at least 80%, it will not add it to your cart.\n",
    "\n",
    "With respect to the model's performance, please keep in mind that your model is **very lightweight** and was trained on a **small set of data**. It may make the occasional error. \n",
    "\n",
    "### Scanning\n",
    "\n",
    "For demonstration purposes, there are two scanning modes in this applicaton: **Manual** and **Auto**\n",
    "\n",
    "**Manual**: Click the \"Scan Item\" button with an item present in the image. The frame will be captured on button press and sent to the model for detection. Whilst you *can* scan another item whilst the status indicator reads *Processing...*, it is best to wait until the status indicator reads *Ready to scan item.* before scanning your next item. \n",
    "\n",
    "**Auto**: In Auto mode, the status indicator will indicate when to place your item. The status will change to *Scanning...* when there is two seconds left before capture. This image will then be processed. The timing indicator bar is used to visually indicate the cycle between the Scanning and Processing states - each 7 seconds. This is more analogous to a self-serve checkout solution, where a customer will continually scan items and as one item is being processed, they are getting the next item from their basket or trolley."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c1338-ab92-478c-89b4-a66ad821c71e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Conclusion**\n",
    "\n",
    "Throughout the course of this technical demonstration, you have taken raw data from CSVs, created datasets you can easily query from anywhere, visualized those datasets in a C-suite ready dashboard, taken image data and created a product recognition model, served that model at scale to an endpoint, and deployed an application that leverages both the datasets and the served model to be used by thousands of customers... **all within a single platform!**\n",
    "\n",
    "This technical demonstration has showcased the power of **HPE Ezmeral Unified Analytics** - the end-to-end data engieering, analytics, machine learning and AI platform that can be deployed on-premises or in your favorite public cloud vendor. \n",
    "\n",
    "Let's not forget, this demonstration has also showcased the power of... **you!** Leveraging Unified Analytics, you have performed every step of the machine learning development cycle - from data to model building. Be proud! \n",
    "\n",
    "From all of us at HPE, thank you for completing the **Smart Retail Experience** technical demonstration. We hope you had fun! \n",
    "\n",
    "Be sure to check out the other technical demonstrations and product tutorials in the **HPE Ezmeral GitHub Repository!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b16d3-1382-4f11-8e2b-1ea60a42c151",
   "metadata": {
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5777f1f-6986-4d78-969c-a2d22e2776c2",
   "metadata": {
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf79d18-5355-4eba-9ba4-1769aa5f0cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Written and prepared by Alex Ollman, Product Manager, HPE Ezmeral Software.\n",
    "\n",
    "Technical demonstration developed by Dirk Derichsweiler, Isabelle Steinhauser and Vincent Charbonnier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d831c2-28f3-465f-941b-6333913a6e89",
   "metadata": {
    "tags": []
   },
   "source": [
    "© Copyright 2024 Hewlett Packard Enterprise "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
