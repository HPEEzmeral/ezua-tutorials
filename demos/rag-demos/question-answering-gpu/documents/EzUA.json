[
    {
        "content": "\nGet Started Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . The following sections provide links to topics for administrators and members to get started\n      with HPE Ezmeral Unified Analytics Software . Administrators Administrators may be interested in the following topics: Installation AD/LDAP Servers Identity and Access Management Adding and Removing Users Importing Applications and Managing the Application Lifecycle Connecting to External HPE Ezmeral Data Fabric Clusters Configuring Endpoints Members Members (non-administrative users) may be interested in the following topics: Tutorials Data Engineering Data Analytics Data Science Notebooks About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. On this page Administrators Members Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/GetStarted/get-started.html",
        "title": "Get Started"
    },
    {
        "content": "\nAbout Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. About Provides an overview of HPE Ezmeral Unified Analytics Software . HPE Ezmeral Unified Analytics Software is usage-based\n      Software-as-a-Service (SaaS) that fully manages, supports, and maintains hybrid and\n      multi-cloud modern analytical workloads through open-source tools. HPE Ezmeral Unified Analytics Software separates compute and\n      storage for flexible, cost-efficient scalability to securely access data stored in multiple\n      data platforms through a simple user interface, which is easily installed and deployed on\n      private, public, and on-premises infrastructure. Features and Functionality HPE Ezmeral Unified Analytics Software provides the\n        following features and functionality in a single UX: Access data anywhere and manage it in one place Connect bidirectionally to multiple data platforms and join data to create a\n              federated data mesh that you manage in one place. Includes authentication,\n              authorization, logging, metrics collection, and monitoring. Robust, integrated storage layer Includes an integrated, scalable data fabric storage layer with data-mesh like\n              capabilities as the ephemeral storage for all types of data, including structured and\n              unstructured data, files, objects, and streams. Analytical workloads Support for the most common enterprise analytics use cases ranging from traditional\n              BI/Reporting (via PrestoDB and SparkSQL interfaces) to emerging workloads, such as\n              exploratory data science, real-time analytics, and machine learning workflows. Self-service data access All users, including administrators, data engineers, data analysts, and data\n              scientists can directly access data from HPE Ezmeral Unified Analytics Software . Built-in access to BI dashboards and data science tools Includes built-in BI dashboards for analytics and operational reporting, Also\n              includes web-based notebook interfaces, such as Jupyter Lab and Visual Studio, for\n              data science workflows (model training and serving frameworks). Built-in SSO Supports single sign-on experience; users sign in to access HPE Ezmeral Unified Analytics Software and compute\n              components integrate with the storage platform infrastructure to pass the identity of\n              each user. Performance Distributed, in-memory caching ( explicit) that accelerates\n              federated queries on commonly used datasets. Compute Components The compute components included in HPE Ezmeral Unified Analytics Software enable users to get up and running in minutes. Components\n        connect to each other at start-up and use pre-defined storage areas in the built-in data\n        fabric. When applicable, compute components can automatically take advantage of GPUs. The following list describes the compute components included in HPE Ezmeral Unified Analytics Software : Spark Spark is a primary engine for data analytics tasks. EzPresto EzPresto is a distributed SQL query\n              engine with a built-in query federation capability (distributed in-memory caching and\n              pushdown optimizations) for fast analytic queries on data of any size. Kubeflow Kubeflow as an ML framework focused on model training that includes Notebooks,\n              Pipelines (Airflow), Experiments, Kserve, and various distributed training\n              operators. Airflow Airflow for data engineering and task automation. Notebooks Jupyter notebooks for performing varied data science tasks, such as cleaning data,\n              labeling features, testing toy models, and launching distributed training models. Dashboard Frameworks Dashboard frameworks for building data models and visualizations. Workflows and Pipelines HPE Ezmeral Unified Analytics Software provides\n        simplified workflows and pipelines for data engineers, data analysts, and data scientists to\n        solve complex problems. The following image shows some of the supported workflows and pipelines: On this page Features and Functionality Compute Components Workflows and Pipelines Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/About/overview_and_features.html",
        "title": "About"
    },
    {
        "content": "\nTutorials Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included\n    applications, such as tutorials for data science and data analytics workflows with notebooks and\n    applications like Spark, MLflow, Feast, Airflow, and EzPresto. The following sections describe the tutorials and provide links to access the\n      complete tutorials in GitHub. Fraud Detection Use Case Overview In this tutorial, data scientists and machine learning engineers inspect fraudulent\n                transactions using the Bankism dataset. This synthetically created dataset is a\n                combination of various customer payments, made at different intervals and in varying\n                amounts. This tutorial covers everything from data processing, through model development, to\n                the final stage of model deployment. By the end of this tutorial, you will learn how to detect and curtail fraudulent\n                activities with high accuracy. Tools This tutorial uses the following components from HPE Ezmeral Unified Analytics Software : Kale to enable the transformation of a Jupyter Notebook into a Kubeflow\n                    Pipeline. Kubeflow Pipelines to scale the training and deployment process in a\n                    reproducible way. MinIO to store the training artifacts. KServe as a fully trained machine learning model. GitHub Link To complete this tutorial, follow the instructions outlined in the fraud detection tutorial . Question-Answering Use Case Overview In this tutorial, data engineers explore the deployment of LLMs (Large Language\n                Models) to write the code that serves the model, processes the user requests, and\n                packages everything in a custom Docker. This tutorial utilizes an open-source Large Language Model (LLM) that can answer\n                questions over a corpus of private documentation. To achieve this, the tutorial\n                employs a Vector Store that captures and indexes a latent representation for each\n                document. This allows the application to retrieve the relevant context based on the\n                user's questions, enabling accurate and efficient question answering. Tools This tutorial uses the following components from HPE Ezmeral Unified Analytics Software : KServe to serve the fully trained machine learning model. GitHub Link To complete this tutorial, follow the instructions outlined in the question-answering tutorial . Wind Turbine Use Case Overview In this tutorial, data scientists and data engineers use Spark to explore the\n                training dataset and train a Gradient-Boosted Tree (GBT) regressor. GBT regressor\n                estimates the power output of a wind turbine by utilizing various features, such as\n                wind speed and direction. Tools This tutorial uses the following components from HPE Ezmeral Unified Analytics Software : Apache Spark to process large-scale data and train machine learning models in\n                    a distributed manner. Apache Livy to enable easy interaction with a Spark cluster over a REST\n                    interface. GitHub Link To complete this tutorial, follow the instructions outlined in the wind turbine tutorial . Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . On this page Fraud Detection Use Case Question-Answering Use Case Wind Turbine Use Case Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/Tutorials.html",
        "title": "Tutorials"
    },
    {
        "content": "\nPreparing the Tutorial Environment Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits\n    Recognition tutorials. Prerequisites: Sign in as an administrator to prepare the environment for the\n      Financial Time Series and MNIST Digits Recognition tutorials. Create an S3 Object Store Bucket and Load Data The Spark application reads raw data from the S3 Object Store. Use MinIO to create an S3 bucket named ezaf-demo and put the following\n        files in the ezaf-demo bucket, as described: Create data/mnist directory in the ezaf-demo bucket,\n            and upload the following dataset to the mnist folder: https://github.com/HPEEzmeral/ezua-tutorials/tree/main/Data-Science/Kubeflow/MNIST-Digits-Recognition/dataset Create a data folder in the ezaf-demo bucket, and\n            the following data set to the data folder: https://github.com/HPEEzmeral/ezua-tutorials/tree/main/Data-Science/Kubeflow/Financial-Time-Series/dataset Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/pepare-tutorial-env.html",
        "title": "Preparing the Tutorial Environment"
    },
    {
        "content": "\nData Source Connectivity and Exploration Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . You can connect to data sources and work with data within the Data Engineering space of HPE Ezmeral Unified Analytics Software . The Data\n      Engineering space includes: Data Sources \u2013 View and access connected data sources; create new data source\n          connections. Data Catalog \u2013 Select data sets (tables and views) from one or more data sources\n          and query data across the data sets. You can cache data sets. Caching stores the data in a\n          distributed caching layer within the data fabric for accelerated access to the data. Query Editor \u2013 Run queries against selected data sets; create views and new\n          schemas. Cached Assets \u2013 Lists the cached data sets (tables and views). Airflow Pipelines \u2013 Links to the Airflow interface where you can connect to data\n          sets created in HPE Ezmeral Unified Analytics Software and use them in your data pipelines. Tutorial Objective Although you can perform more complex tasks in HPE Ezmeral Unified Analytics Software , the purpose of this tutorial is to walk you through\n        some Data Engineering basics and familiarize you with the interface, including how to: Connect data sources Select predefined data sets in data sources Join data across data sets/data sources Create a voew Run a query against the view This tutorial takes approximately 10 minutes to complete. You may want to print the following instructions or open the instructions on a different\n        monitor to avoid switching between HPE Ezmeral Unified Analytics Software and the tutorial on one monitor. IMPORTANT This tutorial\n          demonstrates how to perform a series of tasks in HPE Ezmeral Unified Analytics Software to complete an example workflow. The data and\n          information used in this tutorial is for example purposes only. You must connect Unified Analytics to your own data sources and use\n          the data sets available to you in your data sources. A \u2013 Sign in to HPE Ezmeral Unified Analytics Software Sign in to HPE Ezmeral Unified Analytics Software with the URL provided by your administrator. B \u2013 Connect Data Sources Connect HPE Ezmeral Unified Analytics Software to\n        external data sources that contain the data sets (tables and views) you want to work with.\n        This tutorial uses MySQL and Snowflake as the connected data sources. To connect a data source: In the left navigation column, select Data Engineering > Data\n              Sources . The Data Sources screen appears. Click Add New Data Source . Complete the steps required to connect to the MySQL, Snowflake, and Hive data sources: Connecting to MySQL In the Add New Data Source screen, click Create\n                        Connection in the MySQL tile. In the drawer that opens, enter required information in the respective\n                        fields: NOTE The information used here is for example purposes\n                        only. Name : mysql Connection URL : jdbc:mysql://<ip-address>:<port> Connection User : demouser Connection Password : moi123 Enable Local Snapshot Table : Select the check box TIP When Enable Local Snapshot Table is selected, the system caches remote\n                            table data to accelerate queries on the tables. The cache is active for\n                            the duration of the configured TTL or until the remote tables in the\n                            data source are altered. Click Connect . Upon successful connection, the system returns the\n                          following\n                          message: Successfully added data source \"mysql\". Connecting to Snowflake In the Add New Data Source screen, click Create\n                        Connection in the Snowflake tile. In the drawer that opens, enter the following information in the respective\n                        fields: Name : snowflake_ret Connection URL : jdbc:snowflake://mydomain.com/ Connection User : demouser Connection Password : moi123 Snowflake DB : my_snowflake_db Enable Local Snapshot Table : Select the check box TIP When Enable Local Snapshot Table is selected, the system caches remote\n                            table data to accelerate queries on the tables. The cache is active for\n                            the duration of the configured TTL or until the remote tables in the\n                            data source are altered. Click Connect . Upon successful connection, the system returns the\n                          following\n                          message: Successfully added data source \"snowflake_ret\". Connecting to Hive In the Add New Data Source screen, click Create\n                        Connection in the Hive tile. In the drawer that opens, enter the following information in the respective\n                        fields: Name : hiveview Hive Metastore : file Hive Metastore Catalog Dir : file:///data/shared/tmpmetastore In Optional Fields , search for the following fields and add the\n                          specified values: Hive Max Partitions Per Writers : 10000 Hive Temporary Staging Directory Enabled : Unselect Hive Allow Drop Table : Select Enable Local Snapshot Table : Select the check box TIP When Enable Local Snapshot Table is selected, the system caches remote\n                            table data to accelerate queries on the tables. The cache is active for\n                            the duration of the configured TTL or until the remote tables in the\n                            data source are altered. Click Connect . Upon successful connection, the system returns the\n                          following\n                          message: Successfully added data source \"hiveview\". C \u2013 Select Data Sets in the Data Catalog In the Data Catalog, select the data sets (tables and views) in each of the data sources\n        that you want to work with. This tutorial uses the customer tables in the connected mysql and snowflake_ret data sources. In the mysql data source, the schema for the\n        customer table is retailstore . In the snowflake_ret data source, the schema\n        for the customer table is public . To select the data sets that you want to work with: In the left navigation bar, select Data Engineering > Data\n              Catalog . On the Data Catalog page, click the dropdown next to the mysql and snowflake_ret data sources to expose the available schemas in those data\n            sources. For the snowflake_ret data source select the public schema and for the mysql data source, select the retailstore schemas. In the All Datasets search field, enter a search term to limit the number of\n            data sets. This tutorial searches on data sets with the name customer . All the\n            data sets that have customer in the name with public or retailstore schema display. Click a customer table and preview its data in the Columns and Data\n              Preview tabs. NOTE Do not click the browser's back button; doing so takes you to\n              the Data Sources screen and you will have to repeat the previous steps. Click Close to return to the data sets. Click Select by each of the tables named customer . Selected Datasets\n            should show 2 as the number of data sets selected. Click Selected Datasets . The Selected Datasets drawer opens, giving you another\n            opportunity to preview the datasets or discard them. From here, you can either query or\n            cache the selected data sets. For the purpose of this tutorial, we will query the data\n            sets. Click Query Editor . D \u2013 Run a JOIN Query on Data Sets and Create a View The data sets you selected display under Selected Datasets in the Query Editor. Run a JOIN\n        query to join data from the two customer tables and then create a view from the query. The\n        system saves views as cached assets that you can reuse. To view table columns and run a JOIN query: Expand the customer tables in the Selected Datasets section to view the columns\n            in each of the tables. In the SQL Query workspace, click + to add a worksheet. Copy and paste the following query into the SQL Query field. This query creates\n            the a new schema in the hiveview data source named demoschema : create schema if not exists hiveview.demoschema; Click Run to run the query. As the query runs, a green light pulsates next to\n            the Query ID in the Query Results section to indicate that the query is in progress.\n            When the query is completed, the Status column displays Succeeded. In the SQL Query workspace, click + to add a worksheet. Copy and paste the following query into the SQL Query field. This query creates\n            a view (hiveview.demoschema) from a query that joins columns from the two customer tables (in the mysql and snowflake-ret data sources) on the customer\n            ID . create view hiveview.demoschema.customer_info_view as SELECT t1.c_customer_id, t1.c_first_name, t1.c_last_name, t2.c_email_address FROM mysql.retailstore.customer t1 INNER JOIN snowflake_ret.public.customer t2 ON t1.c_customer_id=t2.c_customer_id Click Run to run the query. In the SQL Query workspace, click + to add a worksheet. Copy and paste the following query into the SQL Query field. This runs against\n            the view you created (hiveview.demoschema) and returns all data in the\n            view. SELECT * FROM hiveview.demoschema.customer_info_view; Click Run to run the query. In the Query Results section, expand the Actions option for the query\n            and select Query Details to view the query session and resource utilization\n            summary. Click Close to exit out of Query Details. End of Tutorial You have completed this tutorial. This tutorial demonstrated how easy it is to connect HPE Ezmeral Unified Analytics Software to various\n        data sources for federated access to data through a single interface using standard SQL\n        queries. You may also be interested in the BI Reporting (Superset) Basics , which\n        shows you how to create a Superset dashboard using the view (customer_info_view) and schema\n        (customer_schema) created in this tutorial. On this page Tutorial Objective A \u2013 Sign in to HPE Ezmeral Unified Analytics Software B \u2013 Connect Data Sources C \u2013 Select Data Sets in the Data Catalog D \u2013 Run a JOIN Query on Data Sets and Create a View End of Tutorial Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/data-engineer-basics-tutorial.html",
        "title": "Data Source Connectivity and Exploration"
    },
    {
        "content": "\nBI Reporting (Superset) Basics Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . You can add data sets that you created in HPE Ezmeral Unified Analytics Software to Superset and visualize the data in dashboards. You can access\n      dashboards (Superset) from the BI Reporting space within HPE Ezmeral Unified Analytics Software . Tutorial Objective The purpose of this\n        tutorial is to walk you through some Superset basics to familiarize you with the interface\n        and how to use it with the data sets you create in HPE Ezmeral Unified Analytics, including\n        how to: Add datasets created in HPE Ezmeral Unified Analytics Software to Superset Visualize the data set in a chart Create a dashboard Add the chart to the dashboard This tutorial takes approximately 10 minutes to complete. You may want to\n      print the following instructions or open the instructions on a different monitor to avoid\n      switching between HPE Ezmeral Unified Analytics Software and the tutorial on one monitor. IMPORTANT This tutorial\n        demonstrates how to perform a series of tasks in HPE Ezmeral Unified Analytics Software to complete an example workflow. The data and\n        information used in this tutorial is for example purposes only. You must connect Unified Analytics to your own data sources and use\n        the data sets available to you in your data sources. Prerequisite This tutorial builds on Data Source Connectivity and Exploration . In the Data Source Connectivity and\n      Exploration tutorial, you created a view (customer_info_view) and a schema (customer_schema)\n      from a query that joined customer tables from two different data sources (MySQL and\n      Snowflake). In this tutorial, you import the view and schema into Superset, visualize the data\n      in a chart, and add the chart to a dashboard. A \u2013 Sign in to HPE Ezmeral Unified Analytics Software Sign in to HPE Ezmeral Unified Analytics Software with the URL provided by your administrator. B - Connect to the Presto Database Complete the following steps to connect Superset to the Presto database for access to your\n        data sources and data sets in HPE Ezmeral Unified Analytics Software . Once connected to the Presto database, you can access your\n        data sets in HPE Ezmeral Unified Analytics Software from Superset. To connect to the Presto database, you need the connection URI. You can get the URI from\n        your HPE Ezmeral Unified Analytics Software administrator. To open Superset, in the left navigation pane of HPE Ezmeral Unified Analytics Software , select BI Reporting >\n              Dashboards . Superset opens in a new tab. In Superset, select Settings > Database Connections . Click +DATABASE . In the Connect a database window, select the Presto tile. Enter the SQLALCHEMY URI provided by your administrator. Test the connection. If the test was successful, click Connect . C \u2013 Add a Data Set to a Chart To add a dataset to a chart: Select the Datasets tab. Click + DATASET . In the Add dataset window, make the following selections in the fields: DATABASE: Presto SCHEMA: <your_schema> SEE TABLE SCHEMA: <your_view> Click ADD DATASET AND CREATE CHART . In Choose chart type column, select #Popular and choose Table . Click CREATE NEW CHART . In the chart screen, enter a name for the chart. For example, name the chart Customer Info . Select RAW RECORDS as the QUERY MODE . Drag and drop the following four columns into the COLUMNS field: c_customer_id c_first_name c_last_name c_email_address Click into the Filters field and select or enter the following information in\n            the window that opens: c_first_name Equal to (=) Charles Click SAVE . Click CREATE CHART . The query runs and results that meet the query conditions\n            display. The chart displays four columns of data for customers with the first name\n            Charles. Click SAVE to save the chart. A window opens. Click SAVE in the window.\n            Do not add to a dashboard. Superset saves the chart. D \u2013 Create a Dashboard and Add the Chart To create a dashboard and add the chart you created to the dashboard: In Superset, click the Dashboards tab. Click +DASHBOARD . Enter a name (title) for the dashboard, for example Customer Dashboard . In the right navigation bar, click the LAYOUT ELEMENTS tab. Drag and drop the Header element into the dashboard. In the Header element, enter a title, for example Customers Named\n              Charles . In the right navigation bar, click the CHARTS tab. Locate the chart you created (Customer Info) and drag and drop the chart into the\n            dashboard. You may need to drag the chart over the Header title and drop it there to get\n            it to stay in place. A blue line appears in the dashboard when the chart is in a place\n            it can be dropped. Click SAVE to save the dashboard. End of Tutorial You have completed this tutorial. This tutorial demonstrated the integration of the HPE Ezmeral Unified Analytics Software SQL query\n        engine ( EzPresto ) with Superset to visualize data models that you create in\n        the Data Engineering space using the charting and dashboarding features in Superset. You may also be interested in the Retail Store Analysis Dashboard (Superset) , which\n        shows you how to create a database connection, visualize data, and monitor queries used in\n        visualizations. On this page Tutorial Objective Prerequisite A \u2013 Sign in to HPE Ezmeral Unified Analytics Software B - Connect to the Presto Database C \u2013 Add a Data Set to a Chart D \u2013 Create a Dashboard and Add the Chart End of Tutorial Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/ua-superset-basics-tutorial.html",
        "title": "BI Reporting (Superset) Basics"
    },
    {
        "content": "\nCandy Sharing Tutorial (Kale) Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook\n        annotations. Upload candies_sharing.ipynb if you do not already\n            have the file. Log in to the Kubeflow notebook. Upload candies_sharing.ipynb using the Upload Files button inside the Kubeflow notebook. Open the candies_sharing.ipynb file and enable the Kale\n                    extension. Run all cells in the notebook using Run -> Run All Cells . At the bottom of Kale Deployment Panel , select COMPILE\n                        AND RUN and then click the button. Open the Kubeflow Dashboard from the Runs page and check the\n                    status of the pipeline run launched from the Kubeflow notebook. More information https://github.com/kubeflow-kale/kale Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/candy-sharing-tutorial.html",
        "title": "Candy Sharing Tutorial (Kale)"
    },
    {
        "content": "\nFeast Ride Sharing Use Case Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online\n        model inference for the ride-sharing driver satisfaction model. Prerequisites Sign in to HPE Ezmeral Unified Analytics Software . About this task Use Feast to generate training data and perform online model inference for the\n                ride-sharing driver satisfaction model. In this tutorial, you will: Deploy a local feature store with a Parquet file offline store and SQLite online\n                    store. Build a training dataset using time series features from Parquet files. Read the latest features from the offline store for batch scoring. Ingest batch features (\"materialization\") and streaming features into the online\n                    store. Read the latest features from the online store for real-time inference. Explore the Feast web interface to see Data Sources, Entities, Feature Views,\n                    Feature Services, and Datasets which are defined through feature\n                    definitions. Procedure Connect to the notebook server. See Creating and Managing Notebook Servers . Copy the Feast folder from the /shared directory into the /<username> directory. NOTE If the Feast folder is not available in the /shared directory, perform: Go to GitHub repository for tutorials . Clone the repository. Navigate to ezua-tutorials/Data-Science . Navigate back to the /shared directory. Copy the /Feast folder from the ezua-tutorials/Data-Science repository into\n                                    the /shared directory. Copy the /Feast folder from /shared folder to <username> directory. Validate the ride-sharing-example.ipynb file, definitions.py file, and the data folder\n                    are available in the /<username>/Feast directory. Validate the driver_stats.parquet file is available in the /<username>/Feast directory. Open the definitions.py file and update the path for the driver_stats.parquet file for your username. For\n                        eg: /home/<username>/<username>/feast/data/driver_stats.parquet Open the ride-sharing-example.ipynb file and update the path\n                    for the driver_stats.parquet file for your username. For\n                        eg: /home/<username>/<username>/feast/data/driver_stats.parquet Select the first cell of the notebook and click Run the selected cells and\n                        advance (play icon). Results Click the Tools & Frameworks icon on the left\n                    navigation bar. Navigate to the Feast tile under the Data Science tab and click Open . Explore the Feast web interface to see Data Sources, Entities, Feature Views,\n                    Feature Services, and Datasets that are defined through feature definitions. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/feast-ride-sharing-usecase.html",
        "title": "Feast Ride Sharing Use Case"
    },
    {
        "content": "\nFinancial Time Series Workflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a\n    Jupyter notebook to analyze and visualize data that the Spark application puts into a shared\n    directory in the shared volume that the data scientist\u2019s notebook is mounted to. Scenario NOTE An administrator must prepare the environment for this tutorial to work. See Preparing the Tutorial Environment . A DAG source (located in GitHub) is coded to\n        submit a Spark job that pulls CSV data (financial.csv) from an S3 data\n        source, transforms the data into Parquet format, and puts the data in a shared volume in the financial-processed folder. The following diagram shows the components and applications in the workflow: Steps Sign in to HPE Ezmeral Unified Analytics Software and perform the following steps: Prerequisites Use Airflow to run a DAG that\n            submits a Spark application. View the Spark application that the\n            DAG submitted. Connect to and run\n            the Jupyter notebook to analyze and visualize the data. Prerequisites Connect to your Jupyter notebook and perform setup tasks to prepare the environment to\n            train the model. A <username> folder with a sample notebook file and\n            SSL certificate is provided for the purpose of this tutorial. To connect your notebook\n            and perform setup tasks: In the HPE Ezmeral Unified Analytics Software , go to Applications &\n                Frameworks . Select the Data Science tab and then click Open in the Kubeflow tile. In Kubeflow, click Notebooks to open the notebooks page. Click Connect to connect to your notebook server. Go to the /<username> folder. Copy the template object_store_secret.yaml.tpl file from the shared/ezua-tutorials/Data-Analytics/Spark directory to the <username> folder. In the <username>/Financial-Time-Series folder, open the financial_time_series_example.ipynb file. NOTE If you do not see the Financial-Time-Series folder in the <username> folder, copy the folder from the /shared/ezua-tutorials/Data-Science/Kubeflow directory into the <username> folder. The /shared directory is\n              accessible to all users. Editing or running examples from the /shared directory is not advised. The <username> directory is specific to\n              you and cannot be accessed by other users If the Financial-Time-Series folder is not available in the /shared/ezua-tutorials/Data-Science/Kubeflow directory,\n                perform: Go to GitHub repository for tutorials . Clone the repository. Navigate to ezua-tutorials/Data-Science/Kubeflow . Navigate back to the <username> directory. Copy the Financial-Time-Series folder from the ezua-tutorials/Data-Science/Kubeflow directory into the <username> directory. To generate a secret to read data source files from S3 bucket by Spark application\n            (Airflow DAG), run the first cell of the financial_time_series_example.ipynb file: import kfp\nkfp_client = kfp.Client()\nnamespace = kfp_client.get_user_namespace()\n!sed -e \"s/\\$AUTH_TOKEN/$AUTH_TOKEN/\" /mnt/user/object_store_secret.yaml.tpl > object_store_secret.yaml A - Run a DAG in Airflow In Airflow, run the DAG named spark_read_csv_write_parquet_fts . The DAG\n        runs a Spark application that reads CSV data (financial.csv) from an S3\n        bucket, transforms the data into Parquet format, and writes the transformed Parquet data\n        into the shared volume. Run the DAG Navigate to the Airflow screen using either of the following methods: Click Data Engineering > Airflow Pipelines . Click Tools & Frameworks , select the Data Engineering tab, and click Open in the Airflow tile. In Airflow , verify that you are on the DAGs screen. Click spark_read_csv_write_parquet_fts DAG. NOTE The DAG is pulled from a pre-configured HPE GitHub repository. This DAG is\n                    constructed to submit a Spark application that pulls financial.csv file into Parquet format, and places the\n                    converted files in a shared directory. If you want to use your private GitHub\n                    repository, see Airflow DAGs Git Repository to learn how to configure your\n                    repository. Click Code to view the DAG code. Click Graph to view the graphical representation of the\n                  DAG. Click Run (play button). Upon successful DAG\n                    completion, the data is accessible inside your notebook server in the following\n                    directory for further processing: /<username>/financial-processed\" To view details for the DAG, click Details . Under DAG Details , you can see green, red, and/or yellow\n                  buttons with the number of times the DAG ran successfully or failed. Click the Success button. To find your job, sort by End Date to see the latest jobs that have run,\n                  and then scroll to the right and click the log icon under Log URL for that run.\n                  Note that jobs run with the\n                    configuration: Conf \"username\":\"your_username\" When running Spark applications using Airflow, you can see the\n                    following logs: Reading from s3a://ezaf-demo/data/financial.csv; \nsrc format is csv 22/11/04 11:53:26 WARN \nAmazonHttpClient: SSL Certificate checking for endpoints has been explicitly disabled. \nRead complete Writing to file:///mounts/data/financial-processed; dest format is parquet Write complete IMPORTANT The cluster clears the logs that result from the DAG runs.\n                      The duration after which the cluster clears the logs depends on the Airflow\n                      task, cluster configuration, and policy. B \u2013 View the Spark Application Once you have triggered the DAG, you can view the Spark application in the Spark\n          Applications screen. To view the Spark application, go to Analytics > Spark\n        Applications . Alternatively, you can go to Applications & Frameworks and then\n        click on the Analytics tab. On the Analytics tab, select the Spark tile and click Open . C \u2013 Run the Jupyter\n        Notebook Run the Jupyter notebook file to analyze and visualize the financial time\n        series data. To run the notebook: Connect to the notebook server. See Creating and Managing Notebook Servers . In the Notebooks screen, navigate to the <username>/financial-processed/ folder to validate that the data processed by the\n          Spark application is available. In the <username>/financial-processed/ folder, open\n          the financial_time_series_example.ipynb file. In the sixth cell of the financial_time_series_example.ipynb file, update the user folder name\n            as follows: user_mounted_dir_name = \"user\" In the Notebook Launcher, select the second cell of the notebook\n          and click Run the selected cells and advance (play icon). After the packages install, restart the notebook kernel. To restart the kernel, click\n          the Restart the kernel button or select Kernel > Restart\n            Kernel in the menu bar at the top of the screen. After the kernel restarts, click into the second cell and select Run the selected\n            cells and advance . Review the results of each notebook cell to analyze and visualize the data. End of Tutorial You have completed this tutorial. This tutorial demonstrated that you can use Airflow,\n        Spark, and Notebooks in Unified Analytics to extract, transform, and load data into a shared\n        volume and then run analytics and visualize the transformed data. On this page Scenario Steps Prerequisites A - Run a DAG in Airflow B \u2013 View the Spark Application C \u2013 Run the Jupyter\n        Notebook End of Tutorial Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/financial-time-series-workflow.html",
        "title": "Financial Time Series Workflow"
    },
    {
        "content": "\nMLflow Bike Sharing Use Case Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour\n    based on weather and time. Scenario A data scientist wants to use a Jupyter Notebook to train a model that predicts how many\n        bikes will be rented every hour based on weather and time information. HPE Ezmeral Unified Analytics Software includes the\n        following components and applications to support this scenario: Dataset Bike sharing dataset, bike-sharing.csv , available in the /shared/mlflow directory. Notebook (Jupyter) Two preconfigured Jupyter notebooks: bike-sharing-mlflow.ipynb - Runs code, trains models, finds the best\n                  model. bike-sharing-prediction.ipynb - Predicts based on the\n                  model; deployed via KServe. MLflow Tracks the experiment and trainings/runs. Logs artifacts, metrics, and parameters for each run. Registers the best model Object Storage Stores artifacts that result after running each experiment. KServe Deployment Downloads and deploys a model from object storage and makes the model accessible\n              through a web service endpoint. Steps Sign in to HPE Ezmeral Unified Analytics Software and perform the following steps: Run the Bike Sharing Use Case Track Experiment, Runs, and Register a Model in MLflow Use the Model for Prediction Run the Bike Sharing Use Case In the left navigation pane, click Notebooks . Connect to your notebook server instance. For this example, select hpedemo-user01-notebook . Copy the MLFlow folder from the /shared directory\n            into the /user directory. NOTE If the Mlflow folder is not available in the /shared directory, perform: Go to GitHub repository for tutorials . Clone the repository. Navigate to ezua-tutorials/Data-Science . Navigate back to the /shared directory. Copy the MLflow folder from the ezua-tutorials/Data-Science repository into the /shared directory. Copy the /MLflow folder from /shared folder to /user directory. Open bike-sharing-mlflow.ipynb and import mlflow and\n              install libraries. When done, restart the kernel and run the cell. NOTE If you are using the local s3-proxy, do not set the following environment\n                  variables for MLflow. However, if you are trying to connect from outside the\n                  cluster, you must set the following environment\n                  variables. os.environ[\"AWS_ACCESS_KEY_ID\"] = os.environ['MLFLOW_TRACKING_TOKEN']\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"s3\"\nos.environ[\"AWS_ENDPOINT_URL\"] = 'http://local-s3-service.ezdata-system.svc.cluster.local:30000'\nos.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = os.environ[\"AWS_ENDPOINT_URL\"]\nos.environ[\"MLFLOW_S3_IGNORE_TLS\"] = \"true\"\nos.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\" Run the notebook cells. Running the notebook returns the details of the best\n              model: Track Experiment, Runs, and Register a Model in MLflow Navigate to the MLflow UI. You should see the bike-sharing-exp experiment. Select the best model and then select Register Model . In this\n            example, the best model is run 2. In the Register Model window, enter Bike_Sharing_Model and click Register . Click on the Models menu to view the registered models. Use the Model for Prediction Navigate to the notebook server and open bike-sharing-prediction.ipynb . Run the first cell and wait until the bike-sharing-predictor pod goes\n            into the running state. Run the second cell to deploy machine learning model using KServe inference service.\n            Note: Update DOMAIN_NAME to your domain for external access and save changes. The\n              system prints the following predictions for the input: Rendted Bikes Per Hours:\nInput Data: {'season': 1, 'year': 2, 'month': 1, 'hour_of_day': 0, 'is_holiday': 0, 'weekday': 6, 'is_workingday': 0, 'weather_situation': 1, 'temperature': 0.24, 'feels_like_temperature': 0.2879, 'humidity': 0.81, 'windspeed': 0.0} \nBike Per Hour: 108.90178471846806\nInput Data: {'season': 1, 'year': 5, 'month': 1, 'hour_of_day': 0, 'is_holiday': 0, 'weekday': 6, 'is_workingday': 1, 'weather_situation': 1, 'temperature': 0.24, 'feels_like_temperature': 0.2879, 'humidity': 0.81, 'windspeed': 0.0} \nBike Per Hour: 84.96339548602367 End of Tutorial You have completed this tutorial. This tutorial demonstrated how to train a model using\n        notebooks, track experiments and runs, log artifacts with MLFlow, and use KServe to deploy\n        and predict models. On this page Scenario Steps Run the Bike Sharing Use Case Track Experiment, Runs, and Register a Model in MLflow Use the Model for Prediction End of Tutorial Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/tutorial-mlflow-bike-share.html",
        "title": "MLflow Bike Sharing Use Case"
    },
    {
        "content": "\nMNIST Digits Recognition Workflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Scenario NOTE An administrator must prepare the environment for this tutorial to work. See Preparing the Tutorial Environment . A data scientist wants to use a Jupyter Notebook\n        to train a model that recognizes numbers in images. The image files reside in object storage\n        and need to be transformed into Parquet format and put into a shared directory in the shared\n        volume that the data scientist\u2019s notebook is mounted to. HPE Ezmeral Unified Analytics Software includes the\n        following components and applications to support an end-to-end workflow for this scenario: Spark Spark application that pulls images from the HPE Ezmeral Data Fabric Object Store\n              via MinIO endpoint, transforms the images into Parquet format, and puts the Parquet\n              data into the shared directory in the shared volume. Airflow Coded Airflow DAG that runs the Spark application. Notebook (Jupyter) Preconfigured Jupyter notebook mounted to the shared volume to run code and train\n              models for the following Kubeflow pipelines: Run experiments with Katib to pick the best model and then deploy the model\n                  using KServe. Full training with TensorFlow jobs. The following diagram shows the components and applications in the workflow: Steps Sign in to HPE Ezmeral Unified Analytics Software and perform the following steps: Prerequisites A - Run a DAG in Airflow B \u2013 View the Spark Application C- Update Path of Spark Generated Results D - Train the Model E - Serve the Model Prerequisites Connect to your Jupyter notebook and perform setup tasks to prepare the environment to\n            train the model. A <username> folder with a sample notebook file and\n            SSL certificate is provided for the purpose of this tutorial. To connect your notebook\n            and perform setup tasks: In the HPE Ezmeral Unified Analytics Software , go to Applications &\n                Frameworks . Select the Data Science tab and then click Open in the Kubeflow tile. In Kubeflow, click Notebooks to open the notebooks page. Click Connect to connect to your notebook server. Go to the /<username> folder. Copy the template object_store_secret.yaml.tpl file from the shared/ezua-tutorials/Data-Analytics/Spark directory to the <username> folder. In the <username>/MNIST-Digits-Recognition folder, open the mnist_katib_tf_kserve_example.ipynb file. NOTE If you do not see the MNIST-Digits-Recognition folder in the <username> folder, copy the folder from the /shared/ezua-tutorials/Data-Science/Kubeflow directory into the <username> folder. The /shared directory is\n              accessible to all users. Editing or running examples from the /shared directory is not advised. The <username> directory is specific to\n              you and cannot be accessed by other users If the MNIST-Digits-Recognition folder is not available in the /shared/ezua-tutorials/Data-Science/Kubeflow directory,\n                perform: Go to GitHub repository for tutorials . Clone the repository. Navigate to ezua-tutorials/Data-Science/Kubeflow . Navigate back to the <username> directory. Copy the MNIST-Digits-Recognition folder from the ezua-tutorials/Data-Science/Kubeflow directory into the <username> directory. To generate a secret to read data source files from S3 bucket by Spark application\n            (Airflow DAG), run the first cell of the financial_time_series_example.ipynb file: import kfp\nkfp_client = kfp.Client()\nnamespace = kfp_client.get_user_namespace()\n!sed -e \"s/\\$AUTH_TOKEN/$AUTH_TOKEN/\" /mnt/user/object_store_secret.yaml.tpl > object_store_secret.yaml A - Run a DAG in Airflow In Airflow, run the DAG named spark_read_write_parquet_mnist . The DAG runs a Spark\n        application that pulls the images from object storage, transforms the data into Parquet\n        format, and writes the transformed Parquet data into the shared volume. Go to Airflow using either of the following methods: Click Data Engineering > Airflow Pipelines . Click Applications & Frameworks , select the Data Engineering tab, and click Open in the Airflow tile. In Airflow , verify that you are on the DAGs tab. Click on the spark_read_write_parquet_mnist DAG. NOTE The DAG is\n              pulled from a pre-configured HPE GitHub repository. This DAG is constructed to submit\n              a Spark application that pulls ubyte.gz files from an object storage bucket, converts\n              the images into Parquet format, and places the converted files in a shared directory.\n              If you want to use your private GitHub repository, see Configuring Airflow to find the steps to configure your\n              repository. Click Code to view the DAG code. Click Graph to view the graphical representation of the DAG. Click Run (play button). Upon successful DAG completion, the data is accessible inside your notebook server by\n              default in the following directory for further processing: /<username>/mnist-spark-data/ To view details for the DAG, click Details . Under DAG Details , you can\n            see green, red, and/or yellow buttons with the number of times the DAG ran successfully\n            or failed. Click the Success or Failed button. To find your job, sort by End Date to see the latest jobs that have run, and\n            then scroll to the right and click the log icon under Log URL for that run. Note that\n            jobs run with the\n              configuration: Conf \"username\":\"your_username\" IMPORTANT The cluster clears the logs that result from the DAG runs.\n              The duration after which the cluster clears the logs depends on the Airflow task,\n              cluster configuration, and policy. B \u2013 View the Spark Application After you run the DAG, you can view the status of the Spark application in the Spark\n          Applications screen. To view the Spark application, go to Analytics > Spark Applications .\n            Alternatively, you can go to Applications & Frameworks and then click on the Analytics tab. On the Analytics tab, select the Spark Operator tile and click Open . Identify the spark-mnist-<username>-<timestamp> application, for example spark-mnist-hpedemo-user01-20230728103759 , and view the status of the\n            application.. Optionally, in the Actions column, click View YAML . C- Update Path of Spark Generated Results Open mnist_katib_tf_kserve_example.ipynb file. In the third cell of the mnist_katib_tf_kserve_example.ipynb file, update the user folder\n              name as follows: user_mounted_dir_name = \"user\" D - Train the Model To train the model: In the Notebook Launcher, select the second cell of the notebook and click Run the selected cells\n              and advance (play icon). After the packages install, restart the notebook kernel. To restart the kernel, click\n            the Restart the kernel button or select Kernel > Restart\n              Kernel in the menu bar at the top of the screen. After the kernel restarts, click into the third cell and select Run Selected Sell and All\n            Below . In the second to last cell, follow the Run Details link to open your\n            Kubeflow Pipeline. Run the Kubeflow pipeline in the UI and wait for it to successfully complete. To get details about components created by the pipeline run, go to the Experiments\n              (AutoML) and Models pages in the Kubeflow UI. E - Serve the Model To serve the model with KServe and get the prediction, wait for the the Kubeflow pipeline\n        to successfully complete the run. The output displays the following results: End of Tutorial You have completed this tutorial. This tutorial demonstrated that you can use Airflow,\n        Spark, and Notebooks in HPE Ezmeral Unified Analytics Software to extract, transform, and load data into a shared volume and then run\n        analytics and train models using Kubeflow pipelines. On this page Scenario Steps Prerequisites A - Run a DAG in Airflow B \u2013 View the Spark Application C- Update Path of Spark Generated Results D - Train the Model E - Serve the Model End of Tutorial Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/workflow-mnist-digits-recognition.html",
        "title": "MNIST Digits Recognition Workflow"
    },
    {
        "content": "\nRetail Store Analysis Dashboard (Superset) Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Scenario A data analyst wants to visualize\n        data sets from MySQL, SQL Server, and Hive data sources in Superset. The data analyst signs\n        in to HPE Ezmeral Unified Analytics Software and\n        connects Unified Analytics to\n        MySQL, SQL Server, and Hive data sources. The data analyst runs a federated query against\n        the data sets and then creates a view from the query. The analyst accesses the view from\n        Superset and uses it to visualize the data in a bar chart and adds the chart to a dashboard. HPE Ezmeral Unified Analytics Software includes the\n      following components and applications to support an end-to-end workflow for this scenario: EzPresto An MPP SQL query engine that runs accelerated queries against connected data sources\n            and returns results to Superset for visualization. EzPresto connects to Superset through a database\n            connection, enabling direct access to the data sources connected to Unified Analytics from Superset. Superset An analytical dashboarding application that communicates with EzPresto to send queries and receive the query\n            results needed to visualize data from the selected data sets. The following diagram shows the components and applications in the workflow: Steps Sign in to HPE Ezmeral Unified Analytics Software and perform the following steps: A - Connect Data Sources B \u2013 Select Data Sets and Create a View C - Connect to the Presto Database D - Add the View to Superset and Create a Chart E - Specify Query Conditions to Visualize Results in the Chart F \u2013 Create a Superset Dashboard and Add the Chart (Visualized Data) G \u2013 Monitor Queries IMPORTANT This tutorial demonstrates how to perform a series of tasks in HPE Ezmeral Unified Analytics Software to\n          complete an example workflow. The data and information used in this tutorial is for\n          example purposes only. You must connect Unified Analytics to your own data sources and use the data sets available to you in\n          your data sources. A - Connect Data Sources Connect HPE Ezmeral Unified Analytics Software to\n        external data sources that contain the data sets (tables and views) you want to work with.\n        This tutorial uses MySQL, SQL Server, and Hive as the connected data source examples. To connect a data source: In the left navigation column, select Data Engineering > Data\n              Sources . The Data Sources screen appears. Click Add New Data Source . Complete the steps required to connect to the MySQL, SQL Server, and Hive data sources: Connecting to MySQL In the Add New Data Source screen, click Create\n                        Connection in the MySQL tile. In the drawer that opens, enter the following information in the respective\n                        fields: Name : mysql Connection URL : jdbc:mysql://<ip-address>:<port> Connection User : myaccount Connection Password : moi123 Enable Local Snapshot Table : Select the check box TIP When Enable Local Snapshot Table is selected, the system caches remote\n                            table data to accelerate queries on the tables. The cache is active for\n                            the duration of the configured TTL or until the remote tables in the\n                            data source are altered. Enable Transparent Cache : Select the check box TIP When Enable Transparent Cache is selected, the system caches data\n                            at runtime when queries access remote tables. As the query engine scans\n                            data in remote data sources, the scanned data is cached on the fly.\n                            Results for subsequent queries on the same data are quickly returned\n                            from the cache. The cache lives for the duration of the\n                          session. Click Connect . Upon successful connection, the system returns the\n                          following\n                          message: Successfully added data source \"mysql\". Connecting to SQL Server In the Add New Data Source screen, click Create\n                        Connection in the SQL Server tile. In the drawer that opens, enter the following information in the respective\n                        fields: Name : mssql_ret2 Connection URL :\n                          jdbc:sqlserver:<ip-address>:<port>;database=retailstore Connection User : myaccount Connection Password : moi123 Enable Local Snapshot Table : Select the check box TIP When Enable Local Snapshot Table is selected, the system caches remote\n                            table data to accelerate queries on the tables. The cache is active for\n                            the duration of the configured TTL or until the remote tables in the\n                            data source are altered. Enable Transparent Cache : Select the check box TIP When Enable Transparent Cache is selected, the system caches data\n                            at runtime when queries access remote tables. As the query engine scans\n                            data in remote data sources, the scanned data is cached on the fly.\n                            Results for subsequent queries on the same data are quickly returned\n                            from the cache. The cache lives for the duration of the\n                          session. Click Connect . Upon successful connection, the system returns the\n                          following\n                          message: Successfully added data source \"mssql_ret2\". Connecting to Hive In the Add New Data Source screen, click Create\n                        Connection in the Hive tile. In the drawer that opens, enter the following information in the respective\n                        fields: Name : hiveview Hive Metastore : file Hive Metastore Catalog Dir : file:///data/shared/tmpmetastore In Optional Fields , search for the following fields and add the\n                          specified values: Hive Max Partitions Per Writers : 10000 Hive Temporary Staging Directory Enabled : Unselect Hive Allow Drop Table : Select Enable Local Snapshot Table : Select the check box TIP When Enable Local Snapshot Table is selected, the system caches remote\n                            table data to accelerate queries on the tables. The cache is active for\n                            the duration of the configured TTL or until the remote tables in the\n                            data source are altered. Enable Transparent Cache : Select the check box TIP When Enable Transparent Cache is selected, the system caches data\n                            at runtime when queries access remote tables. As the query engine scans\n                            data in remote data sources, the scanned data is cached on the fly.\n                            Results for subsequent queries on the same data are quickly returned\n                            from the cache. The cache lives for the duration of the\n                          session. Click Connect . Upon successful connection, the system returns the\n                          following\n                          message: Successfully added data source \"hiveview\". B \u2013 Select Data Sets and Create a View In HPE Ezmeral Unified Analytics Software , complete\n        the following steps to create a view. First select data sources and data sets to work with.\n        Then, run a federated query against the selected data sets and create a view from the query.\n        This tutorial creates an example view named qf_retailstore_view . Select datasets. In the left navigation bar, select Data Engineering > Data\n                  Catalog . On the Data Catalog page, click the dropdown next to the mysql and mssql_ret2 data sources to expose the available schemas in those data\n                sources. Select schemas for each of the data sources: For the mysql data source, select the retailstore schema. For the mssql_ret2 data source, select the dbo schema. In the All Datasets section, click the filter icon to open the Filters drawer. Use the filter to identify and select the following data sets in the selected\n                  schemas: For the dbo schema, filter for and select the following datasets: call_center catalog_sales data_dim item For the retailstore schema, filter for and select the following\n                      datasets: customer customer_address customer_demographics After you select all the data sets, click Apply . Click Selected Datasets (button that is displaying the number of selected\n                data sets). In the drawer that opens, click Query Editor . Depending on the number of\n                selected data sets, you may have to scroll down to the bottom of the drawer to see\n                the Query Editor button. Query the datasets and create a view. In the Query Editor , click + to Add Worksheet . Run the following command to create a new schema, such as hiveview.demoschema , for\n                example: create schema if not exists hiveview.demoschema; Run a query to create a new view from a federated query against the selected data\n                sets, for\n                example: create view hiveview.demoschema.qf_retailstore_view as select * from mssql_ret2.dbo.catalog_sales cs\ninner join mssql_ret2.dbo.call_center cc on cs.cs_call_center_sk = cc.cc_call_center_sk\ninner join mssql_ret2.dbo.date_dim d on cs.cs_sold_date_sk = d.d_date_sk\ninner join mssql_ret2.dbo.item i on cs.cs_item_sk = i.i_item_sk\ninner join mysql.retailstore.customer c on cs.cs_bill_customer_sk = c.c_customer_sk\ninner join mysql.retailstore.customer_address ca on c.c_current_addr_sk = ca.ca_address_sk\ninner join mysql.retailstore.customer_demographics cd on c.c_current_cdemo_sk = cd.cd_demo_sk Click Run . When the query completes, the status \" Finished \"\n                displays. C - Connect to the Presto Database Complete the following steps to connect Superset to the Presto database for access to your\n        data sources and data sets in HPE Ezmeral Unified Analytics Software . Once connected to the Presto database, you can access the\n        view you created in the previous step (step B). To connect to the Presto database, you need\n        the connection URI. You can get the URI from your HPE Ezmeral Unified Analytics Software administrator. To open Superset, in the left navigation pane of HPE Ezmeral Unified Analytics Software , select BI Reporting >\n              Dashboards . Superset opens in a new tab. In Superset, select Settings > Database Connections . Click +DATABASE . In the Connect a database window, select the Presto tile. Enter the SQLALCHEMY URI provided by your administrator. Test the connection. If the test was successful, click Connect . D - Add the View to Superset and Create a Chart Complete the following steps to import the view you created in HPE Ezmeral Unified Analytics Software and create a bar\n        chart. This tutorial demonstrates how to import the view qf_retailstore_view . In the left navigation bar, select BI Reporting > Dashboards to\n            open Superset. In Superset, click the Datasets tab. Click +DATASET . In the Add Dataset window, select the following options: DATABASE: Presto SCHEMA: <your_schema> SEE TABLE SCHEMA: <your_view> This tutorial uses the retailstore schema and qf_retailstore_view . Click ADD DATASET AND CREATE CHART . In the Create a New Chart window, select Bar Chart . Click CREATE NEW CHART . Enter a name for the chart, such as Retail Store View . E - Specify Query Conditions to Visualize Results in the Chart In Superset, charts visualize data based on the query conditions that you specify. The\n        charts created in Superset automatically generate queries that Superset passes to the SQL\n        query engine. Superset visualizes the query results in the chart. Try applying query\n        conditions to visualize your data. Save your chart when done. The following steps demonstrate how query conditions were applied to visualize data in the\n        resulting example bar chart (shown in step 2): Enter the specified query parameters in the following fields: METRICS Click into the METRICS field (located on the DATA tab). A\n                      metrics window opens. Select the Simple tab. Click the edit icon and enter a name for the metric, such as SUM(cs_net_paid) . In the Column field, select cs_net_paid . In the Aggregate field, select SUM . Click Save . FILTERS Click into the FILTERS field (located on the DATA tab). In the window that opens, select the CUSTOM SQL tab. Select the WHERE filter and enter the\n                      following: NULLIF(ca_state, '') IS NOT NULL Click Save . DIMENSIONS Drag and drop the ca_state column into the DIMENSIONS field. Click into the BREAKDOWNS column. In the window that opens, select the SIMPLE tab and select the cc_name column. Click Save . SORT BY Click into the SORT BY field. In the window that opens, select the SIMPLE tab and enter cs_net_paid as the COLUMN and SUM as the AGGREGATE. Click Save . Click CREATE CHART . The bar chart displays results when the query finishes\n              processing. Click Save to save the chart. In the Save Chart window that opens, do\n            not enter or select a dashboard. Click Save to continue. F \u2013 Create a Superset Dashboard and Add the Chart (Visualized Data) Complete the following steps to create a new dashboard and add your chart to the dashboard.\n        This tutorial adds the Retail Store View chart to a dashboard named Retail Store\n          Analysis Dashboard . To create a new dashboard and add your visualized data: In Superset, click on the Dashboards tab. Click + DASHBOARD . Enter a name for the dashboard, for example Retail Store Analysis Dashboard . Drag and drop your chart into the dashboard. Click Save to save the dashboard. NOTE Any time you open a chart or dashboard, Superset and the SQL query engine work\n          together to visualize data. Loading a dashboard page triggers the queries against the\n          database. As the queries run, buffering icons display until the data loads. When data is\n          loaded, the visualizations display. G \u2013 Monitor Queries You can monitor queries generated through Superset from the EzPresto endpoint. You can access the EzPresto endpoint in the EzPresto tile in the Applications &\n          Frameworks space in HPE Ezmeral Unified Analytics Software . Complete the following steps to monitor the query that the chart generates: Return to the HPE Ezmeral Unified Analytics Software UI. In the left navigation bar, select Applications &\n              Frameworks . On the Data Engineering tab, click the EzPresto endpoint in the EzPresto tile. The EzPresto UI\n            opens in a new tab. In the Query Details section, verify that Finished is selected. Selected\n            options have a visible checkmark. You can see the\n            query that ran to populate the Retail Store View bar chart in the Retail Store\n              Analysis Dashboard . Click on the Query ID to see the query details. To see a visualized query plan and metadata for the query, click Live Plan and\n            hover over different areas of the visualized plan. You can also click on various parts\n            of the visualized plan to zoom in on details. End of Tutorial You have completed this tutorial. This tutorial demonstrated the integration of the HPE Ezmeral Unified Analytics Software SQL query\n        engine ( EzPresto ) with Superset to visualize the results of a query on data\n        sets made available through the default Presto database connection. This tutorial also\n        showed you how to monitor queries from the EzPresto Cluster Monitoring tool. On this page Scenario Steps A - Connect Data Sources B \u2013 Select Data Sets and Create a View C - Connect to the Presto Database D - Add the View to Superset and Create a Chart E - Specify Query Conditions to Visualize Results in the Chart F \u2013 Create a Superset Dashboard and Add the Chart (Visualized Data) G \u2013 Monitor Queries End of Tutorial Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/ua-workflow-ezsql-superset.html",
        "title": "Retail Store Analysis Dashboard (Superset)"
    },
    {
        "content": "\nSubmitting a Spark Wordcount Application Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Preparing the Tutorial Environment Describes how to prepare the environment for the Financial Time Series and MNIST Digits     Recognition tutorials. Data Source Connectivity and Exploration Provides basic steps for using the Data Engineering space within HPE Ezmeral Unified Analytics Software . BI Reporting (Superset) Basics Provides basic steps for using the BI Reporting (Superset) space within HPE Ezmeral Unified Analytics Software . Candy Sharing Tutorial (Kale) Describes how Kale converts Notebook to pipeline by applying notebook         annotations. Feast Ride Sharing Use Case Provides an end-to-end workflow using Feast in HPE Ezmeral Unified Analytics Software to generate training data and perform online         model inference for the ride-sharing driver satisfaction model. Financial Time Series Workflow Describes how to use HPE Ezmeral Unified Analytics Software to run a Spark application from an Airflow DAG and then run a     Jupyter notebook to analyze and visualize data that the Spark application puts into a shared     directory in the shared volume that the data scientist\u2019s notebook is mounted to. MLflow Bike Sharing Use Case Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MLflow prediction model to determine bike rentals per hour     based on weather and time. MNIST Digits Recognition Workflow Provides an end-to-end workflow in HPE Ezmeral Unified Analytics Software for an MNIST digits recognition example. Retail Store Analysis Dashboard (Superset) Provides an end-to-end workflow example for a retail store analysis scenario in HPE Ezmeral Unified Analytics Software using EzPresto and Superset. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark         Application in HPE Ezmeral Unified Analytics Software . Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Submitting a Spark Wordcount Application Provides an end-to-end example for creating and submitting a wordcount Spark\n        Application in HPE Ezmeral Unified Analytics Software . Prerequisites Sign in to HPE Ezmeral Unified Analytics Software . For the wordcount Spark Application, the application argument is file:///mounts/shared-volume/spark/wordcount.txt . For the wordcount Spark Application, the application class name is org.apache.spark.examples.JavaWordCount . Ensure that you have the spark-examples_212-32016-eep-810.jar file available in the auto_spark_test_data directory and the wordcount.txt file available in the spark directory. NOTE Always create the auto_spark_test_data and spark directory in the shared directory. In the left navigation column, navigate to Data Engineering \u2192\n                                Data Sources . Click Browse . Select the shared directory. Select the auto_spark_test_data directory and verify\n                            that you have the spark-examples_212-32016-eep-810.jar file. Select the spark directory and verify that you have the wordcount.txt file. NOTE If the spark-examples_212-32016-eep-810.jar file is\n                                not available in the auto_spark_test_data directory\n                                and the wordcount.txt file is not available in the spark directory, follow these steps: Go to GitHub repository for tutorials . Navigate to ezua-tutorials/Data-Analytics/Spark in\n                                        the repository and download the spark-examples_212-32016-eep-810.jar file and the wordcount.txt file. Upload the spark-examples_212-32016-eep-810.jar file to the auto_spark_test_data directory\n                                        in HPE Ezmeral Unified Analytics Software . Upload the wordcount.txt file to the spark directory in HPE Ezmeral Unified Analytics Software . Submitting Wordcount Spark\n                Application The wordcount Spark application counts the number of\n                occurrences of each unique word in the wordcount.txt input\n                file. In HPE Ezmeral Unified Analytics Software , use one the following methods to go to Spark\n                        Applications : In the left navigation bar, click the Analytics\n                                    icon and click Spark\n                                    Applications . In the left navigation bar, click the Applications &\n                                    Frameworks icon. On the Analytics tab, click Open in the Spark tile. Click Create Application on the Spark Applications\n                    screen. Navigate through each step within the Create Spark\n                        Application wizard: Application Details : Create a new application.\n                            Set the following boxes: Name: Enter the application name as username-wordcount . NOTE The\n                                                application name must be unique. Description: Enter the application description. For example: This\n                                            application counts words in a text file. Configure Spark Application : Set the following\n                            boxes: Type: Select the application type as Java. Source: Select the main application file source as Shared Directory . Filename: Click Browse , and select spark-examples_212-32016-eep-810.jar file from the auto_spark_test_data directory. Class Name: Enter org.apache.spark.examples.JavaWordCount as main class of the application. Arguments: Enter file:///mounts/shared-volume/spark/wordcount.txt as input parameter required by the username-wordcount Spark\n                                            application. Click Dependencies . The wordcount application\n                            does not require any additional dependencies. Click Driver Configuration . When boxes in this\n                            wizard are left blank, default values are set. The default values are as\n                            follows: Number of Cores: 1 Core Limit: unlimited Memory: 1g Click Executor Configuration . When boxes in this\n                            wizard are left blank, default values are set. The default values are as\n                            follows: Number of Executors: 1 Number of Cores per Executor: 1 Core Limit per Executor: unlimited Memory per Executor: 1g Click Schedule Application . If you want to\n                            schedule a Spark application, see Creating Spark Applications for details. Click Review. To view the application\n                            configuration, click Edit YAML . To apply the\n                            changes, click Save Changes . To cancel the\n                            changes, click Discard Changes . You\n                                can also click the pencil icon in each\n                                section to navigate to the specific step to change the application\n                                configuration. Click Create Spark Application on the bottom right of\n                    the Review step. The wordcount Spark application is created and submitted. You can view it on the Spark Applications screen. You can also view the logs to check the output of  the wordcount application. To see the\n            logs, click the menu icon in the Actions column of the username-wordcount application, and click View\n                Logs . NOTE Note: After you are finished with your task, click the menu icon in the Actions column of\n                    the username-wordcount application and\n                    click Delete . Alternatively, you can select a checkbox\n                for the application you want to delete and click Delete on\n                the top right pane of the table. On this page Prerequisites Submitting Wordcount Spark\n                Application Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Tutorials/Tutorials/creating-spark-apps-workflow-UI.html",
        "title": "Submitting a Spark Wordcount Application"
    },
    {
        "content": "\nResources Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . About Provides an overview of HPE Ezmeral Unified Analytics Software . Tutorials Provides a set of tutorials that you can use to experience HPE Ezmeral Unified Analytics Software and the included     applications, such as tutorials for data science and data analytics workflows with notebooks and     applications like Spark, MLflow, Feast, Airflow, and EzPresto. Resources Provides links to additional resources such as product licensing information, on-demand     training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Resources Provides links to additional resources such as product licensing information, on-demand\n    training, videos, blogs, and HPE Ezmeral Unified Analytics Software community. In addition to the product documentation, you may be interested in the following\n      resources: Download Documentation Click here to download a PDF of the HPE Ezmeral Unified Analytics Software documentation. Contact for Support Get in touch with HPE Ezmeral Unified Analytics Software support team through HPE Support Center . HPE Ezmeral Software Resources Slack Community for Developers https://slack.hpedev.io/ Videos, Reports, and Case Studies https://www.hpe.com/us/en/resource-library.html HPE GreenLake Marketplace https://www.hpe.com/us/en/software/marketplace.html/platform/ezmeraldata Glossary To find the list of terms (with description) used in HPE Ezmeral Unified Analytics Software documentation. See Glossary . On this page Download Documentation Contact for Support HPE Ezmeral Software Resources Glossary Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Resources/resources.html",
        "title": "Resources"
    },
    {
        "content": "\nAdministration Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/administration.html",
        "title": "Administration"
    },
    {
        "content": "\nInstallation Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/ua-installation.html",
        "title": "Installation"
    },
    {
        "content": "\nInstalling on User-Provided Hosts (Connected and Air-gapped Environments) Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installation Prerequisites Lists the prerequisites for HPE Ezmeral Unified Analytics Software installation on user-provided hosts in connected     (internet access) and air-gapped (no internet access) environments. Post Installation Steps Provides steps to complete after you install HPE Ezmeral Unified Analytics Software on user-provided hosts. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and\n    air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the\n    installation prerequisites. HPE Ezmeral Unified Analytics Software supports bare metal and VM installations on AWS, GCP, and Azure. You can install HPE Ezmeral Unified Analytics Software from a laptop or host\n      machine. Complete the following steps to install HPE Ezmeral Unified Analytics Software on a bare metal machine or virtual machine (VM): Review the prerequisites and verify\n            that the requirements have been met. Run the installation script to\n            access the Installer Web UI. In the Installer Web UI, provide the pertinent information on each of the following\n            screens: Node Setup Installation\n              Details User Authentication\n                Details Complete the post-installation\n            steps. Prerequisites Verify that you have configured a pool of user-provided hosts that meet\n            the installation prerequisites. See Installation Prerequisites . You must have the HPE Ezmeral Unified Analytics Software downloaded before you follow the instructions in this document.\n            The download includes the software binaries, installation script, Airgap Utility (for\n            air-gapped environments), and a README.txt file. After purchasing HPE Ezmeral Unified Analytics Software , the downloads\n            are made available to you through the Access your products button in the HPE\n              Subscription Electronic Receipt email that you receive from HPE. The HPE Ezmeral Unified Analytics Software deployment runs on a Kubernetes cluster. Components within HPE Ezmeral Unified Analytics Software cannot launch\n            until they download their respective container images. How the components download the\n            container images depends on your environment. The following table describes container\n              downloads in different environments: Environment Description Direct connection If the machine is directly connected to the internet (UI accessible),\n                        you do not have to provide any proxy settings during installation. However,\n                        the firewall settings can prevent the packages from being\n                        downloaded. Proxy connection If the machine is connected to the internet via proxy, you must provide\n                        the proxy server information for http, https, and no_proxy during\n                        installation Air-gapped environment The Airgap Utility prerequisite describes the requirements for an\n                        air-gapped environment. See Installation Prerequisites . Run the Installation Script to Access the Installer Web UI To run the installation script and open the Installer Web UI, complete the following\n          steps: Go to the directory where you extracted the installer bundle ( HPE_Ezmeral_Unified_Analytics_Installer_S1U85-70016.star ): cd S1U85-70016 Run the installation script\n            on a host, but do\n            not run it on the hosts used to deploy HPE Ezmeral Unified Analytics Software . See Installation Prerequisites for\n            details. ./start_ezua_installer_ui.sh The\n            launcher guides you through the prompts to start the Installer Web UI. NOTE If you get a permission denied error, run chmod +x\n                    start_ezua*.sh before you run the installation script. If the image is locally available, the container starts right away. If the image\n                  is not local, it takes time to download the image. Time for the image to download\n                  and start the container UI depends on network speed. If you ran the script on a laptop, you can access the installer UI by connecting\n                  to the browser using localhost:8080 . If you ran the script on a\n                  different node, you can access the installer UI by connecting to the browser using <node-ip-address>:8080 . Verify that port 8080 is opened\n                  through firewalls from the laptop to the node running the installer. If proxy settings are present in the environment, include the master node DNS\n                  names of the workload and coordinator clusters in the NO_PROXY list. On the screen that appears, select one of the following options: TIP The Ezmeral Coordinator is the\n              component that orchestrates the deployment of HPE Ezmeral Unified Analytics Software instances. Installation Using New Ezmeral Coordinator For first time installation, select this option. When you install with a new Ezmeral Coordinator , you designate the control plane ( Ezmeral Coordinator and management\n                      cluster nodes) and worker nodes, as described in the following section, Node Setup . Installation Using Existing Ezmeral Coordinator If you previously installed HPE Ezmeral Unified Analytics Software , select this option to use the existing Ezmeral Coordinator to\n                      create a new HPE Ezmeral Unified Analytics Software cluster. All files in the existing cluster are cleared, except for the kubeconfig file for the Ezmeral Coordinator . You do not\n                      have to reconfigure the management cluster or upload the configuration file\n                      again. On the Select your deploy target screen, select Install in the Bare\n              Metal or VM tile. The Node Setup screen appears. Node Setup Node setup sets up the control plane and worker nodes. You can upload a YAML file or\n        manually configure the nodes through fields in the Installer Web UI. You\n          have the option of running an installation pre-check script, as described in step 2 of\n          this section. The following table describes control plane and worker nodes: Node Type Description Minimum Required Minimum Required for High Availability Control Plane Enter a comma-separated list of nodes (IP addresses). If you\n                  chose to install using a new Ezmeral Coordinator , the first node listed becomes the Ezmeral Coordinator node. This node\n                  orchestrates the deployment of HPE Ezmeral Unified Analytics Software instances. The remainder of the nodes in the list\n                  serve as the management cluster. Installation Using New Ezmeral Coordinator (First-time installation) 2 * 4 ** Installation Using Existing Ezmeral Coordinator 1 3 Worker Enter a comma-separated list of nodes (IP addresses). These nodes run the HPE Ezmeral Unified Analytics Software service. Calculate the number of worker nodes based on the VCPUs you enter in step\n                  7. Must be a minimum of 96 VCPUs. The accumulated total VCPU of the worker nodes\n                  should match or exceed the number of VCPUs that you enter in step 7. 3 N/A * Requires one node for the Ezmeral Coordinator and one node for the workload. ** Requires one node for the Ezmeral Coordinator and three nodes for the workload. IMPORTANT Either the SSH password or SSH key is required. The SSH pass phrase is optional and\n            only applicable if the SSH key is provided. Wall clock time on the hosts in the deployment must be synchronized. On the Node Setup screen, complete the following steps: Upload a YAML or complete the fields to manually configure the nodes. If you upload a YAML File, the system runs a validation check against\n              the file and returns an error message if the file is invalid. TIP A YAML\n                template file is provided and includes the following fields: controlplanes: \"\" # comma-separated list of ip values\nworkers: \"\" # comma-separated list of ip values\nssh_username: root\nssh_password: \"\"\nssh_key: \"\" # base64 encoded string\nssh_passphrase: \"\" (Optional) Run the installation pre-check script. The installation pre-check script\n              runs checks against each of the host machines configured for HPE Ezmeral Unified Analytics Software , including the Ezmeral Coordinator , control\n              plane, and worker hosts. The script also does an aggregated check to verify that the\n              hosts, operating as a cluster, have enough resources to support the installation. Running the pre-check script can take some time; however, you can continue the\n              installation as the pre-check runs in the background. When the pre-check completes,\n              the system posts a message stating that the pre-check succeeded or failed. In case of\n              failure, return to the Node Setup screen. The system posts the node(s) that did\n              not pass pre-check. In case of failure, complete the following steps to access the\n              logs in the UI container: To exec into the Docker container,\n                  run: docker exec -it node-server bash Go to the prechecks directory: cd /tmp/prechecks To view the prechecks logs: cat prechecksLogs.txt Check the logs for errors and resolve the errors. Once resolved, run the\n                  installation pre-check again to verify that the issue is resolved and then\n                  complete installation. Click Next to proceed to Installation Details . Installation Details On the Installation Details screen, complete the following steps: Complete the following fields: Field Description Installation Name Enter a unique name for the installation. The installation name must\n                    consist of lowercase alphanumeric characters or - . For example, installation-1 . This name becomes the name of the cluster\n                    namespace. In the future, if you need to add additional hosts to increase\n                    resources for applications, you will use this name as the namespace when adding\n                    hosts, as described in Expanding the Cluster . Domain Name Enter a valid DNS domain name to connect to the cluster via the browser. NOTE The HPE Ezmeral Unified Analytics Software cluster domain name cannot be the same as the DNS\n                          host domain name. Do not enter your corporate top level domain (TLD) name in this field.\n                          If you enter the corporate TLD name, you must set up a wildcard record\n                          that points all subdomains of the corporate domain to the HPE Ezmeral Unified Analytics Software ingress gateway hosts. Best practice is to enter a subdomain off the corporate domain. For\n                          example, if your corporate domain is company.com , you\n                          could enter ezua.company.com as your domain name. As you continue the installation process, you will set up wildcard\n                          records for the domain name you enter in this field. The DNS name\n                          resolution to those records should work for pods and any member of your\n                          organization that needs access to HPE Ezmeral Unified Analytics Software . VCPU The number of VCPUs that you enter is determined by the number of worker\n                    nodes. Typically, 96 VCPUs translates to three worker nodes, and entering 97\n                    would translate to four worker nodes. If you need to distinguish between cores\n                    and VCPUs, for example in cases where hyperthreading is enabled, run the lscpu tool to accurately determine the VCPUs for your\n                    hosts. High Availability When selected, three controller nodes are enabled. Currently, HA is\n                    available for the workload cluster only. The management cluster does not support\n                    HA. Use GPU See GPU Support . Air Gap Environment Select this option when installing in an air-gapped environment (no\n                    internet access). If you select Air Gap Environment, you must provide the\n                    registry details. Registry URL Enter the registry URL. Only required for air-gapped environments, but can\n                    also be used for a custom image registry in connected environments. Make sure\n                    you add the trailing / at the end of the URL, as shown in the\n                    following example: my-registry.mip.storage.mycompany.net/ezua/ Username Enter the user name for the administrative user. Password Enter the password for the administrative user. Registry Insecure Select this option if the registry is not secure. If the registry is\n                    secure, do not select this option. CA Certificate Upload the CA certificate. See Working with Certs and the Truststore . TLS Certificates Use Self Signed Certificate - Typically only selected for POCs and\n                        demos. For production environments, HPE recommends uploading your own\n                        certificates (CA certificate and Private Key). CA Certificate - Upload the CA certificate Private Key - Upload the private key. Certificate - Upload additional certificates. See AD/LDAP Servers and Working with Certs and the Truststore . Proxy Details NOTE The proxy details apply to the HPE Ezmeral Unified Analytics Software application; they do not apply to the\n                      host. HTTP Proxy - Enter the URL for the proxy data center. HTTPS Proxy - Enter the URL for the proxy data center. No Proxy - Each of the hosts in the HPE Ezmeral Unified Analytics Software cluster must have the IP addresses of the coordinator and control\n                          plane hosts of the workload cluster in the no_proxy list. Add\n                        the FQDN of the master host in the workload cluster OR a comma-separated list of IP addresses or hostnames . Note that\n                        some of the IP addresses in the cluster are required to bypass the proxy\n                        settings to reach the internal pod/container entities. Use the following\n                        string of IP addresses to bypass the proxy settings: 10.96.0.0/12,10.224.0.0/16,10.43.0.0/16,\\\n.external.hpe.local,localhost,.cluster.local,.svc,\\\n.default.svc,127.0.0.1 For example, if your domain is ezua.company.com , you would enter the following string\n                        for no_proxy: 10.96.0.0/12,10.224.0.0/16,10.43.0.0/16,\n.external.hpe.local,localhost,.cluster.local,.svc,\\\n.default.svc,127.0.0.1, ezua.company.com External URL - This field only applies to the workload nodes and is\n                        only required if you select HA for the HPE Ezmeral Unified Analytics Software application. If you want HA for\n                        the Ezmeral Coordinator ,\n                        contact HPE Support before you install on the Ezmeral Coordinator node. Click Next to proceed to User Authentication Details . User Authentication Details Connected and air-gapped installations can use internal or external LDAP. Internal LDAP is\n        typically used for POC and demo scenarios. External LDAP is typically used for production\n        environments. See AD/LDAP Servers . To add user authentication details, complete the following steps: Either select or do not select the option to use an external LDAP server. If you select Use External LDAP Server , complete the related fields. The\n                user that you enter becomes the default Unified Analytics administrative user. This user must already exist in the\n                AD/LDAP server that you specify. List of related fields: Select Active Directory if the LDAP is an Active Directory\n                      (ADLDAP) Security Protocol LDAP Server Address Server Port Bind DN Bind Password Search Base DN Trust Store File Trust Store Password Username Attribute Fullname Attribute Email Attribute UID Attribute GID Attribute Group Name Group GID Username of the default admin user Validation options If you do not select the Use External LDAP Server option, Provide\n                the following information to create the default Unified Analytics administrative user. This user must be part of your\n                organization and have an organization email, for example bob@company.com . Username Full Name Email Password Click Submit . The installation of components and applications begins. The Installation Status screen displays the installation status of the components\n              and applications as the installation progresses. IMPORTANT Note the IP addresses on this screen. You need these to complete the post\n                    installation steps to update your DNS A and DNS records. If the installation fails at any point, click Download Logs to access\n                    the logs files for the Ezmeral Coordinator , infrastructure services, or application services.\n                    Review the log files to troubleshoot the failure. If\n                    you cannot resolve the installation failure issue, contact HPE Support. TIP The first status update shows the progress of the Ezmeral Coordinator . When complete,\n                  the Download Kubeconfig button appears on the screen. You can download the kubeconfig for the Ezmeral Coordinator and worker cluster. Clicking Open HPE Ezmeral Unified Analytics Software launches the UI. Clicking Start New Installation installs another instance of HPE Ezmeral Unified Analytics Software . Post Installation Steps Complete the post installation steps, as described in Post Installation Steps . Installation Prerequisites Lists the prerequisites for HPE Ezmeral Unified Analytics Software installation on user-provided hosts in connected     (internet access) and air-gapped (no internet access) environments. Post Installation Steps Provides steps to complete after you install HPE Ezmeral Unified Analytics Software on user-provided hosts. More information Installation Prerequisites Post Installation Steps Administration AD/LDAP Servers Configuring Included Applications Upgrading Included Frameworks Managing Imported Tools and Frameworks On this page Prerequisites Run the Installation Script to Access the Installer Web UI Node Setup Installation Details User Authentication Details Post Installation Steps Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/install-physhost-vm.html",
        "title": "Installing on User-Provided Hosts (Connected and Air-gapped Environments)"
    },
    {
        "content": "\nInstallation Prerequisites Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installation Prerequisites Lists the prerequisites for HPE Ezmeral Unified Analytics Software installation on user-provided hosts in connected     (internet access) and air-gapped (no internet access) environments. Post Installation Steps Provides steps to complete after you install HPE Ezmeral Unified Analytics Software on user-provided hosts. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Installation Prerequisites Lists the prerequisites for HPE Ezmeral Unified Analytics Software installation on user-provided hosts in connected\n    (internet access) and air-gapped (no internet access) environments. You can install HPE Ezmeral Unified Analytics Software on user-provided hosts. User-provided hosts are machines that meet the prerequisite criteria listed on\n      this page. A user-provided host\n      is a bare metal machine or virtual machine (VM) that meets the prerequisites listed. HPE Ezmeral Unified Analytics Software supports bare metal and VM installations on AWS, GCP, and Azure. If you need to add additional user-provided hosts to increase the amount of resources for applications and\n      users after you install HPE Ezmeral Unified Analytics Software , you can expand the cluster, as described in Expanding the Cluster . IMPORTANT The HPE Ezmeral Unified Analytics Software product downloaded includes the software binaries, installation script, Air Gap Utility\n          (for air-gapped environments), and a README.txt file. After purchasing HPE Ezmeral Unified Analytics Software , the downloads are\n          made available to you through the Access your products button in the HPE\n            Subscription Electronic Receipt email that you receive from HPE. When creating a domain name, opt for a subdomain name that is only used for HPE Ezmeral Unified Analytics Software . For example, if\n          your top level domain (TLD) name is company.com , use a subdomain name\n          such as ezua.company.com . Software Binaries The README.txt file included with the product provides instructions for downloading and\n        extracting the HPE Ezmeral Unified Analytics Software binaries that are required to install the product, including the Air Gap Utility. Air Gap Utility (Only required for air-gapped environments) Use the Air Gap Utility to get the required container images. Create a local repository if\n        you do not already have one. In addition to setting up a local repository, you must also set\n        up a RHEL/Rocky 8-based yum repository. The installer runs yum commands\n        against this repository. See Using the Air Gap Utility for additional information. For\n        operating system support, see the Operating System support matrix. Host Machines HPE Ezmeral Unified Analytics Software installation\n        requires two types of host machines with the following minimum storage requirements: Table 1 . Host Machine Requirements Machine Type VCPU Memory Size (GB) Disk Size (Disk Count) Machine Count Control plane ( Ezmeral Coordinator /Management Cluster) 4 32 500 (1) 2 Workload 32 128 500 (2) 3 Launcher Host 1 2 4 1 This is the host that\n        runs the installation script. This host is separate from the hosts that deploy HPE Ezmeral Unified Analytics Software . This host must also\n        have Docker version 20.10 (with a minimum of 20GB storage) and firewall allowed on port\n          8080. IMPORTANT To meet VCPU sizing requirements, at least three storage capable hosts are\n              required. Host machines must have a sudo password. Mount Points The supported mount points and their minimum sizes depends on the type of host. The\n              host file system must have at least the root mount point: / The\n                total minimum required size is the combination of all the mount point sizes listed\n                in the table for a given type of host. If you choose not to configure a listed mount\n                point, that mount point's required size must be added to the root\n                  ( / ) mount point. For example, if you choose not to\n                configure /opt as a separate mount point on the Controller host,\n                you must add the 100GB listed for /opt to the 50GB listed for the\n                root mount point (/). That is, if /opt is not a separate mount\n                point, the Controller host requires 150GB for the root ( / ) mount\n                point. The storage size for the Controller and Shadow Controller hosts must\n                  match. Table 2 . Mount Point Requirements for Controller and Shadow Controller\n                    Hosts Mount Point Minimum Size (GB) Purpose / 50 Root file system where the Unified Analytics components are\n                          stored /var , or /var/lib , or /var/lib/docker 150 Stores container metadata information /opt 100 Stores all Unified Analytics software /srv or /srv/bluedata 20 /srv/bluedata stores all temporary runtime files,\n                          including any artifacts, such as scripts and JAR files, that have been\n                          uploaded for running jobs. Table 3 . Mount Point Requirements for Kubernetes Hosts Mount Point Minimum Size (GB) Purpose / 70 Root file system where the Unified Analytics components are stored. /var , or /var/lib , or /var/lib/containerd , or /var/lib/docker 150 Stores container metadata information. /var/lib/containerd is used for hosts running the\n                          Hewlett Packard Enterprise distribution of Kubernetes. /var/lib/docker is used for the other hosts in the\n                          deployment. /opt 50 Stores all Unified Analytics software. /opt/ezkube (on\n                          Kubernetes hosts hosts only), /opt/bluedata , and /opt/hpe are used to install Unified Analytics . VCPU Sizing Guidelines The combined VCPUs of worker hosts should be no less than 96 for deploying HPE Ezmeral Unified Analytics Software services and apps; otherwise, some services cannot start due to lack of resources.\n                  If the machine configuration has 16 VCPU and 64 GB of memory, HPE recommends using\n                  a minimum of six (6) machines. When installing HPE Ezmeral Unified Analytics Software , the VCPU option (on the Installation Details screen) should\n                  be equal to or less than the total VCPUs of the combined capability of the worker\n                  hosts; otherwise, the installation will fail due to lack of resources. DNS Configuration The DNS configuration requires that: All hosts have A records added to DNS. The name resolution works forward and backward. The FQDN is a maximum of 63 characters. All hosts must be part of the DNS domain and be able to resolve the FQDNs. Operating System HPE Ezmeral Unified Analytics Software supports RHEL\n        8.8. All machines serving as hosts must run the same OS. Both GPU\n        and non-GPU hosts are supported with RHEL 8.8. Hewlett Packard Enterprise strongly recommends using only dedicated hosts with clean OS\n        installations on them. Installing HPE Ezmeral Unified Analytics Software on hosts with other running applications can cause unpredictable\n        behavior. To ensure your OS has the latest packages, Hewlett Packard Enterprise recommends\n        performing a yum update before installation. Use the standard OS kernel; modifications may cause HPE Ezmeral Unified Analytics Software to function unpredictably. To minimize the need for troubleshooting, Hewlett Packard Enterprise recommends newer kernel versions. HPE Ezmeral Unified Analytics Software does not\n        support upgrades between major OS versions. For example, if you are migrating from OS\n        version 7.x to 8.x, you must perform a new installation (not an upgrade), and then install HPE Ezmeral Unified Analytics Software . RHEL 8.8 Requirements HPE Ezmeral Unified Analytics Software has\n              the following RHEL requirements: RHEL systems must have active, valid subscriptions in order to access the RHEL\n                  RPM repositories. Firewall is supported only in iptables mode for RHEL 8.8. TIP The GPU operator does not support Ubuntu or Rocky. Rocky works in non-GPU environments. For information related to operating systems and operating system version\n                    support, contact HPE Support. Network HPE Ezmeral Unified Analytics Software installation\n        have the following network requirements: Table 4 . Network Requirements VM DNS Network IP Address Single vNIC, static IP DNS server to resolve the FQDN Single network connecting all machines. Static: 2 controller machine + 3 worker machines Disable IP Checksum Before you install HPE Ezmeral Unified Analytics Software , run the following script on all nodes to disable IP checksum: #! /bin/bash\n\n# Script to disable ip checksum offload using ethtool for the primary nic. We will create a oneshot systemd service\n# to persist this across reboots\n\n# Setting ipaddress of the node\nHOST_IP=\"$(hostname -i)\"\n\necho \"fetching interface name for host: $HOST_IP\"\nPRIMARY_NIC=$(ip -o a show | grep ${HOST_IP} | awk '{print $2}')\n\necho \"printing current configuration for the nic\"\n\nethtool -k \"${PRIMARY_NIC}\" | grep tx-checksum-ip-generic\n\necho \"creating env and systemd unit file to turn chksum off for interface \\\"$PRIMARY_NIC\\\"\"\n\ncat > /etc/sysconfig/ezfab-chksum-off <<EOF\nPRIMARY_NIC=${PRIMARY_NIC}\nEOF\n\ncat > /usr/lib/systemd/system/ezfab-chksum-off.service <<EOF\n[Unit]\nDescription=Oneshot service to turn checksum off\nAfter=network.service\n\n[Service]\nType=oneshot\nEnvironmentFile=/etc/sysconfig/ezfab-chksum-off\nExecStart=ethtool -K ${PRIMARY_NIC} tx-checksum-ip-generic off\nRemainAfterExit=yes\nTimeoutSec=0\n\n# Output needs to appear in instance console output\nStandardOutput=journal+console\nStandardError=journal+console\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\nsystemctl daemon-reload\nsystemctl start ezfab-chksum-off\nsystemctl enable ezfab-chksum-off\n\necho \"printing configuration after disabling\"\n\nethtool -k \"${PRIMARY_NIC}\" | grep tx-checksum-ip-generic Port Access See Ports Used by HPE Ezmeral Unified Analytics Software . GPU (Optional) HPE Ezmeral Unified Analytics Software supports GPU\n        on user-provided hosts. For\n        GPU configuration information, see GPU Support . On this page Software Binaries Air Gap Utility (Only required for air-gapped environments) Host Machines Operating System Network Disable IP Checksum Port Access GPU (Optional) Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/prereq-install-pph.html",
        "title": "Installation Prerequisites"
    },
    {
        "content": "\nPost Installation Steps Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installation Prerequisites Lists the prerequisites for HPE Ezmeral Unified Analytics Software installation on user-provided hosts in connected     (internet access) and air-gapped (no internet access) environments. Post Installation Steps Provides steps to complete after you install HPE Ezmeral Unified Analytics Software on user-provided hosts. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Post Installation Steps Provides steps to complete after you install HPE Ezmeral Unified Analytics Software on user-provided hosts. After you have successfully installed HPE Ezmeral Unified Analytics Software , complete the following post installation steps: Note the ingress node IP address on the Installation Status screen and\n            configure or update your DNS A records to point to this address. NOTE If\n              you do not see the IP address, refer to the User Interface troubleshooting\n              page to resolve the issue. Update A records in your DNS server to resolve your domain name with the addresses\n            provided. You can do this by pointing your DNS record to the two IP addresses that\n            display on the Installation Status screen. It may take a few minutes for your DNS\n            settings to propagate. Access the HPE Ezmeral Unified Analytics Software home page by clicking the green bar that reads Open HPE Ezmeral Unified Analytics Software . Note the Product ID in the window. You need the Product ID to activate the HPE Ezmeral Unified Analytics Software service. To activate the HPE Ezmeral Unified Analytics Software service, follow the steps listed in Service Activation and Billing in Connected Environments . (Air-gapped environments only) For a successful Airflow installation, manually set the\n            HTTP proxy or configure Airflow to point to your internal GitHub repository, as\n            described in Airflow DAGs Git Repository . This step is required in an air-gapped\n            environment because Airflow is pre-configured to pull DAGs from an HPE GitHub\n            repository. In air-gapped environments, Airflow cannot access the HPE repository. Run the following command to update the SPIFFE CSI\n            driver: kubectl -n spire set image ds spire-spiffe-csi-driver  spiffe-csi-driver=ghcr.io/spiffe/spiffe-csi-driver:0.2.5 For\n            details, see Host (Node) Management . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/pph-post-install.html",
        "title": "Post Installation Steps"
    },
    {
        "content": "\nInstalling HPE Ezmeral Unified Analytics Software on OpenShift Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster\n    and also lists the current limitations. To install HPE Ezmeral Unified Analytics Software in an OpenShift cluster, complete the following steps: 1. Complete the Prerequisites. A. Verify that the VMs (nodes) in the OpenShift cluster meet the installation requirements B. Apply labels to the storage nodes C. (Air-Gapped Only) Inject HPE Ezmeral Unified Analytics Software images into your local repository D. (Air-Gapped Only) Apply the image registry certificate E. Install the CertManager 2. Install HPE Ezmeral Unified Analytics Software . Currently, you can install HPE Ezmeral Unified Analytics Software through the Installer Web UI only. See Install HPE Ezmeral Unified Analytics Software with the Installer Web UI . The ability to install HPE Ezmeral Unified Analytics Software manually (through a CLI) is coming soon. NOTICE Temporary Limitations Upcoming releases will address the following temporary limitations: Some Pods in the HPE Ezmeral Unified Analytics Software platform must run as root . To avoid\n                    permission-denied errors, the HPE Ezmeral Unified Analytics Software installation process sets the anyuidsecurity context in some namespaces to allow root-based\n                    execution. Some Pods in the HPE Ezmeral Unified Analytics Software platform require HostPath-based volume mounts, which\n                    OpenShift denies by default. These Pods need permission to mount HostPath\n                    volumes. Permission to mount these volumes is granted by the securityContext parameter, with privileged set to true . Read more about OpenShift security context constraints here . A. Verify that the VMs (nodes) in the OpenShift cluster meet the installation\n        requirements The following table lists the requirements: Prerequisite Details Operating System RHEL8.8 based RHCOS OpenShift An OpenShift 4.12.x cluster must be dedicated to HPE Ezmeral Unified Analytics Software . Storage Minimum of 3 storage nodes, each with at least: 16 vCPUs 32 GB RAM 2 additional disks with a minimum of 500 GB GPU The only GPU model supported is Nvidia A100 GPU with Multi-Instance (MIG)\n                      configuration. The MIG configuration must be applyed equally to all GPU cards. Install the NFD and GPU operators and then create instances of these through\n                      the OpenShift console. When done, verify that the GPU is active. B. Apply labels to the storage nodes Tag your storage nodes (non-GPU worker nodes) with the \"hpe.com/dataplatform\"=\"true\" label, as shown in the following example that uses\n        generic DNS names: kubectl label no worker0.user01.ezfab.local \"hpe.com/dataplatform\"=\"true\" \nkubectl label no worker1.user01.ezfab.local \"hpe.com/dataplatform\"=\"true\" \nkubectl label no worker2.user01.ezfab.local \"hpe.com/dataplatform\"=\"true\" \nkubectl label no worker3.user01.ezfab.local \"hpe.com/dataplatform\"=\"true\" NOTE You\n          need at least three storage nodes in your cluster that meet this requirement. This\n          is not required for all nodes. Refer to the section A (above) for details about the\n          required configuration for each storage node. C. (Air-Gapped Only) Inject HPE Ezmeral Unified Analytics Software images into your local repository For an air-gapped installation, you must inject the HPE Ezmeral Unified Analytics Software images into a local\n        repository that you will use to bootstrap the installation process. For this purpose: HPE recommends having an empty dedicated image registry. You can also use an existing\n            image registry with other pre-existing images. Run the HPE Ezmeral Airgap Utility from a\n            connected host. The Airgap Utility connects to the HPE Greenlake image repository\n            marketplace to download the images into your local registry. To inject images into\n              your local repository, create a local registry (optional) and download the\n                images (required) : (Optional) Create a local registry. You\n              have many options to create a local registry. If you already have a registry or want\n              to follow your own procedure to set one up, skip to step 2 (Download Images). The registry can be hosted on a container, virtual machine, or BareMetal. This\n              document describes how to set up a registry inside a container using the podmanutility . The container OS is RHEL8. To create a local\n              registry, complete the following steps: On a fresh RHEL BareMetal/VM, deploy all the utilities required to create the\n                  container: yum module enable -y container-tools:rhel8\n\nyum module install -y container-tools:rhel8 Install the additional dependencies required for the\n                  process: yum install -y httpd-tools jq wget Create the following directories: certs/: stores certificates to enable https access to the registry auth/: authentication files for the registry data/: location where the registry stores all the images To create the\n                        directories,\n                        run: mkdir -p /local_registry/{certs, auth, data} Later,\n                        you will mount these directories to the registry container. (Optional) Create self-signed certificates. Complete this step to make your\n                  registry accessible through HTTPS. You can also use a company-wide certificate. In\n                  that case, simply copy your certificate to the local_registry/certsdirectory and skip to the next step. NOTE You can use the same certificate across more than one registry. There are many ways to use openssl to create a\n                    self-signed certificate, for example: openssl req -newkey rsa:4096 -nodes -sha256 -keyout <$KEY_FILE_LOCATION> -x509 -days 365 -subj \"/CN= <$CERTIFICATE_NAME> \" -addext \"subjectAltName = DNS: <$FULL_DNS> \" -out <$CRT_FILE_LOCATION> //Example:\nopenssl req -newkey rsa:4096 -nodes -sha256 -keyout /local_registry/certs/domain.key -x509 -days 365 -subj \"/CN=Myname\" -addext \"subjectAltName = DNS:*.example.com\" -out /local_registry/certs/domain.crt You must copy this certificate file to the standard location of the\n                    operating system. For RHEL, the standard cert location is /etc/pki/ca-trust/source/anchors : cp /local_ registry/certs/domain.crt /etc/pki/ca-trust/source/anchors/ After you copy the file, run: update-ca-trust Create access credentials to the registry to keep it secure. You can skip this\n                  step for anonymous\n                  access. htpasswd -bBc /local_registry/auth/ <$PASSWORD_FILENAME> <$USERNAME> <$PASSWORD> //Example:\nhtpasswd -bBc /local_registry/auth/htpd user01 admin123 Expose the registry on port 5000. Add this rule to firewalld to\n                  open the port and make it\n                  available. firewall-cmd --zone=public --permanent --add-port=5000/tcp \nfirewall-cmd reload Create the container to use as local registry. In this example, podman is used to create the container; however, you can use\n                  any container utility that you prefer: podman run -d --name <$REGISTRY NAME> -p <$PORT>:<$PORT> \\ \n-v <$DATA_DIRECTORY> :/var/lib/registry:z \\ \n-v <$AUTH_DIRECTORY> :/auth:z \\ \n-v <$CERT_DIRECTORY> :/certs:z \\ \n-e \"REGISTRY_AUTH=htpasswd\" \\ \n-e \"REGISTRY_AUTH_HTPASSWD_REALM= <$REALM_NAME> \" \\ \n-e \"REGISTRY_HTTP_SECRET= <$PHRASE_FOR_SECRET> \" \\ \n-e \"REGISTRY_AUTH_HTPASSWD_PATH= <$PATH_TO_AUTH_FILE> \" \\ \n-e \"REGISTRY_HTTP_TLS_CERTIFICATE= <$PATH_TO_CERT_FILE> \" \\ \n-e \"REGISTRY_HTTP_TLS_KEY= <$PATH_TO_KEY_FILE> \" \\ <$REGISTRY_IMAGE> //Example:\npodman run -d --name local-registry -p 5000:5000 \\ \n-v /local_registry/data:/var/lib/registry:z \\ \n-v /local_registry/auth:/auth:z \\ \n-v /local_registry/certs:/certs:z \\ \n-e \"REGISTRY_AUTH=htpasswd\" \\ \n-e \"REGISTRY_AUTH_HTPASSWD_REALM=my-local-registry\" \\ \n-e \"REGISTRY_HTTP_SECRET=ALongRandomSecretForLocalRegistry\" \\ \n-e \"REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpd\" \\ \n-e \"REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt\" \\ \n-e \"REGISTRY_HTTP_TLS_KEY=/certs/domain.key\" \\ \ndocker.io/library/registry:2 Use curl to access the registry and test that the registry is\n                  up and running: curl  -u <$USERNAME>:<$PASSWORD> -k -X GET https://$(hostname -f):5000/v2/_catalog \n\n//Example:\ncurl -u user01:admin123 -k -X GET https://local-registry.example.com:5000/v2/_catalog (Required) Download the images. To download the images, refer\n              to Using the Air Gap Utility for information about pulling HPE Ezmeral Unified Analytics Software images into\n              the local registry. D. (Air-Gapped Only) Apply the image registry certificate You can configure your air-gapped registry with HTTP or HTTPS (see previous steps).\n        To make it accessible using the HTTPS protocol, you need to add a certificate to the\n        registry. This certificate can be a self-signed certificate (see previous steps) or a\n        company-wide common certificate. The same certificate can be used for multiple registries.\n        If there are multiple registries and all of them are configured with different certificates,\n        the OpenShift configuration should be updated with all the certificates. Follow this\n        procedure to update the registry certificate on your OpenShift cluster. Create a config map with all the certificates for accessing multiple\n        registries. The following syntax shows how to create one config map with\n        one registry and one\n        certificate. kubectl create -n openshift-config cm <$REGISTRY_CONFIG_NAME> --from-file= <$REGISTRY_URL_WITHOUT_PROTOCOL> = <$CERTIFICATE_FILENAME> If\n        you have more than one registry and more than one certificate, run this instead: kubectl create -n openshift-config cm <$REGISTRY_CONFIG_NAME> \\ \n      --from-file= <$REGISTRY_URL_WITHOUT_PROTOCOL> = <$CERTIFICATE_FILENAME> \\ \n      --from-file= <$REGISTRY_URL_WITHOUT_PROTOCOL> = <$CERTIFICATE_FILENAME> //Example: \nkubectl create -n openshift-config cm image-registry-config --from-file=image-registry.example.com=registry.crt \nkubectl create -n openshift-config cm multiple-registry-config -\\\n      --from-file=image-registry.example.com=registry.crt \\ \n      --from-file=image-registry.example.com..5000=registry.crt \\ \n      --from-file=new-image-registry.example.com=newCert.crt Once the configmap is available, patch that configmap with the\n        existing OpenShift config: kubectl patch image.config.openshift.io cluster --type merge -p '{\"spec\":{\"additionalTrustedCA\":{\"name\":\" <$REGISTRY_CONFIG_NAME> \"}}}' \n\n//Example: \nkubectl patch image.config.openshift.io cluster --type merge -p '{\"spec\":{\"additionalTrustedCA\":{\"name\":\" multiple-registry-config \"}}}' E. Install the CertManager Install the cert manager on the OpenShift cluster. The version should be higher than 1.10. To install CertManager,\n        run: kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.1/cert-manager.yaml Install HPE Ezmeral Unified Analytics Software with the Installer Web UI To install HPE Ezmeral Unified Analytics Software on OpenShift through the Installer Web UI, complete the followign steps: Run the installation script that was provided with the software bundle. The host on\n            which you run this command must be connected to the internet (the Web UI image is public\n            for the specific version of HPE Ezmeral Unified Analytics Software that you are installing) or must point to a local registry where\n            you pre-pulled the Web UI image. Running the installation script opens the launcher\n              that guides you through the prompts to start the Installer Web UI. For a connected environment,\n                run: ./start_ezua_installer_ui.sh For an air-gapped environment, run the following command and provide the\n                URL of the image repository that you configured as a\n                prerequisite: ./start_ezua_installer_ui.sh --image <$PRIVATE_REGISTRY> /us.gcr.io/mapr-252711/hpe-ezua-installer-ui Copy the OpenShift kubeconfig to the UI installer container. The\n              UI installer is a container that accesses the OpenShift cluster via kubectl commands. You must give the UI installer container kubectl access to the OpenShift cluster. In a connected environment, you can download the OpenShift kubeconfig from the OpenShift console. In an air-gapped environment, use the kubeconfig that was generated during\n              installation. Once you have the kubeconfig , run the following command to\n                  place it in the container running the HPE Ezmeral Unified Analytics Software Web UI Installer (located at ~/.kube/config ): docker cp < $PATH_TO_KUBECONFIG> <$CONTAINER_ID> :/root/.kube/config Update the hosts entries in the Web UI Installer so it can reach the OpenShift\n                    cluster. In a connected environment , you can find the hosts entries of your\n                      OpenShift cluster in the OpenShift console. In the OpenShift console, go to Clusters on the left and then select the cluster on which you are\n                      installing HPE Ezmeral Unified Analytics Software . Under the Installation Progress card, click Not Able to\n                        Access the Web Console? . In the dialog that opens, copy the list of\n                          hosts: Example: Screenshot from the\n                          OpenShift console that shows the hosts of an example OpenShift\n                          cluster. In an air-gapped environment , copy the DNS entries (used during\n                      installation) to the Web UI Installer: To exec into the Web UI Installer container,\n                          run: docker exec --it <$CONTAINER_ID> bash Edit the /etc/hosts file and add the host entries. Navigate back to the launcher that opened when you ran the installation script to\n            start the Installer Web UI. Select Install in the OpenShift tile. On the OpenShift Setup screen, upload your OpenShift kubeconfig and then\n            click Next . See Installing on User-Provided Hosts (Connected and Air-gapped Environments) to continue installation, starting with Installation Details on that\n              page. TIP If installation fails, you can access the Installer Web UI logs\n              in the live container at /root/ezua-installer-ui/log. On this page A. Verify that the VMs (nodes) in the OpenShift cluster meet the installation\n        requirements B. Apply labels to the storage nodes C. (Air-Gapped Only) Inject HPE Ezmeral Unified Analytics Software images into your local repository D. (Air-Gapped Only) Apply the image registry certificate E. Install the CertManager Install HPE Ezmeral Unified Analytics Software with the Installer Web UI Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/install-openshift.html",
        "title": "Installing HPE Ezmeral Unified Analytics Software on OpenShift"
    },
    {
        "content": "\nHPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Service Activation and Billing in Connected Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in a connected environment,     including activation steps. Service Activation and Billing in Air-Gapped Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in an air-gapped environment,     including activation steps. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. HPE Ezmeral Unified Analytics Software Service\n    Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and\n    air-gapped environments. When you install HPE Ezmeral Unified Analytics Software through the installation wizard, you have the option to install in a\n      connected environment or air-gapped environment. The activation and billing processes differ\n      for each type of installation. In a connected environment, billing is an automated process. In\n      an air-gapped environment, the billing process is manual and requires an activation code in\n      addition to an activation key. After you install and deploy HPE Ezmeral Unified Analytics Software , the system provides you with a URL to access Unified Analytics . The first time you go to the URL,\n      the system prompts you for an activation key (and an activation code for air-gapped\n      environments) to activate the product. The following sections provide the information needed to get the activation key and\n      activation code (for air-gapped environments). When you have those, you can return to the Unified Analytics URL and enter the activation\n      key to activate Unified Analytics . IMPORTANT HPE Ezmeral Unified Analytics Software services only work with a valid activation key and activation code\n          (for air-gapped environments). Services are deactivated if the activation key and/or\n          activation code become invalid, for example, if contractual obligations are not\n        met. Service Activation and Billing in Connected Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in a connected environment,     including activation steps. Service Activation and Billing in Air-Gapped Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in an air-gapped environment,     including activation steps. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/service-activation.html",
        "title": "HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes"
    },
    {
        "content": "\nService Activation and Billing in Connected Environments Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Service Activation and Billing in Connected Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in a connected environment,     including activation steps. Service Activation and Billing in Air-Gapped Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in an air-gapped environment,     including activation steps. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Service Activation and Billing in Connected Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in a connected environment,\n    including activation steps. An administrator needs the following information to activate Unified Analytics in a connected environment: Information Description Platform\n                  ID Unique, system-generated ID assigned to the Ezmeral Coordinator instance during installation. The ID is displayed when\n                    you go to the Unified Analytics URL provided after installation. Activation key The license file that the administrator uploads to complete the installation\n                  of Unified Analytics . The\n                  administrator can download the activation key in their MY\n                    HPE SOFTWARE CENTER customer portal. The activation key file is a signed\n                  XML file. Service activation and billing in connected environments is mostly automated. The only\n        manual process that the administrator performs is going to MY HPE SOFTWARE\n          CENTER and downloading the activation key file and then uploading the file into Unified Analytics to activate the product.\n        The activation key is valid for the length of the contract, typically one, three, or five\n        years unless the contract is made invalid, such as product cancellation or failure to meet\n        the contractual agreement. To activate Unified Analytics , an\n        administrator completes the following steps: Install and deploy Unified Analytics .\n            For connected environments, select the Connected option during installation. The system\n            provides the URL to access Unified Analytics . Go to the Unified Analytics UI URL\n            provided. The window displays a Platform ID and requests an activation key. You cannot\n            proceed with activation until you provide the activation key file. Copy the unique Platform ID. After purchasing HPE Ezmeral Unified Analytics Software , the activation key is made available to you through the Activate your products button in the HPE Subscription Electronic Receipt email that you receive from HPE. This receipt directs you to MY HPE\n              SOFTWARE CENTER where you can activate your product. On the Activate EON page, enter the Platform ID (copied in step 3) in the Platform ID\n            field. Once activation is completed, download the Unified Analytics activation key file. Return to the Unified Analytics URL and\n            upload the activation key file. Billing Process in Connected Environments When the activation key is uploaded, the cluster registers with the HPE billing service.\n        Consumption data is uploaded to the HPE billing service on an hourly basis. Consumption data\n        is based on the vCPU used by applications every hour. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/connected-service-activation.html",
        "title": "Service Activation and Billing in Connected Environments"
    },
    {
        "content": "\nService Activation and Billing in Air-Gapped Environments Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Service Activation and Billing in Connected Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in a connected environment,     including activation steps. Service Activation and Billing in Air-Gapped Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in an air-gapped environment,     including activation steps. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Service Activation and Billing in Air-Gapped Environments Provides information for administrators about HPE Ezmeral Unified Analytics Software activation and billing in an air-gapped environment,\n    including activation steps. An administrator needs the following information to activate Unified Analytics in an air-gapped environment: Information Description Platform\n                  ID Unique, system-generated ID assigned to the Ezmeral Coordinator instance during installation. The ID is displayed when\n                    you go to the Unified Analytics URL provided after installation. Activation key The license file that the administrator uploads to complete the installation\n                  of Unified Analytics . The\n                  administrator can download the activation key in their MY\n                    HPE SOFTWARE CENTER customer portal. The activation key file is a signed\n                  XML file. Activation code A unique code that HPE Ezmeral Customer Support gives to the administrator\n                  every 30 days to keep clusters in an active state. Automatically deactivated after\n                  45 days (includes a 15-day grace period). The activation code file is a signed\n                  JSON file. See Billing Process in Air-Gapped Environments and Renewing the Activation Code . Service activation and billing in an air-gapped environment requires an activation key file\n        and an activation code. The activation code must be renewed on a monthly basis (every 30\n        days). See Billing Process in\n          Air-Gapped Environments . Getting the Activation Key File and Activation Code To get the activation key: Install and deploy Unified Analytics .\n            For air-gapped deployments, select the Air-Gapped option during installation. The system\n            provides the URL to access Unified Analytics . Go to the Unified Analytics URL\n            provided. The window displays a Platform ID and requests an activation key and\n            activation code. You cannot proceed with the activation until you provide the activation\n            key file and activation code. Copy the unique Platform ID. After purchasing HPE Ezmeral Unified Analytics Software , the activation key is made available to you through the Activate your products button in the HPE Subscription Electronic Receipt email that you receive from HPE. This receipt directs you to MY HPE\n              SOFTWARE CENTER where you can activate your product. On the Activate EON page, enter the Platform ID (copied in step 3) in the Platform ID\n            field. Once activation is completed, download the Unified Analytics activation key file. Return to the Unified Analytics URL and\n            upload the activation key file. To get the first activation code to activate Unified Analytics : To request the activation code, open a support case at https://support.hpe.com using the account you have on the HPE Support Center\n            customer portal. The support ticket must include the following information: Activation key Platform ID Cluster ID TIP This is the same portal that you would\n                  use to create any kind of ticket related to your platform. If you do not have an\n                  account, you can create an account for free. When you create an account, you must\n                  link your support contract to the account. If you have never used the customer\n                  portal, refer to the KB article here to help you get your support portal\n                  account up and running. When support notifies you that the activation code is available in your customer\n            portal, go to the portal and get the code. Return to the Unified Analytics URL and\n            upload both the activation key and activation code files. Billing Process in Air-Gapped Environments Contracts for air-gapped installations must be validated with an activation code on a\n        monthly basis. The Unified Analytics cluster\n        securely stores billing data. The Unified Analytics site administrator must download the billing data at the end of the\n        billing cycle and then open an HPE Support Center customer support ticket to renew the\n        activation code. The support ticket that the administrator opens must include the following\n          information: Billing data (downloaded from the Billing tab in Unified Analytics ) Cluster ID HPE Support Center renews the certificate and credentials through the billing and\n        registration system and then uploads the new activation code to your customer portal. This\n        cycle continues on a monthly basis to keep clusters active. Failure to adhere to this\n        process can result in cluster deactivation or service disruption. Unified Analytics provides regular updates and\n        reminder alerts on the product screen. Renewing the Activation Code To get a new activation code (every 30 days), complete the following steps: Sign in to Unified Analytics . In the left navigation bar, select Administration > Settings . Click the Billing tab. On the Billing tab, download the billing data for the current billing\n            cycle. Open a support case at https://support.hpe.com using the account you have on the HPE\n            Support Center customer portal and include the following information: Cluster ID Billing data file When support updates the ticket, go to your customer portal to get the new activation\n            code. Return to Unified Analytics , and enter\n            the activation code in the Activation Code field on the Billing tab. IMPORTANT Failure to complete these steps monthly can result in access to the Unified Analytics applications and\n              services being disabled. On this page Getting the Activation Key File and Activation Code Billing Process in Air-Gapped Environments Renewing the Activation Code Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/airgapped-service-activation.html",
        "title": "Service Activation and Billing in Air-Gapped Environments"
    },
    {
        "content": "\nUsing the Air Gap Utility Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. IMPORTANT The README.txt file included with the product provides instructions for\n        downloading and extracting the HPE Ezmeral Unified Analytics Software binaries that are required to install the product, including the Air\n        Gap Utility. If you downloaded and extracted the files, as described in the README.txt file,\n        you should have the Air Gap Utility. Requirements The Air Gap Utility has the following requirements: Python 2.7 3.6 and above Operating System At minimum: RHEL 8 SLES 15 Rocky Linux 8 Scopeo At minimum: For RHEL or Rocky Linux: Skopeo 0.1.40 For SLES: Skopeo 0.1.41 About the Air Gap Utility HPE Ezmeral Unified Analytics Software provides a\n        utility you can use to query, filter, and download all air gap container images necessary\n        for your environment to a local filesystem or remote registry. Installing the Air Gap Utility Package Before downloading files for your air gap environment, you must first install the air gap\n        script package. You can install the package on any non-platform host, even outside the\n        platform installation. Python 2.7 or Python 3.6 and greater is required for\n        installation. To install the air gap utility package: Install Skopeo. In the CLI, enter the following: For RHEL: dnf install -y skopeo For SLES: zypper install -y skopeo Install the hpeairgaputil package: PIP2: pip install hpeairgaputil-1.5.3-py2.py3-none-any.whl PIP3: pip3 install hpeairgaputil-1.5.3-py2.py3-none-any.whl TIP To uninstall hpeairgaputil , use: PIP2: pip uninstall hpeairgaputil-1.5.3-py2.py3-none-any.whl PIP3: pip3 uninstall hpeairgaputil-1.5.3-py2.py3-none-any.whl Using Air Gap Utility Filters After installing the air gap utility package, you can filter the available apps for a given HPE Ezmeral Unified Analytics Software version in a\n        project. You must provide one of the following mandatory arguments in each of your commands: --list_releases --release TIP To display a list of options available in the ezua-airgap-util , use the following\n              command: ezua-airgap-util --help You can use filters to display the following information: NOTE The system output in the\n          following examples are for illustration only, and might not represent the software\n          available for your release of HPE Ezmeral Unified Analytics Software . Release: List all releases with the following\n            command: ezua-airgap-util --list_releases Images : List all the images for a particular\n              release: ezua-airgap-util --release <release-number> List available images without\n                headers: ezua-airgap-util --release <release-number> --noheaders List all required\n                images: ezua-airgap-util --release <release-number> --required List all optional\n                images: ezua-airgap-util --release <release-number> --optional List components: List all the components that are available for a particular\n            release: ezua-airgap-util --list_components --release <release-number> Component: List all images for a particular\n            component: ezua-airgap-util --release <release-number> --component <component> Size: Valid values include b , kb , mb , and gb . Display images less than a certain\n                size: ezua-airgap-util --release <release-number> --lessthan 1mb Display images greater than a certain\n                size: ezua-airgap-util --release <release-number> --greaterthan 5gb Display images between two\n                sizes: ezua-airgap-util --release <release-number> --lessthan 6gb --greaterthan 5gb You can combine filters to provide a more customized query, for\n            example: ezua-airgap-util --release <release-number> --component falco To filter for a specific name or string, you can use the options \u2013noheaders | grep\n              <String> : ezua-airgap-util --release <release-number> --noheaders | grep <String> Downloading Air Gap Files After Using Air Gap Utility Filters to find the necessary files for\n        your deployment, download the files as follows: Use a single command to filter and copy air gap files to a local filesystem or remote\n            registry. Include all filters you want to apply to your download. Include --dest_compress to compress the files and download in a .tgz file.\n            Otherwise, the files download in a .tar file. For\n            example: ezua-airgap-util --release <release-number> --lessthan 1mb --copy --dest_path images/ --dest_compress Use --force to delete the .tgz or .tar file of the image if it already\n            exists. For\n              example: ezua-airgap-util --release <release-number> --lessthan 1mb --copy --dest_path images/ --force\nezua-airgap-util --release <release-number> --lessthan 1mb --copy --dest_path images/ --dest_compress --force To copy multiple images to a local filesystem, run the following command.\n                Provide the destination path where you want to store your\n                files. ezua-airgap-util --release <release-number> <add-on_filters> --copy --dest_path <destination-path> To copy a single image to a local filesystem, execute the following\n                command. Provide the destination path where you want to store your\n                files. ezua-airgap-util --release <release-number> --image <image-name> --copy --dest_path <destination-path> To copy multiple images to a remote container registry, select one of the\n                following options. Provide the destination URL and credentials for your container\n                  registry. Use the --dest_creds <username:password> command line\n                    option: ezua-airgap-util --release <release-number> <add-on-filters> --copy --dest_url <destination-url> --dest_creds <username:password> Alternatively, set environment variable AIRGAP_UTIL_CREDS .\n                    You can set environmental variables using the export command: export AIRGAP_UTIL_CREDS=<username>:<password> To copy a single image to a remote container registry, execute the\n                    following command. Provide the destination URL and credentials for your\n                    container\n                    registry. ezua-airgap-util --release <release-number> --image <image-name> --copy --dest_url <destination-url> --dest_creds <username:password> Air Gap Utility Logging By default, the Air Gap Utility creates a logs/ directory in the present\n        working directory from which you invoked the Air Gap Utility command line. You can change the log directory location as follows: If you pass the --logdir argument in the Air Gap Utility command\n            line, then the Air Gap Utility creates a logs/ directory in the path\n            provided in the --logdir arguement. If you set the AIRGAP_UTIL_LOGDIR environment variable, but do not\n            pass the --logdir argument in the Air Gap Utility command line, then\n            the Air Gap utility creates a logs/ directory in the path set in the AIRGAP_UTIL_LOGDIR environment variable. NOTE The Air Gap Utility does not create log files when commands are run in TTY mode. For\n              example: ezua-airgap-util --release v1.3.0 | grep -i airflow Using Skopeo --options with the Air Gap Utility This section describes how to use Skopeo --options with the Air Gap\n        Utility and provides usage examples. The following examples show the Skopeo --preserve-digests and --retry-times options used with the Air Gap\n        Utility: ezua-airgap-util --release v1.3.0 --image longhornio/livenessprobe:v2.9.0 --copy --dest_path ezua-v1.3.0/ --options=\"--preserve-digests\" zua-airgap-util --release v1.3.0 --image longhornio/livenessprobe:v2.9.0 --copy --dest_path ezua-v1.3.0/ --options=\"--retry-times 5\" You\n        can use multiple Skopeo options with the Air Gap Utility. The following example demonstrates how to use the Skopeo --preserve-digests and --retry-times options\n        together: ezua-airgap-util --release v1.3.0 --image longhornio/livenessprobe:v2.9.0 --copy --dest_path ezua-v1.3.0/ --options=\"--preserve-digests --retry-times 5\" On this page Requirements About the Air Gap Utility Installing the Air Gap Utility Package Using Air Gap Utility Filters Downloading Air Gap Files Air Gap Utility Logging Using Skopeo --options with the Air Gap Utility Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/airgap-utility.html",
        "title": "Using the Air Gap Utility"
    },
    {
        "content": "\nPorts Used by HPE Ezmeral Unified Analytics Software Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Installing on User-Provided Hosts (Connected and Air-gapped Environments) Provides the steps for installing HPE Ezmeral Unified Analytics Software on user-provided hosts in connected and     air-gapped environments. A user-provided host is a bare metal machine or virtual machine (VM) that meets the     installation prerequisites. Installing HPE Ezmeral Unified Analytics Software on OpenShift Provides the prerequisites and steps for installing HPE Ezmeral Unified Analytics Software in an OpenShift cluster     and also lists the current limitations. HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes Provides post-installation steps required to activate HPE Ezmeral Unified Analytics Software in connected and     air-gapped environments. Using the Air Gap Utility Describes how to use the Air Gap Utility to download files in an air-gapped HPE Ezmeral Unified Analytics Software environment. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Ports Used by HPE Ezmeral Unified Analytics Software Lists and describes the ports used by HPE Ezmeral Unified Analytics Software . Kubernetes Ports Ports Purpose 80, 443 Ingress traffic into the cluster 6443 kube apiserver 2379-2380 etcd 10250 kubelet 10248 kubelet (healthz endpoint) 10249 kube-proxy (metrics) 10256 kube-proxy (health check) 10259 kube-scheduler 10257 kube-controller-manager 9099 calico-node 9100 Node exporter service 30000-32767 NodePort Services Installer Host Ports TIP The installer automatically opens ports if the firewall is disabled. Ports Purpose 8080 Installer UI On this page Kubernetes Ports Installer Host Ports Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Installation/ua-ports.html",
        "title": "Ports Used by HPE Ezmeral Unified Analytics Software"
    },
    {
        "content": "\nIdentity and Access Management Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . HPE Ezmeral Unified Analytics Software uses Keycloak\n      as its OIDC provider for identity and access management. Keycloak secures access to HPE Ezmeral Unified Analytics Software and applications\n      through authorization, authentication, and SSO protocols. Users authenticate to Keycloak\n      instead of authenticating to multiple application services. The following steps describe the basic access flow for a user signing in to HPE Ezmeral Unified Analytics Software application\n        services: A user goes to the application URL with their web browser. If the user has not yet signed in to an application in this cluster, the user's browser\n          is redirected to a sign-in page that is managed by the cluster's Keycloak instance. The user enters their credentials (username and password) at the sign-in page. Keycloak verifies the user's credentials against those in the organization's AD/LDAP\n          server. If the provided credentials are valid, the user's browser is redirected to the\n          originally requested application URL. The browser receives one or more cookies. The\n          cookies represent active sessions with Keycloak and the application. The application is (through a secure back channel) provided with an access token that\n          encapsulates the user's authentication and their authorized roles within the cluster. The application internally uses the access token to determine the user's identity and\n          authorization. Some applications may also use this token to communicate with other\n          services within the cluster. Once a user signs in to HPE Ezmeral Unified Analytics Software , SSO enables the user to seamlessly switch between different\n      authentication-requiring application services while the session is valid. For example, the\n      user can open the Feast application without reentering their credentials. However, if the user\n      signs out of HPE Ezmeral Unified Analytics Software and\n      then tries to access the Feast endpoint URL, the OIDC provider (Keycloak) prompts the user to\n      reenter their credentials. If the browser is left idle in the main interface for more than one hour, the user is\n      automatically signed out. If more than one week has passed since the user has authenticated,\n      the user must re-enter credentials. Architecture The following diagram shows two access flows; one for application A and one for application\n        B. Application A is an OIDC-native application that understands how to integrate with a\n        provider such as Keycloak for user authentication and authorization. Application B is not an\n        OIDC-native application. The auth proxy interacts with Keycloak to ensure that access to application B is only\n        available to authenticated users. The proxy also provides information about user identity\n        and roles to application B through HTTP headers. Note that although application A is OIDC-native, it also sits behind the auth proxy. This\n        ensures that, regardless of how the application itself manages sessions and access tokens, a\n        user will be immediately blocked from accessing the application if an admin has revoked the\n        user's cluster access. The following sections describe the components in the access flow diagram: Ingress Istio provides the service mesh, request routing, policy enforcement, and the\n                proxies used to intervene in service requests. The Istio Ingress gateway performs TLS termination for all incoming traffic and\n                validates JSON Web Tokens (JWTs) issued by Keycloak. External client access to\n                application services is TLS-terminated at the Istio Ingress gateway, then routed to\n                internal service endpoints with mutual TLS encryption. Internal service\n                communications also use TLS. Communication to internal services (from the gateway or from applications) is\n                policy-restricted to a set of allowed clients. The clients are identified by SPIFFE\n                credentials. Istio and SPIRE manage the SPIFFE credentials. Routing Istio routes traffic from the Ingress gateway to the appropriate application\n                service based on the DNS name destination of the traffic. During HPE Ezmeral Unified Analytics Software installation,\n                the administrator can set up a DNS domain that includes the entire sub-domain DNS\n                (sub-domain wild card A record) to route all domain traffic to the Ingress of the\n                application environment. Auth Proxy (Oauth2 Proxy) Oauth2 Proxy gates access to applications that are not OIDC aware. It gives those\n                applications information about the user's token and claims in the token by inserting\n                header values (individual claim values as well as the entire token). The primary\n                header values populated by the proxy are: Authorization, from \"Bearer\" prefixed to the entire token in JSON Web Token\n                    (JWT) format X-Auth-Request-Preferred-Username, from the preferred_username claim X-Auth-Request-Email, from the email claim X-Auth-Request-Groups, from the groups claim (Some additional headers are populated with the same username and groups values\n                for backwards compatibility reasons.) Oauth2 Proxy is also used with OIDC-native apps in order to promptly and\n                universally enforce administrative revocation of user access. Oauth2 Proxy hooks into application traffic through Istio authorization policies.\n                The Istio authorization policy forces traffic to go through the proxy before\n                accessing services in HPE Ezmeral Unified Analytics Software . OIDC Client An OIDC client provides a set of API endpoints used for interactions with the OIDC\n                provider, such as authenticating users. The OIDC client instance used by browser-accessed applications in an HPE Ezmeral Unified Analytics Software cluster is\n                represented by the ID ua and a unique generated secret. This secret\n                is passed to application installation scripts during initial setup, then stored in a\n                Kubernetes secret for later use in deploying applications that you import into HPE Ezmeral Unified Analytics Software . For any OIDC-native application that integrates with this OIDC client, Keycloak\n                must be configured to be aware of an application-specific \"callback URL\" that will\n                be used as part of the OIDC flow. For applications imported after initial setup, you\n                must modify Keycloak's list of allowed callback URLs using the Keycloak web\n                interface or REST API. A separate OIDC client with the ID ua-grant (no client secret) is\n                available, which can be used from a CLI or program to directly exchange user\n                credentials for tokens. This client implements the resource owner password\n                  credentials grant flow, or what Keycloak documentation calls Direct Access\n                  Grant . The ua-grant OIDC client is used for two main purposes, both of\n                which apply to REST APIs (or other non-browser service endpoints) exposed to\n                out-of-cluster users: If the service requires token-based authentication, the out-of-cluster caller\n                    can use the ua-grant client to obtain a token which is then\n                    provided to the service. Note that it is the caller's responsibility to securely\n                    store and otherwise manage the token. If the service requires username/password authentication, perhaps because of\n                    constraints from existing service clients, the service can use the ua-grant client internally to validate the user and also\n                    obtain a token that can be used to communicate with other cluster services. OIDC Provider (Keycloak) Keycloak sources user information from the internal or external AD/LDAP directory.\n                Keycloak imports user data from the AD/LDAP server on an hourly basis. The following\n                user attributes are mapped from the AD/LDAP server to Keycloak: username email full name NOTE The specific attribute names representing these three items are provided in the\n                AD/LDAP configuration details when the HPE Ezmeral Unified Analytics Software is installed. Users authenticate with Keycloak instead of authenticating with individual\n                applications. Keycloak assigns a special Keycloak ID to each user and supplies\n                applications with tokens in JWT format. Each token contains claims that\n                describe the user's authenticated identity and other attributes. The claims mapped from the AD/LDAP user attributes, respectively, are: preferred_username email name, given_name, and family_name (The latter two formed by splitting \"name\"\n                    at the first space.) The token also contains a groups claim. This claim contains a list of the\n                user's group memberships that are important to Keycloak or to applications.\n                Currently, the only application-significant group is admin , which is present\n                in the groups list if the user has been designated as an Administrator of the\n                cluster. For additional information about Keycloak, including how to access the Keycloak\n                Admin Web Console, refer to the Keycloak Admin Web Console section in Security . Internal/External AD/LDAP See AD/LDAP Servers and Working with Certs and the Truststore . User Management (Management Operator) An administrator manages users through the HPE Ezmeral Unified Analytics Software UI; for example, creating users and\n                assigning roles. These operations result in the creation of custom Kubernetes\n                resources (representing queries and user configuration) that are processed by the\n                backend user management service. This service has credentials for the Keycloak\n                administrative REST API, the Kubernetes API, and (if applicable) the internal LDAP\n                server. Tasks performed by this service include: Accessing the internal LDAP server to create and delete users. Marking a user in Keycloak to enable or disable their ability to authenticate\n                    into the cluster. Assigning roles to users in Keycloak. User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/identity-management.html",
        "title": "Identity and Access Management"
    },
    {
        "content": "\nUser Isolation Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . When an HPE Ezmeral Unified Analytics Software administrator adds a new user to HPE Ezmeral Unified Analytics Software , the system automatically assigns each user a user-designated workspace.\n      User-designated workspaces isolate each user's applications and objects from other users in\n      the cluster. If a user wants to share their work, they can do so by setting access controls\n      directly on the objects they create or by changing the namespace in which their applications\n      run. HPE Ezmeral Unified Analytics Software bundles\n      applications with different isolation mechanisms and assurances. For example, HPE Ezmeral Unified Analytics Software bundles cloud-native\n      applications and open-source web applications. Cloud-native applications such as Kubeflow use\n      namespaces to isolate users, whereas web applications such as open-source Airflow and Superset\n      require customized changes to the open-source code to support user isolation and roles in HPE Ezmeral Unified Analytics Software . Customization\n      entails mapping the HPE Ezmeral Unified Analytics Software user role (member or admin) to permissions in the open-source\n      applications. The following table summarizes user isolation in HPE Ezmeral Unified Analytics Software with regard to HPE Ezmeral Unified Analytics Software user roles (admin and member) and application permission\n      mappings, as well as the result of changing user roles and deleting users on applications and\n        objects: MLflow Airflow Superset Spark Admin Assumes admin role View/Edit access on all experiments Does not have personal models or experiments Assumes admin role View/Edit access on all DAGs Does not have personal DAGs Assumes admin role View/Edit access on all dashboards, datasets, and charts Does not have personal dashboards N/A (no role hierarchy in Spark) Can only view/access personal Spark jobs Member Assumes member role Can only view/access personal experiments No access to other users' experiments and models Assumes custom role (segregated) Must explicitly define own role when creating DAGs to keep private; otherwise,\n                    DAGs are shared Assumes customized AlphaDbAccessed role with added permissions to create\n                    database connections Must explicitly define own role when creating DAGs to keep private; otherwise,\n                    DAGs are shared Can view all dashboards and create charts based on all dashboards. Cannot edit the dashboards N/A (no role hierarchy in Spark; similar to Kubeflow) Can only view/access personal Spark jobs Running in user namespace N/A Yes N/A Yes User role propagation Yes Yes Yes N/A (no role hierarchy in Spark) User deletion Objects remain untouched; only admins have access DAGs remain untouched; only admins have access Objects remain untouched; only admins have access Jobs are removed with the user namespace IMPORTANT Do not modify user roles or permissions in the applications\n        that users access through HPE Ezmeral Unified Analytics Software . Modifying roles or permissions directly in an application can break\n        the mapping between the HPE Ezmeral Unified Analytics Software user role and application permission setting. For example, do not\n        assign an HPE Ezmeral Unified Analytics Software member the Admin role in the Superset application. If you want a user to have admin-level\n        permissions in Superset, add the admin role to the user directly in HPE Ezmeral Unified Analytics Software . Changing a user\u2019s\n        role to admin in HPE Ezmeral Unified Analytics Software grants the user access to the Administration settings in HPE Ezmeral Unified Analytics Software . To edit a user role,\n        see Adding Users . The following topics describe user isolation in more detail for each of the applications that\n      curenntly support user isolation: Defining RBACs on MLflow Experiments Defining RBACs on DAGs Defining RBACs in Superset Running Spark Applications in Namespaces Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/user-isolation.html",
        "title": "User Isolation"
    },
    {
        "content": "\nUser Roles Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . In HPE Ezmeral Unified Analytics Software , a user is\n      either a member or an administrator. The user that installs HPE Ezmeral Unified Analytics Software and applies the license\n      is the platform administrator. After applying the license, the administrator is prompted to\n      sign in using the credentials entered during installation. Once signed in, the administrator\n      can add users. See Adding and Removing Users . Any user added and assigned the admin role can also add and remove users. Users that\n      are not assigned the admin role are members . Members have access to all areas of HPE Ezmeral Unified Analytics Software except for the\n      Administration area. NOTE Admins can only add users that are in the AD/LDAP server. The\n        platform administrator configures AD/LDAP settings for HPE Ezmeral Unified Analytics Software during installation. For additional information,\n        see Installation and AD/LDAP Servers . Administrators Only users assigned the admin role can see and use the Administration area in\n        the left navigation bar. The following list describes the tasks that an admin can perform through the Administration options and provides links to additional information: Settings Upload the activation key and activation code to activate services. See HPE Ezmeral Unified Analytics Software Service Activation and Billing Processes . Update application container images. See Upgrading Included Frameworks . Register an Otel endpoint or view the JDBC endpoint. See Configuring Endpoints and Connect to External Applications via JDBC . Identity & Access Management Add and remove users. See Adding and Removing Users . Data Fabric Connect to HPE Ezmeral Data Fabric clusters. See Connecting to External HPE Ezmeral Data Fabric Clusters . Audit Logs View a chronological set of records that document the events that occur in an HPE Ezmeral Unified Analytics Software cluster. See Audit Logging . More information Adding and Removing Users Adding and Removing Users Programmatically AD/LDAP Servers Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/user-roles.html",
        "title": "User Roles"
    },
    {
        "content": "\nAD/LDAP Servers Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Working with Certs and the Truststore Describes how to provide a truststore with a valid server certificate, including how to     view and locate certs, as well as how to create and validate a truststore for certs. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP\n    servers. Also describes some of the server-related configuration options that you set during\n    installation. When you install HPE Ezmeral Unified Analytics Software , the configuration options vary depending on whether you use the\n      internal OpenLDAP server (default) included with HPE Ezmeral Unified Analytics Software or an external AD/LDAP server. After installation, the designated administrator can sign in and grant users permission to\n      access HPE Ezmeral Unified Analytics Software and\n      assign roles. A user management operator running in HPE Ezmeral Unified Analytics Software sets up local resources for users, such as their user\n      profile and workspace, and also enables access. NOTE SSO does not support applications that use AD/LDAP integration to validate credentials\n            presented to an external service. The AD/LDAP server supports access by PLAIN (unsecured) LDAP, LDAPS, or StartTLS. Do\n            not use PLAIN LDAP in production. If using LDAPS or StartTLS, one or more custom\n            certificates may be needed to validate the server certificate. See Working with Certs and the Truststore . The following sections describe the differences between internal and external AD/LDAP\n      servers: Internal OpenLDAP Server In HPE Ezmeral Unified Analytics Software , the\n        internal directory setup is an OpenLDAP server. Only use the internal directory for POCs and\n        demos; do not use the internal directory in production. If you opt to use the internal directory, during installation you specify the following\n        information to create the administrator in the system: username full name email password The administrator is the initial user that signs in to HPE Ezmeral Unified Analytics Software to add other users\n        and perform administrative tasks. Adding users creates the internal user directory. When you remove a user, the user can no longer access the HPE Ezmeral Unified Analytics Software cluster, and the\n        system clears the local resources. See Adding and Removing Users . External AD/LDAP Server If you select Use\n          External LDAP Server during installation and configure an external directory, HPE Ezmeral Unified Analytics Software references the\n        external AD/LDAP server and gets users from it. When you sign in to HPE Ezmeral Unified Analytics Software , you can search for\n        users, grant access, and assign roles. HPE Ezmeral Unified Analytics Software has the\n      following external AD/LDAP server requirements: The AD/LDAP server must already exist. The AD/LDAP server must be network-accessible to the deployed HPE Ezmeral Unified Analytics Software instance. For AWS deployments, the AD/LDAP server must be accessible to the VPC where the HPE Ezmeral Unified Analytics Software instance runs. The AD/LDAP server must contain user objects with the required attributes. Any addition,\n          removal, or modification of users and their attributes must be done at the AD/LDAP server. The user objects on the external AD/LDAP server must have the following\n                attributes: Username Fullname Email UID GID Group GID These attributes are required to federate users from the AD/LDAP server to\n                Keycloak. User objects obtained from the direct AD/LDAP integration do not contain\n                any role assignments and does not know which users are enabled to use HPE Ezmeral Unified Analytics Software . When you configure the external AD/LDAP server during installation, you specify the\n        following information: How to contact the LDAP server. How to bind to the server to find account information. Truststore for validating the server certificate. Information about how user objects are configured. The following table lists and describes some of the AD/LDAP fields that you configure\n        during installation: Field Description Active Directory If you do not select the Active Directory (AD) option, the possible schemas\n                  are more varied. You must enter additional information to properly describe the\n                  user and group objects. Validation The validation check boxes are for sanity checks before the installation\n                  starts and during the installation process. The validation can detect issues with\n                  the AD integration server before the installation is well underway. Only disable\n                  these options when running the installation container in an environment that\n                  cannot access AD. Search Base DN Must cover both user and group objects. Security Protocol If the security protocol is LDAPS or StartTLS, the server certificate will be\n                  validated. If the server certificate was signed by something other than a known\n                  public CA, a truststore must be provided. A truststore is a JKS file such as those\n                  created by the Java keytool utility. If a provided truststore is password\n                  protected, the truststore password must be supplied. Username Attribute Must contain the name of a user object attribute on the server that contains\n                  a username following some content rules: Starts and ends with a lowercase letter. Contains only lowercase letters and dashes, for example \"hsimpson\" and not\n                      homer.simpson@mycompany.com. Fullname Attribute Must contain the name of a user object attribute on the server that contains\n                  the user's full name. This is typically the name attribute on AD\n                  servers or cn on OpenLDAP servers. Email Attribute Must contain the name of a user object attribute on the server that contains\n                  the user's email address. Each user must have a unique email address. This is\n                  typically the mail attribute on AD or OpenLDAP servers. UID Attribute GID Attribute For non-AD servers, the UID Attribute and GID Attribute fields name user\n                  object attributes that are expected to contain an integer userID or group ID\n                  value. Similarly for the group GID attribute for group objects. Default Admin User Must identify a user that already exists on the server. The value specified\n                  here should be the value of the Username Attribute on that user object. Working with Certs and the Truststore Describes how to provide a truststore with a valid server certificate, including how to     view and locate certs, as well as how to create and validate a truststore for certs. More information Adding and Removing Users On this page Internal OpenLDAP Server External AD/LDAP Server Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/ad-ldap.html",
        "title": "AD/LDAP Servers"
    },
    {
        "content": "\nWorking with Certs and the Truststore Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Working with Certs and the Truststore Describes how to provide a truststore with a valid server certificate, including how to     view and locate certs, as well as how to create and validate a truststore for certs. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Working with Certs and the Truststore Describes how to provide a truststore with a valid server certificate, including how to\n    view and locate certs, as well as how to create and validate a truststore for certs. When you use an external AD/LDAP server, Keycloak verifies the server certificate. If the\n      certificate is not signed by a commonly known certificate authority (CA), you must provide a\n      truststore with the information required to verify that the server certificate is valid. Note the following guidelines and conditions related to certs and the\n      truststore: A truststore is needed for StartTLS or LDAPS connections. Different applications with\n          potentially different default trusted-certificate stores may need to verify the\n          connection, so the means to verify the LDAP server\u2019s certificate must be explicitly\n          provided. A truststore contains the certs required to finish the signing chain \u2013 from the issuing\n          cert mentioned in the cert that the server presents to the trusted self-signed cert. In\n          the case of a self-signed server cert, the chain is the server cert itself. Any truststore that you provide must contain all of the necessary certs. The truststore\n          must be a chain of certs signed by certs that terminate in a self-signed cert. Locating the Certs to put in the Truststore If you do not know which certs need to go into the truststore (possibly due to IT\n        protocols), use openssl to probe the server to see which certs are being\n        presented by the AD/LDAP server. The following commands create the files myserver-cert1.pem,\n          myserver-cert2.pem , and so on. These are the certs presented by the server. The\n        first one is the server cert, followed by any intermediate certs. LDAPS server The following command probes an LDAPS server running at myserver.com on port\n              636 : openssl s_client -showcerts -verify 10 -connect myserver.com:636 < \\ \n    /dev/null | \\ \n    awk '/BEGIN/,/END/{if(/BEGIN/) {a++}; out=\"myserver-cert\"a\".pem\"; print >out}' StartTLS server The following command probes an StartTLS server running at myserver.com on port\n              389 : openssl s_client -showcerts -verify 10 -connect myserver.com:389 -starttls ldap < \\ \n    /dev/null | \\ \n    awk '/BEGIN/,/END/{if(/BEGIN/) {a++}; out=\"myserver-cert\"a\".pem\"; print >out}' Getting the Issuer and Subject from a cert file To get the Issuer and Subject from a cert file, run the following\n                command: openssl x509 -in myserver-cert1.pem -text | grep '\\(Issuer\\|Subject\\)' TIP If there is only one cert and it refers to itself as Issuer, that means it is\n                    a self-signed server cert, and that server cert needs to go into the truststore. If there is a list of Issuers certs, there is typically one Issuer that does\n                    not have a match among the Subjects. That missing Issuer cert is the next link\n                    in the trust chain. You will need to get that cert either by way of the CA, your\n                    IT department, or whoever configured and runs the server. Often the missing\n                    Issuer is a custom root cert, in which case you only have one cert to put in\n                    your truststore. If the missing Issuer is not a root cert and is actually an intermediate cert,\n                    you will need to get the intermediate cert and also get the cert that the\n                    intermediate cert is signed by and continue this process until you get to the\n                    root (self-signed) cert. Creating a Truststore Build the truststore with the Java keytool utility by performing a series\n        of cert imports. Note the following points from the Keystore docs about accepted input cert formats: Keytool can import X.509 v1, v2, and v3 certificates, and PKCS#7 formatted certificate\n            chains consisting of certificates of that type. The data to be imported must be provided either in binary encoding format or in\n            printable encoding format (also known as Base64 encoding) as defined by the Internet RFC\n            1421 standard. In the latter case, the encoding must be bounded at the beginning by a\n            string that starts with \"-----BEGIN\" and bounded at the end by a string that starts with\n            \"-----END\".\" Importing a truststore and setting the password Alias values in the commands are used for readability when dumping the truststore.\n              You can use any alias you choose. The first import creates the truststore. During\n                the first import, you set the password for the truststore. Subsequent imports will\n                ask for this password. To import a self-signed server cert from the servercert.pem file, run the following command: NOTE This is the\n                only command you hae to run for a self-signed\n              certificate. keytool -importcert -alias selfsigned \\ \n    -file servercert.pem -keystore truststore.jks When asked if you want to trust it, respond with yes . Importing a custom root cert and intermediate certs ATTENTION If you follow the instructions to import down the trust\n                chain, you should not be asked whether any of the intermediate certs should\n                be trusted because keytool should be aware of what cert they were signed by. If you\n                get that question when importing an intermediate cert, you may have missed a link in\n                the chain or you are importing in the wrong order. To import a custom root\n              cert and intermediate certs, start by running the following command to import the\n              custom root cert ( root.pem in this\n              example): keytool -importcert -alias root \\ \n    -file root.pem -keystore truststore.jks When asked if you want to trust it, respond with yes . Importing intermediate certs If you have intermediate certs to import, start with the one closest to the root,\n              and work down the signing chain toward the server cert. If your first intermediate\n              cert was signed by a default trusted cert, run the following command to import it\n              (example filename intermediate.pem ): keytool -importcert -trustcacerts -alias intermediate \\ \n    -file intermediate.pem -keystore truststore.jks For any\n                intermediate cert signed by something previously imported into your truststore, run\n                the following command to import it without the trustcacerts argument: keytool -importcert -alias intermediate \\ \n    -file intermediate.pem -keystore truststore.jks Validating a Truststore Run the command appropriate for your server type and then press enter to kill the\n        connection. If the validation is successful, the system returns the following message: Verify return code: 0 (ok) If the truststore is not correct, the system returns the following message: Verify return code: 20 (unable to get local issuer certificate) LDAPS To validate a truststore, run the following command: NOTE The following example\n              validates that a truststore named truststore.jks with password mypass works for an LDAPS server running at myserver.com port 636 as follows: openssl s_client -verify 10 -connect myserver.com:636 \\ \n    -CAfile <(keytool -list -rfc -keystore truststore.jks -storepass mypass) StartTLS To validate a truststore, run the following command: NOTE The following example\n              validates that a truststore named truststore.jks with password mypass works for an LDAPS server running at myserver.com port 389 as follows: openssl s_client -verify 10 -connect myserver.com:389 -starttls ldap \\ \n    -CAfile <(keytool -list -rfc -keystore truststore.jks -storepass mypass) On this page Locating the Certs to put in the Truststore Creating a Truststore Validating a Truststore Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/truststore.html",
        "title": "Working with Certs and the Truststore"
    },
    {
        "content": "\nAdding and Removing Users Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . The user search field is only enabled for HPE Ezmeral Unified Analytics Software installations configured to use an external AD/LDAP directory.\n      The search field does not work for installations using the internal OpenLDAP configuration;\n      however, an admin can still add new users. For an external AD/LDAP directory, complete the following steps to add a user: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Administration > Identity & Access\n            Management . In the search field, enter a substring search on the user's username or email ID and\n          then enable HPE Ezmeral Unified Analytics access. You can also assign the admin role if\n          you want the user to have administrative access in HPE Ezmeral Unified Analytics Software . For the internal OpenLDAP directory, complete the following steps to add a user: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Administration > Identity & Access\n            Management . Click Add User . In the drawer that opens, enter the following information: Username - Enter the username. First Name - Enter the first name of the user. Last Name - Enter the last name of the user. Email ID - Enter the email ID associated with the user. Password - Enter the password for the user. Role - Selecting Administrator assigns the user the administrator role, which\n              gives the user permission to act as an administrator in the HPE Ezmeral Unified Analytics Software UI. If you do\n              not select Administrator, the user is assigned the member role. To remove a user: In the list of users, select the user you want to remove. Click into the Actions column, and click the Delete option. Alternatively,\n          click the Delete button on the screen. The system prompts you to confirm the\n          action. Once you confirm, the user is removed. To edit the role and password for a user: In the list of users, select the user you want to edit. Click into the Actions column, and click the Edit option. In the drawer that opens, change the password and role for the user. Click Update . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/add-users.html",
        "title": "Adding and Removing Users"
    },
    {
        "content": "\nAdding and Removing Users Programmatically Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery\n    and EzUserConfig custom resources. The user management operator in HPE Ezmeral Unified Analytics Software responds to the\n      EzUserQuery and EzUserConfig custom resources when they are created by a client with the\n      required Kubernetes API permissions. Use the administrative kubectl config that you get when you create the HPE Ezmeral Unified Analytics Software cluster to onboard and manage users programmatically\n      through the Kubernetes API. To onboard a user, complete the following steps: Use the EzUserQuery custom resource to search for the user in the internal or external\n          AD/LDAP directory. The EzUserQuery returns a list of attributes for a user, including the\n          Keycloak ID. The Keycloak ID is required to onboard a user. Use the EzUserConfig custom resource to onboard the user. The following sections describe the custom resources: EzUserQuery Use the EzUserQuery custom resource to query the user AD/LDAP directory. The EzUserQuery properties map directly to the query types of the Keycloak user API.\n        Providing values for the email , firstName , lastName , and/or username properties sets criteria that must match the returned users. The search property value is typically the most useful and can match against the email or username . Keycloak returns the query response and the status updates. The query results are bounded\n        and a query only returns up to five results. Narrow your search criteria to reduce the\n        number of results returned. Results show you attributes for the user, for example if they\n        are enabled (true/false), id (keycloak user ID), and role (admin or not). EzUserQuery resources self-delete after they expire. Using the EzUserQuery Custom Resource In a YAML file, add the following properties, specifying your own\n                  values: apiVersion: ezconfig.hpe.ezaf.com/v1alpha1\nkind: EzUserQuery\nmetadata:\n  name: my-query-1\nspec:\n  search: joel To create and get the query, run the following commands, specifying your YAML\n                  file name: kubectl create -f query.yaml\n\nkubectl get ezuserquery A ready status indicates that there are query results. This is the status.status property. To query the AD/LDAP directory, run the following command, specifying your query\n                    name: kubectl get ezuserquery my-query-1 -o yaml The\n                    command returns results similar to those shown in the following image: The userQuery property\n                    displays the user attributes. EzUserConfig Use the EzUserConfig custom resource to enable/disable users and manage user roles. EzUserConfig identifies the user (via keycloak ID) and indicates the roles that a user\n        should have when onboarded. The following table describes the differences between internal and external AD/LDAP servers\n        when using EzUserConfig: AD/LDAP Server Type Description Internal EzUserConfig creates and enables a user. Deleting an\n                  EzUserConfig disables and deletes the user. External EzUserConfig enables a user. EzUserConfig identifies the user (via\n                  Keycloak ID) and sets the user role. Deleting an EzUserConfig disables the user. The EzUserConfig status stanza shows user attributes, whether the user is\n        successfully enabled, the roles that have successfully been assigned, and any error\n        messages. TIP The user management operator actually onboards the user. Enabled is not a role that you can assign to a user. To show existing ezuserconfigs ,\n              run: kubectl get ezuserconfig Using the EzUserConfig Custom Resource In a YAML file, add the following properties, specifying your own\n                  values: apiVersion: ezconfig.hpe.ezaf.com/v1alpha1\nkind: EzUserConfig\nmetadata:\n  name: my-admin-user-1\nspec:\n  id: 04ef844e\n  roles:\n    - admin Note that the ID is the Keycloak ID that you can get using the\n                  EzUserQuery custom resource. To see a list of all the attributes for a user, run the following command,\n                  specifying the name of the user you want to see attributes\n                  for: get ezuserconfig joel -o yaml The command returns\n                  results similar to those shown in the following image: On this page EzUserQuery EzUserConfig Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/onboard-programmatically.html",
        "title": "Adding and Removing Users Programmatically"
    },
    {
        "content": "\nManaging Data Access Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . User Isolation Describes user isolation in HPE Ezmeral Unified Analytics Software . User Roles Describes roles that you can assign to users in HPE Ezmeral Unified Analytics Software . AD/LDAP Servers Describes the differences between the internal OpenLDAP server in HPE Ezmeral Unified Analytics Software and external AD/LDAP     servers. Also describes some of the server-related configuration options that you set during     installation. Adding and Removing Users Describes how administrators can add and remove users in HPE Ezmeral Unified Analytics Software . Adding and Removing Users Programmatically Describes how to add and remove users through the Kubernetes API using the EzUserQuery     and EzUserConfig custom resources. Managing Data Access Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Managing Data Access HPE Ezmeral Unified Analytics Software administrators\n      have unrestricted access to all the data sources and underlying schemas, tables, views, and\n      buckets. Admins can grant members the following types of access to data sources, schemas,\n      tables, views, and buckets. Read Write Read & Write Admins can grant public access to a data source such that all HPE Ezmeral Unified Analytics Software members have full\n      access (read, write, and execute) to all the data within the data source. Alternatively,\n      admins can grant one or more members access to specific schemas, tables, views, or buckets\n      within a data source. Any access granted can also be revoked by an admin. When members do not have access to a data source, the data source appears greyed out on the\n      screen. Members cannot access any of the data within that data source. Any attempts to access\n      the data results in an access denied error. Members should contact their HPE Ezmeral Unified Analytics Software admin to request access\n      to data. The following sections provide the steps for granting and revoking access to data sources,\n      schemas, tables, and views. Granting a Member Access to Data HPE Ezmeral Unified Analytics Software administrators can grant a member access to one or more tables, views, or buckets in a\n        schema. To grant a member access to data, complete the following steps: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Administration > Identity & Access\n            Management . On the Identity and Access Management screen, locate the user. In the Actions column of the user row, click the three-dots and select Manage\n            Privileges . On the Manage Privileges screen, select the Structured Data or Object\n            Store Data tab, depending on the type of data that you want to grant the user access\n          to. Expand a data source and select a schema. In the Datasets area, select the tables, views, or buckets that you want to grant\n          the user access to. You can grant Read , Write or Read & Write access. If you are only granting the user access to a single table, view, or bucket, use the Access Type column dropdown in the row of the table, view, or bucket. If you are granting the user access to multiple tables, views, or buckets, use the Bulk Access dropdown to the right of the Search field, and select the\n              access type you want to grant the user on all of the selected tables, views, or\n              buckets. Click Update Privilege . The system displays the message: Updated\n              privileges for the user: <user-name> Granting All Members Access to a Data Source (Public Access) HPE Ezmeral Unified Analytics Software administrators can make a data source publicly accessible. When an admin makes a data source\n        publicly accessible, all members have full access (read and write) permissions on the data\n        source and the data within it. To make a data source publicly accessible, complete the following steps: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Data Engineering > Data Sources . Select the Structured Data or Object Store Data tab. In the data source tile, click the three-dots. Select Change to public access . In the Data Access dialog, click Proceed or Cancel . If you chose to\n          proceed, the system displays the message: Access changed for the data source:\n              <data-source-name> Revoking Member Access to Data HPE Ezmeral Unified Analytics Software administrators can revoke a member's access to schemas, tables, views, and buckets. Revoking\n        access makes the data inaccessible to the member. To revoke member access to data, complete the following steps: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Administration > Identity & Access\n            Management . On the Identity and Access Management screen, locate the user. In the Actions column of the user row, click the three-dots and select Manage\n            Privileges . On the Manage Privileges screen, select the Structured Data or Object\n            Store Data tab, depending on the type of data that you want to revoke access\n          to. Expand the data source and select the schema that contains the data you want to revoke\n          access to. In the Datasets area, select the tables, views, or buckets that you want to\n          revoke access to. If you are only revoking access to one table, view, or bucket, select No\n                Access in the Access Type column for the table, view, or bucket. If you are revoking access to multiple tables, views, or buckets, select the tables,\n              views, or buckets and then use the Bulk Access dropdown (to the right of the Search field) and select No Access . Click Update Privilege . The system displays the message: Updated\n              privileges for the user: <user-name> Revoking Public Access to a Data Source HPE Ezmeral Unified Analytics Software administrators can revoke all access to a ata source. Revoking public access to a data\n        source makes the data in the data source totally inaccessible to all members. Only admins\n        can access the data source and the data within it. Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Data Engineering > Data Sources . Select the Structured Data or Object Store Data tab. In the data source tile, click the three-dots. Select Change to private access . In the Data Access dialog, click Proceed or Cancel . If you chose to\n          proceed, the system displays the message: Access changed for the data source:\n              <data-source-name> On this page Granting a Member Access to Data Granting All Members Access to a Data Source (Public Access) Revoking Member Access to Data Revoking Public Access to a Data Source Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/data-access-management.html",
        "title": "Managing Data Access"
    },
    {
        "content": "\nExpanding the Cluster Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how\n    to expand the cluster to include the additional user-provided hosts. Expand the cluster when applications cannot run due to resource limitations, such as lack of\n      vCPU. When applications do not have enough resources to run, the system raises an\n      alarm to alert you of the issue. In such cases, the HPE Ezmeral Unified Analytics Software administrator and system administrator can work together\n      to add additional user-provided hosts to the pool of machines in the management cluster\n      (control plane nodes) and workload cluster to increase the processing capacity of the cluster. The following steps outline the cluster expansion process: An application triggers an alert to users that it does not have sufficient resources to\n          run. Users contact the system administrator to request additional resources (add additional user-provided hosts to\n          the management cluster). A system administrator adds user-provided hosts to the cluster, as described in the section Adding User-Provided Hosts to the Cluster . After the system administrator adds user-provided hosts to the cluster, the HPE Ezmeral Unified Analytics Software administrator signs into the HPE Ezmeral Unified Analytics Software UI and expands the\n          cluster, as described in the section Expanding the Cluster . Adding User-Provided Hosts\n        to the Cluster You can only add user-provided hosts to the cluster. User-provided hosts are machines that\n        meet the installation prerequisites, as described in Installation Prerequisites . TIP If you want to use the high-availabilty (HA) feature when you expand the cluster,\n              note that HA requires three master nodes. You must add two hosts to the ezfabric-host-pool with the controlplane role. If you want to increase the VCPU or VGPU resources when you expand the cluster, you\n              must add worker hosts or GPU hosts with enough resources (VCPU or VGPU) to ezfabric-host-pool with the worker role. SSH into the VM that launched the installation UI when you installed HPE Ezmeral Unified Analytics Software . This is the VM\n            that launched the installation UI when you ran the installation UI script\n              ( ./start_ezua_installer_ui.sh ), as described in Run the Installation Script to Access the Installer Web UI . To run a bash session in the UI installer Docker container on the VM, issue the\n            following command: docker exec -it hpe-ezua-installer-ui bash Create a /tmp/expand directory: mkdir /tmp/expand\ncd /tmp/expand Copy the following files into the /tmp/expand directory and create an add_host.yaml file in the /tmp/expand directory: cd /tmp/expand\ncp /tmp/ezkf-orchestrator/mgmt-kubeconfig ./mgmt-kubeconfig\ncp /root/ezua-installer-ui/ezfabricctl_linux_amd64 ./ezfabricctl\ncp /tmp/hostPoolConfig.yaml ./add_host.yaml Edit the /tmp/expand/add_host.yaml file: IMPORTANT Do not change the defaultHostCredentials object. The sshPassword for the defaultHostCredentials must be a base64 encoded string. For example, if your password is abcde12345! , converting it to a base64 encoded string changes\n                  it to YWJjZGUxMjM0NSE= . Under the hosts: object, remove the worker and/or control plane\n                nodes that are listed from any previous action. Add the new worker and/or control planes nodes. In the following example, node\n                  10.10.10.123 is specified as the control plane node being added to the host pool,\n                  and node 10.10.10.223 is being specified as the worker node being added to the\n                  host pool: defaultHostCredentials:\n  sshUserName: root\n  sshPassword: YWJjZGUxMjM0NSE=\n  sshPort: 22\nhosts:\n- host: 10.10.10.123\n  labels:\n    role: controlplane\n- host: 10.10.10.223\n  labels:  \n    role: worker Make ezfabricctl executable: chmod +x ezfabricctl NOTE The ezfabricctl command-line program is available in the installer UI\n              Docker container. The installer UI invokes this program for cluster expansion. To add the new node(s) to the pool, run the following\n            command: ./ezfabricctl poolhost init --input add_host.yaml --kubeconfig mgmt-kubeconfig To check node status: SSH in to the Ezmeral Coordinator . The Ezmeral Coordinator is the node that orchestrates the deployment of HPE Ezmeral Unified Analytics Software instances,\n                  as described in Node Setup . TIP If you need to identify the Ezmeral Coordinator node, run the\n                    following command: kubectl get nodes --kubeconfig <ezmeral-coordinator-kubconfig-file> To verify that the hosts were added to the hosts pool, run the following command: kubectl get ezph -A The system returns output similar to the\n                  following: NAMESPACE               NAME            CLUSTER NAMESPACE     CLUSTER NAME     STATUS     VCPUS   UNUSED DISKS  GPUS\nezfabric-host-pool      10.10.10.1      ezkf-mgmt             ezkf-mgmt        Ready      4\t  2             0\nezfabric-host-pool      10.10.10.223      \t                               Ready      4\t  2             0\nezfabric-host-pool      10.10.10.123       \t                               Ready      4\t  2             0 NOTE In the kubectl command that you run, ezph is the abbreviated version of ezpoolhosts , an Ezmeral resource that runs against the host\n                  pool. Expanding the Cluster In a user-provided host\n        configuration, the hosts within the pool (namespace) must have enough vCPUs and vGPUs for\n        the cluster expansion to succeed. If you request more vCPUs and vGPUs than are available,\n        the cluster expansion will fail. ATTENTION If repeated attempts\n          to expand the cluster fail with an \" already complete \" message, delete any existing\n          EzkfOpsExpand custom resources on the workload cluster before you expand the cluster. To\n            identify the EzkfOpsExpand custom resources, run the following\n            command: kubectl get ezkfopsexpand -A \n# (lists the Expand CR names and namespaces) For each of the EzkfOpsExpand\n            custom resources listed in the output, run the following\n            command: kubectl delete ezkfopsexpand -n <expand_CR_namespace> <expand_CR_name> To expand the cluster, complete the following steps: In the left navigation bar, select Administration > Settings . On the Cluster tab, select Expand Cluster . In the Expand Cluster drawer that opens, enter the following information: Number of additional vCPU to allocate. For example, if the current vCPU is 96 and\n              you add 4 vCPU, the vCPU increases to a total of 100 vCPU. Select Use GPU if you want to use GPU and it is not already selected. If Use GPU was selected during installation of HPE Ezmeral Unified Analytics Software , this option\n              cannot be disabled and stays selected by default. Indicate the additional number of vGPU to allocate. For GPU configuration, if a size was selected during HPE Ezmeral Unified Analytics Software installation,\n              you cannot change the size. However, if no vGPU size was selected during installation,\n              you can select a size now. For additional information, see GPU Support . If HA was selected during HPE Ezmeral Unified Analytics Software installation, you cannot disable it. If it was not selected\n              during installation, you can select it now. Currently HA is available for the workload\n              cluster only. You cannot set HA for the management cluster. Click Expand . Configuring HPE MLDE for Added GPU Nodes If you add GPU nodes to the cluster after installing HPE MLDE , you must perform additional steps to ensure HPE MLDE works on these nodes. For details, see Configuring HPE MLDE for Added GPU Nodes . On this page Adding User-Provided Hosts\n        to the Cluster Expanding the Cluster Configuring HPE MLDE for Added GPU Nodes Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/expand-cluster.html",
        "title": "Expanding the Cluster"
    },
    {
        "content": "\nShutting Down an HPE Ezmeral Unified Analytics Software Cluster Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade\n    tasks. A typical HPE Ezmeral Unified Analytics Software cluster consists of three or more nodes. Three nodes are specifically designated as data\n      fabric nodes. If your cluster has exactly three nodes, you can simply run the edf\n        shutdown cluster command from the admincli pod to gracefully\n      shutdown the HPE Ezmeral Unified Analytics Software cluster, as described in Shutting Down Data Fabric Nodes . If your HPE Ezmeral Unified Analytics Software cluster\n      has more than three nodes, the cluster consists of both data fabric and non-data fabric nodes.\n      In this case, first identify the data fabric nodes and take note, as described in Identifying Data Fabric Nodes . Shut down the non-data fabric nodes using a\n      standard Linux shutdown command or UI power down in the case of AWS, as described in Shutting Down Non-Data Fabric Nodes . Once you have shut down the non-data fabric\n      nodes, run the edf shutdown cluster command from the admincli pod to gracefully shutdown the HPE Ezmeral Unified Analytics Software cluster, as described\n      in Shutting Down Data Fabric Nodes . After you shut down the cluster and perform maintenance or upgrade tasks, restart the\n      cluster, as described in Restarting an HPE Ezmeral Unified Analytics Software Cluster . IMPORTANT HPE Ezmeral Unified Analytics Software does not support graceful shutdown for installations that use the\n        internal directory (OpenLDAP server). Users added to the HPE Ezmeral Unified Analytics Software internal directory\n        (OpenLDAP server) will not persist beyond the shutdown and restart, making it impossible for\n        any user to access the system. Requirements Shutting down an HPE Ezmeral Unified Analytics Software cluster requires: Access to the Kubernetes cluster Admin access in the HPE Ezmeral Unified Analytics Software cluster Identifying Data Fabric Nodes If the cluster consists of more than three nodes, identify the data fabric nodes. The data\n        fabric nodes have a CLDB service running on them. The CLDB service is a proprietary data\n        fabric service that only runs on data fabric nodes. Run the following command to identify the data fabric nodes: kubectl get pods -n dataplatform -o wide| grep cldb Shutting Down Non-Data Fabric Nodes After you have identified the data fabric nodes, run a standard Linux shutdown command or\n        UI power down in the case of AWS. For example, run the following Linux command on the\n        non-data fabric nodes to shut them down: shutdown [OPTIONS] [TIME] [MESSAGE] Shutting Down Data Fabric Nodes Use the edf shutdown cluster command to gracefully shut down the data\n        fabric nodes and reboot pods. The edf shutdown cluster command shuts down\n        the data fabric nodes in an ordered process to prevent certain components from restarting.\n        Pods are immediately put into a wait state after the reboot to prevent them from becoming\n        operational. You must run the edf shutdown cluster command from the admincli pod of the HPE Ezmeral Unified Analytics Software cluster. To log in to the admincli pod and shut down the data fabric nodes, run the\n        following command: kubectl exec -it admincli-0 -n dataplatform -- edf shutdown cluster Restarting an HPE Ezmeral Unified Analytics Software Cluster Complete the following steps to restart the cluster: To log in to the admincli pod and restart the data fabric nodes, run\n            the following command: kubectl exec -it admincli-0 -n dataplatform -- edf startup resume To check the status of the nodes, run the following\n            command: kubectl get pods mcs-0 -n dataplatform When the mcs pod READY column shows 1/1 ,\n            the cluster is fully operational. Power up the non-data fabric nodes. On this page Requirements Identifying Data Fabric Nodes Shutting Down Non-Data Fabric Nodes Shutting Down Data Fabric Nodes Restarting an HPE Ezmeral Unified Analytics Software Cluster Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/graceful-shutdown.html",
        "title": "Shutting Down an HPE Ezmeral Unified Analytics Software Cluster"
    },
    {
        "content": "\nImporting Applications and Managing the Application Lifecycle Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Administrators can import, run, and manage customized Kubernetes applications and frameworks\n      in HPE Ezmeral Unified Analytics Software .\n      Administrators can manage imported applications as well as the applications that were included\n      with HPE Ezmeral Unified Analytics Software at the time\n      of installation. Imported and included applications appear in the Tools & Frameworks screen in HPE Ezmeral Unified Analytics Software . You can\n      access Tools & Frameworks in the left navigation bar. A tile is\n      displayed for each application. A yellow Imported label on a tile indicates that the\n      application was imported. Importing Custom Kubernetes Applications To import a Kubernetes application, you upload a Helm chart with a tar.gz file extension and specify configuration parameters. After you import your Kubernetes\n        applications, you can also manage them in HPE Ezmeral Unified Analytics Software . Unified Analytics supports SSO for imported applications. For detailed instructions, see Importing Applications . Managing Applications HPE Ezmeral Unified Analytics Software provides the following options to manage the\n        applications: Configure Delete Update for imported applications ( Managing Imported Tools and Frameworks ) Automatic and manual upgrade for included applications ( Upgrading Included Frameworks For detailed instructions, see the following: Managing Imported Tools and Frameworks Configuring Included Applications Upgrading Included Frameworks Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. On this page Importing Custom Kubernetes Applications Managing Applications Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/managing-application-lifecycle.html",
        "title": "Importing Applications and Managing the Application Lifecycle"
    },
    {
        "content": "\nImporting Applications Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . Prerequisites Sign in to HPE Ezmeral Unified Analytics Software as Administrator. Configure istio VirtualService to expose the\n                        endpoint. VirtualService\n                        Example apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: {{ include \"test-app.fullname\" . }}\n  namespace: {{ .Release.Namespace }}\n  labels:\n    {{- include \"test-app.labels\" . | nindent 4 }}\nspec:\n  gateways:\n    - {{ .Values.ezua.VirtualService.istioGateway }}\n  hosts:\n    - {{ .Values.ezua.VirtualService.endpoint }}\n  #The following VirtualService options are specific and depend on the application implementation.\n  #This example is a simple application with single service and simple match routes.\n  #The URL should point to the corresponding service. \n  #Kubernetes provides an internal DNS mapping for services using the format <ServiceName>.<ServiceNamespace>.svc.cluster.local. \n  http:\n    - match:\n        - uri:\n            prefix: /\n      rewrite:\n        uri: /\n      route:\n        - destination:\n            host: {{ include \"test-app.fullname\" . }}.{{ .Release.Namespace }}.svc.cluster.local\n            port:\n              number: {{ .Values.service.port }} Configure the values.yaml file of your application chart as\n                        follows: ezua:\n  ... #other EZUA options\n \n  virtualService:\n    endpoint: \"http://test-app.hpe-staging-ezaf.com\"\n    istioGateway: \"istio-system/ezaf-gateway\" Configure SSO for the applications you want to import. See SSO Support for Imported Applications . All the applications must be deployed as Helm charts. You must have the tar.gz file created from the Helm chart for the application\n                    you want to import. About this task In HPE Ezmeral Unified Analytics Software , you\n                can bring your own Kubernetes customized runtime tools and frameworks. To start\n                importing applications, follow these steps: Click the Tools & Frameworks icon on the left\n                        navigation bar. Click the Import Framework button on the top-right of\n                        the Tools & Frameworks screen. Navigate through\n                        each step within the Import Framework wizard: Framework Details: Set the following boxes\n                                    on the Framework Details step: Framework Name: Enter the framework name. Version: Enter the framework version. Description: Enter the application description. Category: Select the application category from Data\n                                                  Engineering, Analytics, or Data Science. Framework Icon: Click Select File and\n                                                  browse the logo image for your application. Framework Chart: Set the following boxes\n                                    on the Framework Chart step: Helm Chart: Select Upload New Chart to\n                                                  import a new application. A list of all previously\n                                                  imported applications appears in the dropdown. If\n                                                  you deleted the previously imported application\n                                                  and you want to import the same application again,\n                                                  you can choose that application option from the\n                                                  dropdown. NOTE If you are using a bitnami helm chart for your\n                                                  imported applications in HPE Ezmeral Unified Analytics Software , you must set the volumePermissions to true in the values.yaml file. volumePermissions:\n\n  enabled: true When Bitnami starts\n                                                  up, it creates a directory inside the\n                                                  container. When you set this value to true , it initiates the start of\n                                                  an init container that changes the owner of the\n                                                  PersistentVolume mount point. When you set this value to false , the permissions remain\n                                                  unchanged, which prevents the creation of the\n                                                  directory, thus causing the container to fail. Upload Helm Package tar.gz file: Click Select File and\n                                                  browse the tar.gz of your\n                                                  application Helm chart. Namespace: Enter the namespace for framework. Release Name: Enter the name for this specific installation of\n                                                  Helm Chart. Wait: To wait until all the necessary services,\n                                                  volumes, pods, are in ready state before\n                                                  successfully importing the applications, check Wait . Debug: To get detailed information in error status,\n                                                  check Debug . Framework Values: Configure the override values file of your\n                                application by using the Helm Values (YAML) box. Review: Review the framework details. Click\n                                the pencil icon in each section to navigate\n                                to the specific step to change the framework configuration. To import the framework, click Submit on the bottom\n                        right of the Review step. Results The application of your choice is imported and installed. You can view it on the Tools & Frameworks screen underneath your chosen\n                application category. For e.g.: If you imported test-app application under the Data\n                    Engineering category, you can view test-app on the Tools & Frameworks screen underneath the Data\n                    Engineering category. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/importing-applications.html",
        "title": "Importing Applications"
    },
    {
        "content": "\nSSO Support for Imported Applications Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication\n    and applications configured with authentication proxy. Native Authentication Integrated Applications Add the placeholders like %%OIDC_ISSUER%% and %%LDAP_XXXX%% in values.yaml file. HPE Ezmeral Unified Analytics Software automatically susbtitutes these placeholders with suitable\n        values. Authentication Proxy Configured Applications Configure SSO with AuthorizationPolicy: Configure the istio security AuthorizationPolicy before\n              importing the application. Example of AuthorizationPolicy: apiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: {{ .Release.Name }}-auth-policy\n  namespace: {{ .Values.ezua.authorizationPolicy.namespace }}\nspec:\n  action: CUSTOM\n  provider:\n    name: {{ .Values.ezua.authorizationPolicy.providerName }}\n  rules:\n    - to:\n        - operation:\n            hosts:\n            - {{ .Values.ezua.virtualService.endpoint }}\n  selector:\n    {{- with .Values.ezua.authorizationPolicy.matchLabels }}\n    matchLabels:\n      {{- toYaml . | nindent 6 }}\n    {{- end }} Configure the values.yaml file of your application chart as\n            follows: ezua:\n  oidc:\n    client_id: \"${OIDC_CLIENT_ID}\"\n    client_secret: \"${OIDC_CLIENT_SECRET}\"\n    domain: \"${OIDC_DOMAIN}\"\n    \n  domainName: \"${DOMAIN_NAME}\"\n  #Use next options in order to configure the application endpoint.\n  #Example of a VirtualService is here:\n  virtualService:\n    endpoint: \"test-app.${DOMAIN_NAME}\"\n    istioGateway: \"istio-system/ezaf-gateway\"\n\n  authorizationPolicy:\n    namespace: \"istio-system\"\n    providerName: \"oauth2-proxy\"\n    matchLabels:\n      istio: \"ingressgateway\" On this page Native Authentication Integrated Applications Authentication Proxy Configured Applications Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/sso-support-for-imported-apps.html",
        "title": "SSO Support for Imported Applications"
    },
    {
        "content": "\nManaging Imported Tools and Frameworks Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Managing Imported Tools and\n    Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Prerequisites An administrator should sign in to HPE Ezmeral Unified Analytics Software to manage applications. About this task You can configure, delete, or update imported applications and frameworks. Tiles for\n        imported tools and frameworks\n        display a yellow Imported label. Procedure In the left navigation bar, click Tools & Frameworks . Click the three-dots on the tile of the application you want to\n          manage. Perform one of the following tasks: Configure Select Configure . In the editor that opens, modify the application values.yaml file. Click Configure to apply the changes or Cancel to discard the changes. Delete To delete the application, select Delete . You can delete imported\n                    applications only. You cannot delete the applications that were installed with HPE Ezmeral Unified Analytics Software . Update ATTENTION You cannot undo the update action. Select Update . This Update option is only\n                      available for imported applications. Browse to the location where the Helm chart is stored and select the Helm\n                      chart. Click Upload . Clicking Upload enables the Upgrade button in the application tile. To upgrade the application, click Upgrade . More information Configuring Included Applications Upgrading Included Frameworks Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/managing-applications.html",
        "title": "Managing Imported Tools and Frameworks"
    },
    {
        "content": "\nConfiguring Included Applications Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Prerequisites: Sign in to HPE Ezmeral Unified Analytics Software as an administrator. To configure the tools and frameworks that were installed with HPE Ezmeral Unified Analytics Software , follow these steps: In the left navigation bar, click Tools & Frameworks . On the application tile, click the three-dots button. Select Configure to open the editor. In the editor, modify the values.yaml file. To apply the changes, click Configure , or to close the editor\n          without any changes, click Cancel . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/configuring-included-apps.html",
        "title": "Configuring Included Applications"
    },
    {
        "content": "\nUpgrading Included Frameworks Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Automatic Downloads of Framework Updates Describes how to automatically upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Manual Downloads of Framework Updates Describes how to manually upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Prerequisites: Sign in to HPE Ezmeral Unified Analytics Software as an administrator. You can upgrade frameworks installed with HPE Ezmeral Unified Analytics Software when a new version is available. You can upgrade the included frameworks in two different ways. They are: Automatic downloads of framework updates : If you are using a connected\n          (non-air-gapped) environment, you can upgrade the included frameworks by enabling\n          automatic downloads. To learn more, see Automatic Downloads of Framework Updates . Manual downloads of framework updates : If you are using a disconnected\n          (air-gapped) environment, you must manually upgrade the included frameworks. However, you\n          can also manually download framework updates in the connected environment. To learn more,\n          see Manual Downloads of Framework Updates . Automatic Downloads of Framework Updates Describes how to automatically upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Manual Downloads of Framework Updates Describes how to manually upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/upgrading-included-apps.html",
        "title": "Upgrading Included Frameworks"
    },
    {
        "content": "\nAutomatic Downloads of Framework Updates Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Automatic Downloads of Framework Updates Describes how to automatically upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Manual Downloads of Framework Updates Describes how to manually upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Automatic Downloads of Framework Updates Describes how to automatically upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Prerequisites: Sign in to HPE Ezmeral Unified Analytics Software as an administrator. You can upgrade applications by enabling automatic downloads of framework updates, so that\n      the application tile on the Tools & Frameworks screen shows an Upgrade button indicating that a new Helm chart is available or the Tools & Frameworks update bundle will be displayed on the Available Updates table. To upgrade frameworks by enabling automatic downloads, follow these steps: In the left navigation bar, click Administration \u2192 Settings . Click Updates \u2192 Download Updates . To enable the automatic download of framework updates, toggle Enable\n            automatic downloads of framework updates . NOTE To disable automatic download\n            of framework updates, toggle Disable automatic downloads of framework\n              updates . After enabling the automatic downloads of framework updates, you have two choices: Batch framework updates : To upgrade frameworks simultaneously when new\n              versions are available, use batch framework updates. To learn more, see Batch Framework Updates . Individual framework updates : To upgrade frameworks sequentially(one at a\n              time) when new versions are available, use individual framework updates. To learn\n              more, see Individual Framework Updates . Batch Framework Updates If frameworks have updates available for a new version, every hour HPE Ezmeral Unified Analytics Software bundles those updates\n        and displays the update bundle on the Available Updates table as Tools & Frameworks . NOTE The table in Available\n            Updates is updated every hour whereas if there are any new versions of\n          frameworks, you can see the Upgrade button is enabled for that\n          framework immediately in the Tools & Frameworks screen for\n          individual framework updates. Once you see the Tools & Frameworks update bundle, you can click\n        the bundle to view details. In the Details dialog box, you can see\n        the name, description, the current version of the framework and chart, and the new available\n        version for the framework and chart. Once you see the new available versions for the update,\n        you can perform the following actions by clicking on the Actions menu. Update To batch update frameworks immediately, follow these steps: Click Update in the Actions menu. This will open an Update Now dialog box and you can\n                    compare the current and new available versions of frameworks for upgrade. Click Update Now to immediately start framework\n                    updates. Wait for framework updates to be in the In\n                      Progress status. NOTE You cannot cancel framework updates once it\n                      is in the In Progress status. Result: You can navigate to the Tools &\n                  Frameworks screen to see frameworks are now in the Upgrading status. Schedule To schedule batch framework updates for later, follow these steps: Click Schedule in the Actions menu. This will open a Schedule Update dialog box and you can compare the\n                    current and new available versions of frameworks for upgrade. Select a date and time to schedule the update. Wait for framework updates to\n                    be in the Scheduled status. Once the framework updates are in the Scheduled status,\n                    you can perform the following actions from the Actions menu. Cancel You can cancel the scheduled updates any time before update starts or\n                            if updates are not in the In Progress status\n                            yet. Reschedule You can reschedule the scheduled updates any time before update starts\n                            or if updates are not in the In Progress status\n                            yet. Update You can update frameworks immediately even though it has been scheduled\n                            for a later date and time. Viewing Update History Once your updates are complete, the Tools & Frameworks update details will be displayed in the Update History table. You can click Tools & Frameworks to view details. In the Details dialog box, you can see the name, description, the\n                current version of the framework and chart, and the new available version for the\n                framework and chart. Individual Framework Updates To update frameworks one at a time, follow these steps: Click Tools & Frameworks in the left navigation bar. If there are any new versions of frameworks, you can see the Upgrade button is enabled for that framework. An enabled Upgrade button only appears if the version of the framework\n              currently installed is older than the version available. For example, if a new version\n              of Airflow is available, you see the Upgrade button enabled in the application tile for Airflow . Click Upgrade to complete the upgrade for that framework. Repeat steps 1 and 2 to update all frameworks of your choice. Failure and Rollback When you are upgrading frameworks, if one of the framework updates fails, the application\n        tile for that framework will be in the Error status and the failed\n        application will be rollbacked to the previous version from which you were upgrading to the\n        new version. For example: In HPE Ezmeral Unified Analytics Software , if you upgraded ten frameworks and nine frameworks are upgraded and\n        in the Ready status, and if one farmework upgrade failed and is in\n        the Error status with a warning message on the framework tile, then\n        only that failed application is rolled back to the previous version whereas nine frameworks\n        are successfully upgraded to new versions. If for some reason the rollback fails and the framework is in the error state, you must\n        contact HPE support to resolve this issue. On this page Batch Framework Updates Individual Framework Updates Failure and Rollback Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/automatic-framework-updates.html",
        "title": "Automatic Downloads of Framework Updates"
    },
    {
        "content": "\nManual Downloads of Framework Updates Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Importing Applications Describes how to import applications in HPE Ezmeral Unified Analytics Software . SSO Support for Imported Applications Describes SSO support for imported applications integrated with native authentication     and applications configured with authentication proxy. Managing Imported Tools and Frameworks Describes how to configure, delete, and update imported tools and frameworks in HPE Ezmeral Unified Analytics Software . Configuring Included Applications Describes how to configure tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Upgrading Included Frameworks Describes how to upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Automatic Downloads of Framework Updates Describes how to automatically upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Manual Downloads of Framework Updates Describes how to manually upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Manual Downloads of Framework Updates Describes how to manually upgrade tools and frameworks included with the HPE Ezmeral Unified Analytics Software installation. Prerequisites: Sign in to HPE Ezmeral Unified Analytics Software as an administrator. You can upgrade the applications by getting the upgrade bundle (Docker container image) from HPE Support and downloading it. When you\n      download the image, the Helm chart is pushed to the internal charts repository and the\n      application tile on the Tools & Frameworks screen shows an Upgrade button indicating that a new Helm chart is available. To manually upgrade an included application, follow these steps: IMPORTANT In an\n        air-gapped environment, download upgrade bundle (Docker container image) by using the\n        air-gap utility and then push the container image to the air gap registry before you\n        complete the following steps. To learn more about using air-gap utility, see Using the Air Gap Utility . In the left navigation bar, click Administration \u2192 Settings . Click the Updates tab. The UI submits a Kubernetes job that\n          downloads the Helm charts and then uploads them to the local repository. Enter the Image Name for the application distributed by Hewlett Packard Enterprise . Click Download . View the downloaded image in the table. NOTE To\n            remove an image, click Delete . After successfully downloading a new image, click Tools &\n            Frameworks in the left navigation bar. View the application tile to verify that the tile displays an enabled Upgrade button. An enabled Upgrade button only appears if the version of the application\n          currently installed is older than the version downloaded. For example, if you downloaded\n          an image for a new version of Airflow , you see the Upgrade button enabled in the application tile for Airflow . To upgrade the application, click Upgrade . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/manual-framework-updates.html",
        "title": "Manual Downloads of Framework Updates"
    },
    {
        "content": "\nConnecting to External S3 Object Stores Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Administrators can connect HPE Ezmeral Unified Analytics Software to object storage in AWS S3, MinIO, and HPE Ezmeral Data Fabric Object Store .\n      Users can then access data in the connected data sources through clients, such as Spark and\n      Kubeflow notebooks, without providing an access or secret key. When you configure the data source connection, you provide HPE Ezmeral Unified Analytics Software with the\n      access credentials (access key and secret key); the user does not need the access credentials\n      because HPE Ezmeral Unified Analytics Software uses a proxy to communicate with clients. Clients talk to the HPE Ezmeral Unified Analytics Software proxy through the data source endpoint URL and pass JWT tokens to\n      authenticate users. Users configure clients to talk to the connected object store. Users\n      provide the client with the data source name and endpoint URL (as they appear on the data\n      source tile in the HPE Ezmeral Unified Analytics Software UI), as well as the bucket they want the client to access. How to Connect HPE Ezmeral Unified Analytics to Object Storage Regardless of which object store you connect to, the general steps are the same with the\n        exception of a few connection parameters. IMPORTANT You can create multiple\n          object store connections. Each object store connection that you create must have a unique\n          name. To connect to an object store: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Data Engineering > Data Sources . On the Data Sources screen, select the Object Store Data tab. NOTE A\n              local-s3 MinIO tile is displayed. This local version of MinIO is used internally by HPE Ezmeral Unified Analytics Software and cannot be deleted. Click Add New Data Source . Click the Add\u2026 button in one of the tiles ( HPE Ezmeral Data Fabric Object Store , Amazon, or MinIO). In the drawer that opens, enter the connection properties: HPE Ezmeral Data Fabric Object Store To connect to HPE Ezmeral Data Fabric Object Store , provide the following information: Name - Enter a unique name for the data source. Endpoint - Enter the HPE Ezmeral Data Fabric Object Store URL, for example https://<ip-address>:9000 . Access Key - Enter the HPE Ezmeral Data Fabric Object Store access key. Secret Key - Enter the HPE Ezmeral Data Fabric Object Store secret key. Insecure - Only select this option for POCs or demos; do not select\n                      for production environments. When the option is not selected, you must add the\n                      root CA certificate for a secured connection. AWS S3 To connect to AWS S3, provide the following information: Name - Enter a unique name for the data source. Endpoint - Enter the AWS S3 URL, for example https://s3.us-east-20.amazonaws.com . Access Key - Enter the AWS S3 access key. TIP The access\n                        key and secret key are associated with the IAM user in AWS. The IAM policy\n                        associated with the user should permit access to buckets. For example, the\n                        IAM policy should grant the user read, write, and/or create access on\n                        buckets. Secret Key - Enter the AWS S3 secret key. AWS Region - Enter the AWS region. MinIO To connect to MinIO, provide the following information: Name - Enter a unique name for the data source. Endpoint - Enter the MinIO URL. Access Key - Enter the MinIO access key. Secret Key - Enter the MinIO secret key. Insecure - Only select this option for POCs or demos; do not select\n                      for production environments. When the option is not selected, you must add the\n                      root CA certificate for a secured connection. Root Certificate - This is a TLS mode configuration. Add the root CA\n                      certificate bundle. Click Add . The data source is connected and a new tile for the data source\n            displays on the Data Sources screen. IMPORTANT The data source name and endpoint URL display on the tile. Users need this information\n              to connect their clients to the data source. Users can navigate to the Data\n                Sources screen to get the information.\n              See Accessing Data in External S3 Object Stores . Limitations Currently, object storage data source connections have the following limitations: You cannot edit connection properties, such as the access and secret keys, and you\n            cannot delete an object store data source after you create the connection.\n            Alternatively, you can create a new connection to the data source with a different\n            name. Policy authorization is not supported. All HPE Ezmeral Unified Analytics Software users (members and admins) have full\n            access to data in connected object stores, including read, write, and execute\n            permissions. On this page How to Connect HPE Ezmeral Unified Analytics to Object Storage Limitations Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/connect-object-stores.html",
        "title": "Connecting to External S3 Object Stores"
    },
    {
        "content": "\nConnecting to External HPE Ezmeral Data Fabric Clusters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. To connect HPE Ezmeral Unified Analytics Software to HPE Ezmeral Data Fabric clusters, you must\n      provide the following information about the HPE Ezmeral Data Fabric cluster: CLDB nodes (hostnames or IP addresses) Service ticket TIP To get a list of the CLDB hosts, run the following command on the HPE Ezmeral Data Fabric cluster: maprcli node listcldbs -cluster <cluster name> -json For information about service tickets, see Generating a Service Ticket . Complete the following steps to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Administration > Data Fabrics . On the Data Fabrics page, click Add Data Fabric . In the drawer that opens, enter the following information: Name - Enter the HPE Ezmeral Data Fabric name. IMPORTANT Each HPE Ezmeral Data Fabric connection that you\n                create must have a unique name. CLDB Hosts - List one or more CLDB hostnames or IP addresses with the port\n              number. If entering more than one CLDB host, use a comma to separate each host name or\n              IP address, for\n              example: cldb.node.01:7222,cldb.node.02:7222,cldb.node.03:7222 Service Ticket - Paste the HPE Ezmeral Data Fabric service ticket into the field. The service ticket must include\n              the HPE Ezmeral Data Fabric cluster\n              name at the top. If the service ticket does not include the cluster name, the HPE Ezmeral Unified Analytics Software system cannot\n              connect to the HPE Ezmeral Data Fabric cluster. Volume Path - Enter the path to the mounted volume in the HPE Ezmeral Data Fabric cluster. Click Add . The HPE Ezmeral Data Fabric cluster is listed on the Data Fabric page. Status indicates the connection status. TIP When you connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster, it can take one to two minutes for the\n                synchronization with the cluster to complete. Once synchronized, the Data Fabric\n                connection Status column displays Ready (green light) and the Data\n                Fabric name changes to a clickable hyperlink. You can browse the connected HPE Ezmeral Data Fabric volume from the HPE Ezmeral Unified Analytics Software UI. In the left navigation bar, go to Data\n                  Engineering > Data Sources. On the Data Sources page, click the Data\n                  Volumes tab. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/connect-df-clusters.html",
        "title": "Connecting to External HPE Ezmeral Data Fabric Clusters"
    },
    {
        "content": "\nConfiguring Endpoints Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. Configure endpoints in HPE Ezmeral Unified Analytics Software by going to Administration > Settings and\n      selecting the Configurations tab. The following sections provide details for each type of endpoint on the Configurations tab: OTel Endpoint The OTel endpoint is the target URL where HPE Ezmeral Unified Analytics Software OTel exporter sends logs and metrics. The OTel endpoint\n        enables other OTel collectors to receive cluster metrics and logs in OTel format. When you register an OTel endpoint, the cluster OTel collector exports metric and log data\n        to the customer OTel collector hosted at the OTel endpoint. This includes Prometheus metrics\n        about cluster performance, billing/metering related data, and app-based metrics for\n        Kubeflow, Spark, and Ray. Cluster logging data from Fluent Bit is also sent. You can also\n        export the incoming data to tools, such as Grafana or Elasticsearch. OTEL is the standard format for metrics collection. Data only persists for 60 days in\n        prometheus. Use the following OTel endpoint format: <host>:<port> The OTel endpoint format: Must be a valid HTTPS host May contain a port Should contain a path Cannot contain other parts, such as a query string or fragment JDBC Endpoint The JDBC endpoint is automatically created when you install and configure HPE Ezmeral Unified Analytics Software . To connect EzPresto to external applications,\n        see Connect to External Applications via JDBC . EzCentral Forwarding NOTE EzCentral Forwarding is not supported for\n          air-gapped (disconnected) environments. In HPE Ezmeral Unified Analytics Software , you can\n        opt-in to forward your metrics collected by Prometheus to EzCentral via OTEL in real-time. EzCentral is a platform managed by HPE that can monitor your HPE Ezmeral Unified Analytics Software clusters\n        when you enable EzCentral Forwarding. The metrics forwarding to EzCentral has the following\n        benefits: Fast resolution of cluster issues by HPE through efficient cluster management and\n          administration. Provides real-time alerts to HPE enabling immediate incident resolution. Enables HPE to warn you regarding unhealthy clusters and take actions to resolve\n          issues. Provides valuable metrics to fix bugs and improve user experience. The metrics forwarding to EzCentral is enabled by\n        default. The forwarded metrics include: Node \u2013 CPU or Memory or Disk Usage Container \u2013 CPU or Memory GPU usage License or Billing Audit Logs To disable metrics forwarding to EzCentral, toggle off the Metrics Opt In button as\n          follows: On this page OTel Endpoint JDBC Endpoint EzCentral Forwarding Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/config-endpoints.html",
        "title": "Configuring Endpoints"
    },
    {
        "content": "\nGPU Support Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . GPU Resource Management Describes the GPU idle reclaim policy used for GPU resource management. Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts\n    for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . GPUs provide essential computational power and parallel processing capabilities to accelerate\n      the training and inference processes of deep learning models, reading and processing data\n      frames, processing SQL queries within Spark, and running experiments using Jupyter notebooks\n      integrated with GPUs. The hundreds or thousands of smaller cores working in parallel enable GPUs to process massive\n      amounts of data in a short period of time. HPE Ezmeral Unified Analytics Software supports single-access multi-instance GPU. You can\n      use MIG GPU when there are multiple applications that require GPU acceleration. By using MIG,\n      you can achieve higher resource utilization and cost efficiency. Supported GPU Models To see the GPU models supported by HPE Ezmeral Unified Analytics Software , see GPU Models . MIG Partitioning HPE Ezmeral Unified Analytics Software supports homogenous configuration deployment where\n        the GPU is split into N equal parts with the same amount of memory and CUDA cores. All GPU\n        models on the same Kubernetes cluster must operate in the same MIG mode or in the same\n        configuration mode. HPE Ezmeral Unified Analytics Software does not support any mixed\n        configuration across multiple GPU models. In HPE Ezmeral Unified Analytics Software , GPU partitions are presented as whole devices\n        by using the MIG mechanism. When an application requests one GPU, the application receives a\n        partition. Only one GPU device is visible to the application. To learn more, see CUDA visible devices . During the installation of HPE Ezmeral Unified Analytics Software , you must specify GPU\n        partition size (Whole, Large, Medium, and Small) and request the number of GPU instances\n        required for the workload. You cannot change the GPU partition size later. For A100 GPU, the partition size will map to the following profiles: To learn about MIG profile names, see MIG Device Names . Unified Analytics vGPU Size No. of Unified Analytics vGPUs per physical GPU MIG Profile - A100-40GB MIG Profile - A100-80GB Description Whole 1\u2013100% No MIG - entire physical GPU No MIG - entire physical GPU A100 GPU models are not split into any partitions. You will get the entire physical GPU. In this configuration, applications can use only one virtual GPU at a time. Large 2 \u2013 42% each 3g.20gb 3g.40gb A100 GPU models are split into two equal partitions. In this configuration, 16% of the GPU will remain idle. Medium 3 \u2013 28% each 2g.10gb 2g.20gb A100 GPU models are split into three equal partitions. In this configuration, 16% of the GPU will remain idle. Small 7 \u2013 14% each 1g.5gb 1g.10gb A100 GPU models are split into seven equal partitions. In this configuration, 2% of the GPU will remain idle. NOTE Once you select a specific partition size, you cannot change this configuration after\n          installation. Preparing the GPU Environment HPE Ezmeral Unified Analytics Software supports GPUs on Kubernetes nodes. The underlying\n        hosts must be running an operating system and version that is supported on the corresponding\n        version of HPE Ezmeral Unified Analytics Software . HPE Ezmeral Unified Analytics Software supports user-provided deployment. Preparing hosts to use GPU in the user-provided host model: If you want to use GPU in HPE Ezmeral Unified Analytics Software , you will have to prepare\n        your hosts. The following are the requirements for preparing your hosts before installation\n        to use GPU in HPE Ezmeral Unified Analytics Software : The host can be bare metal or VM with GPU pass-through, or an AWS EC2 instance. Install the latest version of the supported operating system. To learn about the\n            supported operating system versions for GPU in HPE Ezmeral Unified Analytics Software ,\n            see Operating System . NOTE Do not use operating systems\n              with pre-installed NVIDIA drivers. HPE Ezmeral Unified Analytics Software does not\n              support operating systems with pre-installed NVIDIA drivers. The GPU operator\n              automatically installs NVIDIA drivers when the host is added to HPE Ezmeral Unified Analytics Software . Disable SELinux on the host before adding the host to HPE Ezmeral Unified Analytics Software . This is the NVIDIA limitation, see GPU Operator with RHEL8/SELinux . NOTE After successfully\n              adding the host to HPE Ezmeral Unified Analytics Software cluster and the successfull\n              NVIDIA driver install through the GPU operator, you can enable SELinux on that host\n              and set it to enforcing mode. To learn more about user-provided hosts, see Installing on User-Provided Hosts (Connected and Air-gapped Environments) . Environments Description vSphere VM Configure the VMs in the GPU pass-through setup by following the steps in VMware setting up GPU pass-through documentation. Add hosts to the HPE Ezmeral Unified Analytics Software . AWS Use the AWS account with access to provision GPU-based instances (p4d.24xlarge,\n                    and p4de.24xlarge EC2 instances). Deploy the A100 EC2 instance (P4d instance) with the AMI image in the supported\n                    operating system. Add hosts to the HPE Ezmeral Unified Analytics Software . Adding Hosts and Enabling GPU Environment After you have prepared hosts to work in the GPU-enabled environment, you must add them to\n        the HPE Ezmeral Unified Analytics Software during the installation or during cluster\n        expansion. After adding the host, the GPU is enabled automatically. Adding Hosts and Selecting GPU Environment During Installation To add hosts and select the GPU environment in the cluster during installation,\n              follow these steps : Perform the installation instructions provided in the installation documentation\n                  for your deployment target until you reach the Installation\n                    Details step in the installation wizard. See Installation . In the Installation Details step, to enable the GPU, check Use\n                    GPU . vGPU: Specify the vGPU instances for your\n                        cluster. The number of vGPUs allocated depends on the GPU configuration\n                        partition size, the number of added GPU worker hosts, and the number of GPU\n                        cards per host. The number of allocated vGPUs may be less than the number of\n                        requested vGPUs. For example: If one A100 GPU host is added with two\n                        GPU cards with the following configurations: vGPU request: 10 vGPUs vGPU configuration: large Then the number of allocated vGPUs is as follows: vGPUs allocated: 2 x 2 large per GPU card = 4 GPU Configuration: Specify the GPU partition\n                      size. NOTE Once you select a specific partition size or specify the number of GPU\n                      instances, you cannot change this configuration after installation. As each node is added to the HPE Ezmeral Unified Analytics Software inventory node pool, HPE Ezmeral Unified Analytics Software configures the MIG profile if it detects\n                    MIG-capable devices (e.g., A100). To specify the details for other boxes or options in the Installation Details step and to complete the cluster\n                    installation, refer to the installation documentation for your deployment\n                    target. See Installation . Adding Hosts and Selecting GPU Environment During Cluster Expansion To add hosts and select the GPU environment in the cluster during cluster expansion,\n              follow these steps: Perform the steps to expand the cluster until you reach the Expand\n                    Cluster screen. See Expanding the Cluster . To enable the GPU, in the Expand Cluster screen, check Use GPU . NOTE If you enabled the Use\n                      GPU option during the cluster installation, then that means GPU is\n                    already enabled and you cannot disable the Use GPU option\n                    while expanding the cluster. vGPU: Specify the additional vGPU instances for your\n                        cluster. NOTE The number of additional vGPUs allocated depends on the GPU\n                        configuration partition size, the number of added GPU worker hosts, and the\n                        number of GPU cards per host. The number of  allocated vGPUs may be less\n                        than the number of requested vGPUs. GPU Configuration: Specify the GPU partition size. NOTE If you selected the partition size during the cluster installation,\n                        you can not update the partition size while expanding the\n                      cluster. To specify the details for other boxes or options in the Expand\n                      Cluster screen and to complete the cluster expansion, see Expanding the Cluster . Viewing GPU Model Information To retrieve the information about the GPU model installed in HPE Ezmeral Unified Analytics Software for your operating system,\n        run: lspci | grep -i nvidia | awk -F'' '{print $2}' To learn more about supported operating systems for GPUs in HPE Ezmeral Unified Analytics Software , see Operating System . Integrating GPU with Applications and Frameworks In HPE Ezmeral Unified Analytics Software , both imported and included applications and\n        frameworks support GPU. With a MIG configuration, only one GPU is assigned per application.\n        Applications request GPUs using the nvidia.com/gpu resource specifier\u200b. NOTE HPE Ezmeral Unified Analytics Software does not support MIG specifier nvidia.com/mig-Xg.YYgb . The following applications and frameworks support GPU in HPE Ezmeral Unified Analytics Software : Kubeflow Kale or KFP. See Enabling Kale Extension in Kubeflow Notebook . Kubeflow KServe. See Enabling GPU Support on Kubeflow Kserve Model Serving . Kubeflow Notebooks. See Creating GPU-Enabled Notebook Servers . Ray. See GPU Support for Ray . Spark. See Enabling GPU Support for Spark . GPU Resource Management Describes the GPU idle reclaim policy used for GPU resource management. On this page Supported GPU Models MIG Partitioning Preparing the GPU Environment Adding Hosts and Enabling GPU Environment Viewing GPU Model Information Integrating GPU with Applications and Frameworks Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/gpu-support.html",
        "title": "GPU Support"
    },
    {
        "content": "\nGPU Resource Management Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . GPU Resource Management Describes the GPU idle reclaim policy used for GPU resource management. Configuring GPU Idle Reclaim Describes how to configure the GPU idle reclaim, view pod details, and view GPU         usage. GPU Scheduling Workload Scenarios Describes GPU scheduling workload scenarios and the notebook example for GPU idle     reclaim. Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. GPU Resource Management Describes the GPU idle reclaim policy used for GPU resource management. GPU resource management enables you to optimize the analytical workloads by distributing the\n      GPU resources to various workloads so that each workload receives the necessary computing\n      power. HPE Ezmeral Unified Analytics Software implements the GPU idle reclaim feature to maximize\n      GPU utilization by dynamically allocating and deallocating resources to different frameworks\n      and workloads as needed. This prevents overallocation and underutilization of the GPU\n      resources and increases efficiency. GPU resource management uses a priority policy to ensure that critical workloads get the\n      resources they need while also allowing lower-priority workloads to utilize the GPU when it is\n      available. When a workload or framework is finished using its GPU resources, HPE Ezmeral Unified Analytics Software initiates GPU resource reclamation. This involves\n      deallocating the resources and making them available for other workloads. Custom Scheduler HPE Ezmeral Unified Analytics Software runs its own scheduler which functions\n        independently and is not connected to the default Kubernetes scheduler. Note that the default Kubernetes scheduler is still available alongside this custom\n        scheduler. The custom scheduler is an enhanced version of the default Kubernetes scheduler\n        that includes the GPU idle reclaim plugins and the preemption tolerance. The custom scheduler plugin governs all GPU workloads and is installed in the hpe-plugin-scheduler namespace. This namespace consists of a controller\n        and a scheduler module. The scheduler is responsible for scheduling and reclaiming. There are two pods in the scheduler namespace. They are scheduler-plugins-controller-dc8fbd68-2plns and scheduler-plugins-scheduler-5c9c5579cb-xz48q . You can see logs of\n          the scheduler-plugins-scheduler-5c9c5579cb-xz48q pod to find details of\n        the GPU reclamation and pod preemption. To see the logs,\n          run: ks logs -f scheduler-plugins-scheduler-5c9c5579cb-xz48q -n hpe-plugin-scheduler Custom Scheduler Configurations HPE Ezmeral Unified Analytics Software sets the default configurations for the tools and\n        frameworks supporting GPU workloads so that the custom scheduler is used by default. The\n        following tools and frameworks support GPU workloads: Kubeflow Spark Livy Ray HPE MLDE Every GPU workload for Kubeflow, Spark, Livy, Ray, and HPE MLDE have the following\n        configurations set as part of their pod spec to use the custom scheduler by default. schedulerName: scheduler-plugins-scheduler priorityClass: <app_name>-<component_name>-gpu For example, For Kubeflow notebooks: kubeflow-notebook-gpu For Spark: spark-gpu (Note: There is no component name for\n                    Spark) Only pods with their spec.schedulerName set to scheduler-plugins-scheduler are considered for reclaiming. You must not modify these configurations for the GPU reclamation. If your GPU pod spec is\n        not set to scheduler-plugins-scheduler , the default Kubernetes scheduler\n        will operate instead of the custom scheduler. The scheduler runs a cron job every 5-10 minutes. Every 5-10 minutes, the scheduler looks\n        at the running pods and determines the feasibility of reclaiming pods based on their GPU\n        usage and the annotation values set in the priority class attached to the pod. If the pod is\n        eligible for preemption, the GPU is reclaimed, and the pending pods are granted resources.\n        Pods without any GPU usage or idle pods grant their resources to the pending pods. NOTE Workloads with an idle GPU will not be preempted unless there is a pending request\n          from another workload for GPU. GPU Configurations In HPE Ezmeral Unified Analytics Software , you can configure the priority level and idle time threshold from the GPU Control Panel screen.\n        However, you cannot configure the toleration seconds and GPU usage threshold for workloads. To learn more about GPU control panel, see Configuring GPU Idle Reclaim . Priority class and priority level HPE Ezmeral Unified Analytics Software attaches priority classes as pod specs to the\n              deployed pods to prioritize pods. The priority class has a number called priority level that determines the importance of a pod. The custom scheduler determines the priority based on this priority level. The\n              default priority level for all pods is 8000. You can set the priority level from 8000-9999 where 8000 is the lowest priority level\n              and 9999 is the highest priority level. You can update the priority level for your\n              applications and workloads from the GPU Control Panel screen. Idle time threshold You can also set the idle time threshold for GPU from the GPU Control Panel\n              screen. The idle time threshold for GPU means the maximum amount of time a GPU\n              can remain idle without running any workloads. If a GPU remains idle for a duration\n              exceeding this threshold, then the GPU on those workloads can be reclaimed to make the\n              GPU available for other workloads. Toleration seconds Toleration seconds is the minimum number of seconds the pod or workload needs\n              to run before it can be preempted. The default toleration seconds is set to 300\n              seconds. GPU usage threshold The GPU usage threshold is the level of GPU utilization. The default usage\n              threshold is set to 0.0. If any pod has a GPU usage of greater than 0 in the last 300\n              seconds, it cannot be preempted. For any pods to be preempted, the usage must be\n              0.0. Configuring GPU Idle Reclaim Describes how to configure the GPU idle reclaim, view pod details, and view GPU         usage. GPU Scheduling Workload Scenarios Describes GPU scheduling workload scenarios and the notebook example for GPU idle     reclaim. On this page Custom Scheduler GPU Configurations Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/gpu-resource-management.html",
        "title": "GPU Resource Management"
    },
    {
        "content": "\nConfiguring GPU Idle Reclaim Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . GPU Resource Management Describes the GPU idle reclaim policy used for GPU resource management. Configuring GPU Idle Reclaim Describes how to configure the GPU idle reclaim, view pod details, and view GPU         usage. GPU Scheduling Workload Scenarios Describes GPU scheduling workload scenarios and the notebook example for GPU idle     reclaim. Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Configuring GPU Idle Reclaim Describes how to configure the GPU idle reclaim, view pod details, and view GPU\n        usage. You can view frameworks, the number of vGPUs assigned, framework status, priority level,\n            and the idle time threshold in the GPU Control Panel screen. You\n            can also view the pod details and the GPU utilization chart. To navigate to the GPU Control Panel screen, Sign in to HPE Ezmeral Unified Analytics Software as an administrator. In the left navigation bar, click Administration \u2192 Resource Management . You are now in the GPU Control Panel screen. In this screen, you can configure the policy settings, view the pod details and GPU usage\n            as follows: Configuring the Policy Settings To set the policy settings (priority level and idle time threshold) for your\n                framework and workload, click the Actions menu. In the Policy Settings screen, set the following boxes: Priority Level Set the priority level in the range of 8000-9999 where 8000 is the\n                                lowest priority and 9999 is the highest priority. For example, a pod\n                                with the 8000 priority level will have a low priority compared to\n                                the pod with the 9999 priority level. Default priority level: 8000 Idle Time Threshold Set the maximum amount of time a vGPU on a workload can be idle\n                                before that workload can be preempted (deallocated) automatically by\n                                a pending workload. Minimum idle time threshold: 60 seconds Default idle time threshold: 300 seconds The new policy settings will not be applied to the pods that are currently in the Running or Idle status. These new\n                policy settings will be applied to the new workloads. Viewing the Pod Details To view the pod details, click frameworks that are in the Idle or Running status.\n                This will open a pod detail screen. Here, you can see a list of pods, vGPU assigned,\n                status, age of pods, and the GPU utilization chart. Viewing the GPU Usage To view the GPU usage, click the GPU utilization chart icon\n                under Actions . In the GPU utilization\n                    screen , you can view the GPU usage for the selected period. On this page Configuring the Policy Settings Viewing the Pod Details Viewing the GPU Usage Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/configure-idle-reclaim.html",
        "title": "Configuring GPU Idle Reclaim"
    },
    {
        "content": "\nGPU Scheduling Workload Scenarios Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . GPU Resource Management Describes the GPU idle reclaim policy used for GPU resource management. Configuring GPU Idle Reclaim Describes how to configure the GPU idle reclaim, view pod details, and view GPU         usage. GPU Scheduling Workload Scenarios Describes GPU scheduling workload scenarios and the notebook example for GPU idle     reclaim. Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. GPU Scheduling Workload Scenarios Describes GPU scheduling workload scenarios and the notebook example for GPU idle\n    reclaim. In HPE Ezmeral Unified Analytics Software , you can encounter the following GPU scheduling\n      workload scenarios during the GPU idle reclamation. GPU Idle Reclaim In HPE Ezmeral Unified Analytics Software , consider two GPU workloads, denoted as Workload1 and Workload2 . Currently, Workload1 is running and is in an idle state while Workload2 is pending due to lack of available GPU resources. In this\n        scenario, if the idle duration of Workload1 exceeds an idle time threshold, Workload1 is preempted in favor of Workload2 . Following\n        the preemption, Workload1 goes into a pending state, while Workload2 is allocated GPU resources and starts running. Active GPU Usage In HPE Ezmeral Unified Analytics Software , consider two GPU workloads, denoted as Workload1 and Workload2 . Currently, Workload1 is running and is using GPU resources while Workload2 is pending due to lack of available GPU resources. The custom\n        scheduler runs a cron job every 5-10 minutes to determine the eligibility of reclaiming pods\n        based on their GPU usage and the annotation values set in the priority class attached to the\n        pod. If the GPU usage for Workload1 is greater than 0.0, Workload1 cannot be preempted in favor of Workload2 . In\n        this scenario, Workload1 will continue to run and utilize the GPU resources\n        without interruption. If the GPU usage for Workload1 is equal to 0.0 and if the idle duration of Workload1 exceeds an idle time threshold, Workload1 is\n        preempted in favor of Workload2 . Following the preemption, Workload1 goes into a pending state, while Workload2 is\n        allocated GPU resources and starts running. Priority Scheduling In HPE Ezmeral Unified Analytics Software , consider three GPU workloads, denoted as Workload1 , Workload2 , and Workload3 .\n        Currently, Workload1 is running and is in an idle state, Workload2 is pending due to lack of available GPU resources, and Workload3 has the highest priority among the three workloads and is\n        pending due to lack of available GPU resources. In this scenario, if the idle duration of Workload1 exceeds an idle time threshold, Workload1 is\n        preempted in favor of Workload3 . Following the preemption, Workload1 goes into a pending state, Workload3 is\n        allocated GPU resources and starts running, and Workload2 will continue to\n        be in the pending state. Notebook Example for GPU Idle Reclaim Consider a scenario in which HPE Ezmeral Unified Analytics Software is configured with a\n        single physical GPU. In this scenario, you have chosen the small vGPU size, which includes 7\n        vGPUs. Each application will always have a maximum of one vGPU assigned to it. Now, assume you have seven notebook servers, denoted as idle-gpu-notebook , used-gpu-notebook-1 , used-gpu-notebook-2 , used-gpu-notebook-3 , used-gpu-notebook-4 , used-gpu-notebook-5 , and used-gpu-notebook-6 . In this\n        scenario, the idle-notebook-gpu notebook server has an idle GPU with no GPU\n        usage while the six other notebook servers are actively using GPU resources. You can navigate to the GPU Control Panel screen to check the status\n        of these notebook servers. There you can see that one notebook server has an Idle status and the six others have a Running status. You can click Notebooks to view the details of each notebook server.\n        You can confirm that the idle notebook has no GPU usage, and six others have an active GPU\n        usage by clicking the GPU utilization chart icon in the Actions menu. Consider you create another GPU-enabled notebook server, denoted as test-idle-notebook-2 . As the GPU usage for idle-gpu-notebook is equal to 0.0, as soon as the idle duration of idle-gpu-notebook exceeds an idle time threshold, idle-gpu-notebook is preempted in favor of test-idle-notebook-2 . Following the preemption, idle-gpu-notebook goes into a pending state, while test-idle-notebook-2 is allocated GPU resources and starts running. On this page GPU Idle Reclaim Active GPU Usage Priority Scheduling Notebook Example for GPU Idle Reclaim Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ManageClusters/gpu-scheduling-workload-examples.html",
        "title": "GPU Scheduling Workload Scenarios"
    },
    {
        "content": "\nTroubleshooting Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . To run kubectl commands and perform the admin-related tasks described in\n      these topics, sign in to HPE Ezmeral Unified Analytics Software as an administrator. Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/troubleshooting.html",
        "title": "Troubleshooting"
    },
    {
        "content": "\nInstallation Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Installation Describes how to identify and debug issues during installation. Kyverno Service Issue The Kyverno installation step returns the following server error: (InternalError): error when creating \"/tmp/platform_ezua_app.yaml\": \nInternal error occurred: failed calling webhook \"mutate-policy.kyverno.svc\": \nfailed to call webhook: Post \"https://kyverno-svc.kyverno.svc:443/policymutate?timeout=10s\": \ncontext deadline exceeded Run the following script on all nodes and then install HPE Ezmeral Unified Analytics Software , as described in Installation Prerequisites and Installing on User-Provided Hosts (Connected and Air-gapped Environments) . #! /bin/bash\n\n# Script to disable ip checksum offload using ethtool for the primary nic. We will create a oneshot systemd service\n# to persist this across reboots\n\n# Setting ipaddress of the node\nHOST_IP=\"$(hostname -i)\"\n\necho \"fetching interface name for host: $HOST_IP\"\nPRIMARY_NIC=$(ip -o a show | grep ${HOST_IP} | awk '{print $2}')\n\necho \"printing current configuration for the nic\"\n\nethtool -k \"${PRIMARY_NIC}\" | grep tx-checksum-ip-generic\n\necho \"creating env and systemd unit file to turn chksum off for interface \\\"$PRIMARY_NIC\\\"\"\n\ncat > /etc/sysconfig/ezfab-chksum-off <<EOF\nPRIMARY_NIC=${PRIMARY_NIC}\nEOF\n\ncat > /usr/lib/systemd/system/ezfab-chksum-off.service <<EOF\n[Unit]\nDescription=Oneshot service to turn checksum off\nAfter=network.service\n\n[Service]\nType=oneshot\nEnvironmentFile=/etc/sysconfig/ezfab-chksum-off\nExecStart=ethtool -K ${PRIMARY_NIC} tx-checksum-ip-generic off\nRemainAfterExit=yes\nTimeoutSec=0\n\n# Output needs to appear in instance console output\nStandardOutput=journal+console\nStandardError=journal+console\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\nsystemctl daemon-reload\nsystemctl start ezfab-chksum-off\nsystemctl enable ezfab-chksum-off\n\necho \"printing configuration after disabling\"\n\nethtool -k \"${PRIMARY_NIC}\" | grep tx-checksum-ip-generic You can verify that\n        the issue is resolved by running the following commands on the main worker node. To get the cluster IP of the Kyverno service, run: kubectl -n kyverno get svc To verify that the service is connected, run: curl -k https://<clusterip>:443 Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-installation.html",
        "title": "Installation"
    },
    {
        "content": "\nHost (Node) Management Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Host (Node) Management Describes how to identify and debug issues for hosts. Pods Stuck in Terminating State If you have not updated the SPIFFE CSI driver, as indicated in the Post Installation Steps , and you encounter pods stuck in the Terminating state after restarting, complete the following steps: Run the following command to update the SPIFFE CSI\n            driver: kubectl -n spire set image ds spire-spiffe-csi-driver  spiffe-csi-driver=ghcr.io/spiffe/spiffe-csi-driver:0.2.5 Remove the pods in the Terminating state. If these steps do not resolve the issue, contact HPE Support. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-host-management.html",
        "title": "Host (Node) Management"
    },
    {
        "content": "\nMetering Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Metering Describes how to identify and debug issues for metering. Resource Usage or Billing Metrics Sometimes the UI does not display or update resource usage or billing metrics. The monitoring and prometheus namespaces are used for\n        observability in HPE Ezmeral Unified Analytics Software . Verify that the pods in these\n        namespaces are running. To get the list of pods in the monitoring namespace,\n          run: kubectl get pods -n monitoring Verify that the ua-application-metrics-generate-cronjob-28079520-6ts28 pod\n        and ua-monitor-deployment-c797c5f44 pod are running. If AGE of ua-application-metrics-generate-cronjob-28079520-6ts28 is less than 60\n        minutes, the cron job is up to date. To see logs for cron jobs and to view all the aggregated values and output of values,\n          run: kubectl  logs ua-application-metrics-generate-cronjob-28079520-6ts28 -n monitoring The Uploaded records successfully at: <time> message suggests that the billing\n        data was uploaded successfully. If the HOURLY USAGE or HOURLY COST values are\n        in zeroes, verify that Prometheus is working as expected without any errors or failures. All\n        Prometheus pods are located in the prometheus namespace. To get the list of pods in the prometheus namespace,\n          run: kubectl get pods -n prometheus Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-metering.html",
        "title": "Metering"
    },
    {
        "content": "\nMonitoring Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Monitoring Describes how to identify and debug issues for monitoring. Failure to display alerts and notifications Verify that the ua-monitor-deployment-c797c5f44 pod is up and running. To\n        get the list of pods in the monitoring namespace,\n          run: kubectl get pods -n monitoring Verify that the alertmanager-af-prometheus-kube-prometh-alertmanager-0 pod\n        is up and running. To get the list of pods in the prometheus namespace,\n          run: kubectl get pods -n prometheus Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-monitoring.html",
        "title": "Monitoring"
    },
    {
        "content": "\nLogging Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Logging Describes how to identify and debug issues for logging. Log Files Cannot see the log files for certain applications or cannot download the log the\n              files. Verify that the fluentbit pods are running. To get the list of\n                pods in the monitoring namespace,\n                  run: kubectl get pods -n monitoring The log file size exceeds the available disk space and causes the pods to crash. Verify that the logrotate-containerd-logs pods are running. To get\n                the list of pods in the monitoring namespace,\n                  run: kubectl get pods -n monitoring Snapshots Cannot see snapshots every four hours or snapshots are missing. Verify that the ua-application-logging-snapshot-cronjob pod is\n                running. To get the list of pods in the monitoring namespace,\n                  run: kubectl get pods -n monitoring On this page Log Files Snapshots Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-logging.html",
        "title": "Logging"
    },
    {
        "content": "\nAirflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Airflow Describes how to identify and debug issues for Airflow. Airflow UI Cannot access Airflow UI or cannot see DAGs. Ensure that the Git repository is configured properly. See Airflow DAGs Git Repository . The administrator can refer to the logs from the git-sync container in the scheduler pod in the airflow-hpe namespace. Cannot sign in to Airflow or other issues in Airflow UI. Check the logs from the af-cluster-airflowui-0 pod in the airflow-hpe namespace.\n                Run: kubectl logs -n airflow-hpe af-cluster-airflowui-0 NOTE If more than one user needs to access the same browser, the\n                logged-in user must explicitly log out before another user can access the UI.\n                Failure to explicitly log out results in caching and dashboard permission issues if\n                multiple users try to access the same UI. Airflow DAG Airflow DAG is failing. If Airflow DAG is failing, you can check the logs in the following three ways: To check the logs of the failed task in the Airflow UI page, follow these\n                      steps: Sign in to HPE Ezmeral Unified Analytics Software . Click the Applications & Frameworks icon on the\n                        left navigation bar. Navigate to the Airflow tile\n                        under the Data Engineering tab and click Open . Click Browse and select Task\n                          Instances . Select the failed task from the list. Scroll horizontally to the right until you find the Log\n                          Url button. Click on the Log Url button to view the logs\n                        associated with the failed task. To check the logs from the pod of a task by its name in the airflow-hpe namespace,\n                    run: kubectl logs -n airflow-hpe <pod_name_associated_with_the_task> To check the logs from the scheduler pod in the airflow-hpe namespace,\n                    run: kubectl logs -n airflow-hpe af-cluster-scheduler-0 Airflow scheduler Pod The scheduler pod is not coming up. If the scheduler pod is not coming up, follow these\n                  steps: NOTE Performing the next steps will result in the deletion of Airflow\n                  metadata. Proceed with caution. Delete the PVC in the airflow-hpe namespace without waiting\n                    for the\n                    deletion. kubectl delete pvc -n airflow-hpe <pvc_name> Delete the PostgreSQL database StatefulSet in the airflow-hpe namespace. kubectl delete statefulset -n airflow-hpe <postgres_db_statefulset_name> Restart the scheduler pod. kubectl rollout restart sts -n airflow-hpe af-cluster-scheduler On this page Airflow UI Airflow DAG Airflow scheduler Pod Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-airflow.html",
        "title": "Airflow"
    },
    {
        "content": "\nEzPresto Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. EzPresto Describes how to identify and debug issues for EzPresto . Insufficient Memory Currently, the maximum memory available to queries is based on the memory resources of a\n        single worker node instead of total cluster memory (all worker nodes). As a result, queries\n        may fail due to insufficient memory. To address this issue, modify the EzPresto configuration as described in the\n        following steps: In the left navigation bar, go to Tools & Frameworks > Data Engineering\n              > EzPresto . Click on the three dots and select Configure . In window that appears, remove the entire cmnConfigMaps section and\n            replace it with the following: cmnConfigMaps:\n  # Configmaps common to both Presto Master and Worker\n  logConfig:\n    log.properties: |\n      # Enable verbose logging from Presto\n      #com.facebook.presto=DEBUG\n \n  # Configmaps specific to Presto Master\n  prestoMst:\n    cmnPrestoCoordinatorConfig:\n      config.properties: |\n        http-server.http.port={{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        discovery.uri=http://{{ tpl .Values.ezsqlPresto.locatorService.fullname $ }}:{{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        coordinator=true\n        node-scheduler.include-coordinator=false\n        discovery-server.enabled=true\n        catalog.config-dir = {{ .Values.ezsqlPresto.stsDeployment.volumeMount.mountPathCatalog }}\n        catalog.disabled-connectors-for-dynamic-operation=drill,parquet,csv,salesforce,sharepoint,prestodb,raptor,kudu,redis,accumulo,elasticsearch,redshift,localfile,bigquery,prometheus,mongodb,pinot,druid,cassandra,kafka,atop,presto-thrift,ampool,hive-cache,memory,blackhole,tpch,tpcds,system,example-http,jmx\n        generic-cache-enabled=true\n        transparent-cache-enabled=false\n        generic-cache-catalog-name=cache\n        generic-cache-change-detection-interval=300\n        catalog.config-dir.shared=true\n        node.environment=production\n        plugin.dir=/usr/lib/presto/plugin\n        log.output-file=/data/presto/server.log\n        log.levels-file=/usr/lib/presto/etc/log.properties\n        query.max-history=1000\n        query.max-stage-count=1000\n        query.max-memory={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        query.max-total-memory={{ mulf 0.7 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        # query.max-memory-per-node={{ mulf 0.5 ( tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.maxHeapSize . ) | floor }}MB\n        # query.max-total-memory-per-node={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.maxHeapSize . ) | floor }}MB\n        # memory.heap-headroom-per-node={{ mulf 0.3 ( tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.maxHeapSize . ) | floor }}MB\n        experimental.spill-enabled=false\n        experimental.spiller-spill-path=/tmp\n        orm-database-url=jdbc:sqlite:/data/cache/metadata.db\n        plugin.disabled-connectors=accumulo,atop,cassandra,example-http,kafka,kudu,localfile,memory,mongodb,pinot,presto-bigquery,prestodb,presto-druid,presto-elasticsearch,prometheus,raptor,redis,redshift\n        log.max-size=100MB\n        log.max-history=10\n        discovery.http-client.max-requests-queued-per-destination=10000\n        dynamic.http-client.max-requests-queued-per-destination=10000\n        event.http-client.max-requests-queued-per-destination=10000\n        exchange.http-client.max-requests-queued-per-destination=10000\n        failure-detector.http-client.max-requests-queued-per-destination=10000\n        memoryManager.http-client.max-requests-queued-per-destination=10000\n        node-manager.http-client.max-requests-queued-per-destination=10000\n        scheduler.http-client.max-requests-queued-per-destination=10000\n        workerInfo.http-client.max-requests-queued-per-destination=10000\n \n  # Configmaps specific to Presto Worker\n  prestoWrk:\n    prestoWorkerConfig:\n      config.properties: |\n        coordinator=false\n        http-server.http.port={{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        discovery.uri=http://{{ tpl .Values.ezsqlPresto.locatorService.fullname $ }}:{{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        catalog.config-dir = {{ .Values.ezsqlPresto.stsDeployment.volumeMount.mountPathCatalog }}\n        catalog.disabled-connectors-for-dynamic-operation=drill,parquet,csv,salesforce,sharepoint,prestodb,raptor,kudu,redis,accumulo,elasticsearch,redshift,localfile,bigquery,prometheus,mongodb,pinot,druid,cassandra,kafka,atop,presto-thrift,ampool,hive-cache,memory,blackhole,tpch,tpcds,system,example-http,jmx\n        generic-cache-enabled=true\n        transparent-cache-enabled=false\n        generic-cache-catalog-name=cache\n        catalog.config-dir.shared=true\n        node.environment=production\n        plugin.dir=/usr/lib/presto/plugin\n        log.output-file=/data/presto/server.log\n        log.levels-file=/usr/lib/presto/etc/log.properties\n        query.max-memory={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        query.max-total-memory={{ mulf 0.7 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        query.max-memory-per-node={{ mulf 0.5 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) | floor }}MB\n        query.max-total-memory-per-node={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) | floor }}MB\n        memory.heap-headroom-per-node={{ mulf 0.2 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) | floor }}MB\n        experimental.spill-enabled=false\n        experimental.spiller-spill-path=/tmp\n        orm-database-url=jdbc:sqlite:/data/cache/metadata.db\n        plugin.disabled-connectors=accumulo,atop,cassandra,example-http,kafka,kudu,localfile,memory,mongodb,pinot,presto-bigquery,prestodb,presto-druid,presto-elasticsearch,prometheus,raptor,redis,redshift\n        log.max-size=100MB\n        log.max-history=10\n        discovery.http-client.max-requests-queued-per-destination=10000\n        event.http-client.max-requests-queued-per-destination=10000\n        exchange.http-client.max-requests-queued-per-destination=10000\n        node-manager.http-client.max-requests-queued-per-destination=10000\n        workerInfo.http-client.max-requests-queued-per-destination=10000\n### values_cmn_configmap.yaml contents END Click Configure to update the configuration on each of the presto pods and\n            restart the pods. This operation takes a few minutes. If this workaound does not resolve the issue, contact HPE Support. Failed Queries If queries fail, go to the Presto UI and view the stack trace for the queries. You can also\n        view the EzPresto log files. You can access the Presto UI from the HPE Ezmeral Unified Analytics Software UI. In the left navigation bar, select Applications & Frameworks . Select the Data Engineering tab. In the EzPresto tile, click on\n          the Endpoint URL. In the Presto UI, select the Failed state. Locate the query and click on the Query ID . Scroll down to the Error Information section to view the stack trace. You can also view the logs in the shared directory. In the left navigation bar, select Data Engineering > Data\n            Sources . On the Data Sources screen, click Browse . Select the following directories in the order shown: shared/ logs/ apps/ app-core/ ezpresto/ Select the log directory for which you want to view EzPresto logs. On this page Insufficient Memory Failed Queries Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-ezpresto.html",
        "title": "EzPresto"
    },
    {
        "content": "\nSuperset Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Superset Describes how to identify and debug issues for Superset. Superset UI If more than one user needs to access the same browser, the logged-in user must explicitly\n        log out before another user can access the UI. Failure to explicitly log out results in\n        caching and dashboard permission issues if multiple users try to access the same UI. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-superset.html",
        "title": "Superset"
    },
    {
        "content": "\nSpark Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Spark Describes how to identify and debug issues for Spark. Spark History Server Long-running Spark applications exceed disk\n              quotas for Spark History Server. Repeatedly running long-running Spark applications generates a large volume of logs\n                in the Spark History Server event log directory. This can exceed disk quotas,\n                causing failures in other Spark applications. You must monitor log sizes and manage\n                disk space to mitigate this issue. Workaround To prevent the exceeding of disk quota for the Spark History Server event log\n                directory, modify the Spark History Server configuration options as follows: To periodically clean up event logs from storage,\n                set: spark.history.fs.cleaner.enabled true To delete job log files older than the specified value,\n                set: spark.history.fs.cleaner.maxAge 1d Here, job log files\n                that are older than 1d are deleted by the filesystem history cleaner. To specify the frequency for the filesystem job history cleaner to check for the\n                files to be deleted,\n                set: spark.history.fs.cleaner.interval 12h Here, the filesystem\n                job history cleaner checks every 12h for files to be deleted. NOTE If the disk quota is full, contact HPE support for assistance. Spark Operator Spark application submission hangs or fails. If the Spark application submission hangs or fails, check the submission pod\n                  state. If the pod is in the pending state, wait for more resources to be\n                    available. If the pod is in the failed state, collect pod logs and contact Hewlett Packard Enterprise . Spark application hangs in the Submitted or Running state. If the Spark application hangs in the Submitted or Running state, check the state of the driver pod. If the driver pod is in the ContainerCreating state, check the\n                  pod events. If the image is downloading, wait until the image is downloaded. For the FailedMount reason, you need to identify what\n                      volume is missing. By default, all Spark workloads submitter pods are preconfigured to\n                          mount system volumes such as Spark History Server PVC, user PVC, and\n                          shared PVC. If the problem is with the system volume, contact Hewlett Packard Enterprise . If the driver pod is in a Running state, check if executor\n                      pods are in a Running state as well\u200b. Sometimes executor pods are in a pending\n                      state due to a lack of resources, in this case, wait for the resources to be\n                      available. For other reasons, collect driver and executor pod logs and contact Hewlett Packard Enterprise . Spark application fails. If the Spark application fails, collect the driver pod logs. If the container fails before running the application code, contact Hewlett Packard Enterprise as there is a problem with the image. If the container fails while the application is running, check the exception\n                    in a driver log:\u200b For the functional exception (e.g. NullPointerException), review the\n                        application source code\u200b. For the non-functional exception (e.g. OutOfMemoryError), increase memory\n                        allocation for the driver pod and/or review the application source\n                        code\u200b. Livy Livy session creation fails. If the Livy session fails, create a Livy session with the default configuration and\n                run. If it runs successfully, check the configuration of your failed Livy session for\n                  configuration issues. If it fails, collect the Livy server pod logs and driver pod logs (if available)\n                  and contact Hewlett Packard Enterprise . Livy session hangs in the Starting state. Verify that the driver pod is not in the Pending or\n                  ContainerCreating state. Livy statement run hangs or fails. If the Livy statement run hangs or fails, Analyze the error message and fix the statement. For a detailed error message\n                    information, go to the Livy Server UI. Verify the executor pods are not in the Pending state.\n                    For the Livy statements to run, executor pods must be available. For other reasons, collect driver and executor pod logs and contact Hewlett Packard Enterprise . Livy session disappears. No action required as this is an expected behaviour for the idling sessions. On this page Spark History Server Spark Operator Livy Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-spark.html",
        "title": "Spark"
    },
    {
        "content": "\nImporting Applications and Managing the Application Lifecycle Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing\n    the application lifecycle. Downloading the application chart version fails. If downloading the application chart version fails, verify the chart is present in\n              the chartmuseum repository. Importing applications results in an error. If you get errors while importing applications, Check the error state in the application tile. Check job logs in ezapp-system namespace. Importing applications after fixing the application charts. If you need to import the application after fixing the application chart, follow\n              these steps: Delete the previously imported application. Update the chart version. Re-package the application. Import the re-packaged application. The Open button within the application tile is not working and the endpoint URL is\n            missing from the tile. Verify that values.yaml file includes the ezua section. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-import-and-manage-app-lifecycle.html",
        "title": "Importing Applications and Managing the Application Lifecycle"
    },
    {
        "content": "\nSecurity Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Security Describes how to identify and debug issues related to security. Internal Network Connection issue SPIRE is currently implemented to rotate certificates that secure mTLS traffic internally\n        right now. The SPIRE server has two containers in it. If SPIRE elements are down, this could\n        be the source of an internal network connection problem. You can check to see if SPIRE is\n        logging for a particular node. SPIRE pods are in the SPIRE namespace, including one agent per node. In the SPIRE server pod, the spire-controller-manager container is the most beneficial to\n        check for\n        logs: kubectl -n spire logs -l app=spire-server -c spire-controller-manager Oauth-2-proxy Pod in CrashLoopBackOff Error State The container in the oauth-2-proxy pod started, but crashes and repeatedly\n        restarts incorrectly. To resolve this issue, update the DNS A record with the node IP\n        address where the Istio Ingress gateway pod was deployed. You can get the node IPs on the\n        Status page of the HPE Ezmeral Unified Analytics Software installer. Authentication If authentication is not working, check to see if pods are running and check pod logs. You\n        may just need to kill a pod and restart it on a healthy node. For more complicated issues,\n        you may need to collect some logs and talk to HPE support. The following table provides pod information and commands you may want to run if\n        authentication is not working: Component Information Internal OpenLDAP server The server runs the ldap-0 pod in the hpe-ldap namespace. You can access the ldap-0 pod with the following internal service DNS\n                    name: ldap-svc.hpe-ldap.svc.cluster.local:389 If you\n                    need to bind it to read some users, use the following DN and\n                    password: cn=readonly,dc=example,dc=com\npassword: mapr Search from the following\n                    base: ldapsearch -Y EXTERNAL -Q -H ldapi:/// -b ou=users,dc=example,dc=com You\n                    can also exec into the ldap-0 pod and use ldap * local utilities like ldap search to\n                    investigate what the internal LDAP server looks like. Oauth-2 proxy HPE Ezmeral Unified Analytics Software uses Oauth2 proxy for authentication. Oauth2 runs in the oauth-2-proxy namespace. To get the pod logs, run the\n                    following command: kubectl -n oauth2-proxy logs -l app=oauth2-proxy Keycloak HPE Ezmeral Unified Analytics Software uses a local instance of Keycloak as its OIDC provider. Keycloak runs in the keycloak namespace in the keycloak-0 pod.\n                  There is also a PostgreSQL pod running in the namespace that stores the\n                  configuration and current known user information. Keycloak pod logs show login\n                  attempts and any AD/LDAP integration errors. To view the Keycloak logs,\n                    run: kubectl -n keycloak logs keycloak-0 Keycloak/LDAP User Authentication Test Use a direct grant endpoint to see if a user can authenticate to Keycloak. Run this test on\n        the command line to verify that the AD/LDAP integration is working for a particular user and\n        that the password is correct. This test hits a client in Keycloak that allows the direct\n        grant on the authentication flow. This test is not doing a web-based redirect flow; it is\n        just saying give me your credentials for a token in return. Run this test on the command line and then go to https://jwt.io/ : USER=<username>\nPASS=<password>\nDOMAIN=<your-domain>.com\nRESULT=$(curl -k --data \"username=$USER&password=$PASS&grant_type=password&client_id=ua-grant\" https://keycloak.$DOMAIN/realms/UA/protocol/openid-connect/token)\nACCESS_TOKEN=$(echo $RESULT | sed 's/.*access_token\":\"//g' | sed 's/\".*//g') You can also use the direct grant endpoint for REST API endpoints that must accept and\n        validate username and password credentials. The direct grant endpoint can validate the\n        incoming username and password and get an access token. The remainder of the flow inside HPE Ezmeral Unified Analytics Software is based on\n        the access token. Keycloak Admin Web Console The Keycloak Admin Web Console is useful for finding and resolving issues. To access the\n        Keycloak Admin Web Console, you will need the system master's kubectl privileges that you got when you first installed and created the HPE Ezmeral Unified Analytics Software cluster. This is\n        required to get the password for the keycloak administrator. To access the Keycloak Admin Web Console: Go to keycloak.<your-UA-domain> . Enter admin as the user. Enter the password. You can get the password with kubectl and kube.config : kubectl -n keycloak get secret admin-pass -o jsonpath=\"{.data.password}\" | base64 -D\u200b NOTE For\n            Linux, use base64 -d . For Mac, use base64\n          -D\u200b . In the left navigation bar of the Keycloak UI, switch over to the UA realm . To find all users: In the left navigation bar, select Users . On the User list tab, enter * in the search field to see all known users. To modify roles for a particular user: NOTE This process can be useful if someone deletes\n          the HPE Ezmeral Unified Analytics Software admin\n          users in the AD server. The user whose role you modify may need to sign out of HPE Ezmeral Unified Analytics Software , and sign back in\n          for the change to take effect. On the Users page, search for the user and click on the username . Select the username in the User list . On the user's page, select Role Mapping . Select the role that you want to assign to the user. To change how users sign in (email vs username): In the left navigation bar, go to Realm Settings > Login tab . On the Login tab , select the Login with email switch. Duplicate emails\n            turns off automatically when you do this. This is safe to do for external AD/LDAP\n            servers. For internal AD/LDAP servers, you can also turn this on, but there are no guard\n            rails on the internal user management to prevent duplicate emails. If this happens, one\n            of the users will not be able to log in. To manually grant or remove the ua-enabled role: NOTE The ua-enabled role is the internal role that grants access to HPE Ezmeral Unified Analytics Software . If the user object\n          does not have this role in Keycloak, they cannot authenticate and get access to HPE Ezmeral Unified Analytics Software applications.\n          However, this does not do all the user onboarding and offboarding that the user management\n          operator does; it merely prevents access to HPE Ezmeral Unified Analytics Software . Setting this role in Keycloak should only be used\n          in special or emergency circumstances. In the left navigation bar, select Users . Search for the user and select the user. On the user's page, select the Role Mapping tab. Select ua-enabled . To see the LDAP settings that identify the source of the HPE Ezmeral Unified Analytics Software user directory: In the left navigation bar, select User federation . On the LDAP page, select the Settings tab . You can change the following settings: How Keycloak batch requests to the remote server. How often Keycloak synchs users from the server; the default is hourly. NOTE You should\n            not modify the settings you entered through the HPE Ezmeral Unified Analytics Software installer, such as the server address.\n            Changing those settings here can have negative consequences because this is not the only\n            place that those settings are stored. Keycloak uses the LDAP information, but so do some\n            of the other HPE Ezmeral Unified Analytics Software applications. Currently, it is best not to change LDAP settings\n            because it can break applications that depend on them. Bad HTTP Request When a custom framework expects HTTPS traffic, the following error displays when you try to\n        access the service in the\n        browser: 400 Bad Request - The plain HTTP request was sent to HTTPS port. To\n        resolve this issue, add a DestinationRule in addition to the VirtualService, as shown in the\n        following examples. DestinationRule Example apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: {{ include \"test-app.fullname\" . }}\n  namespace: {{ .Release.Namespace }}\n  labels:\n    {{- include \"test-app.labels\" . | nindent 4 }}\n\n #The URL should point to the corresponding service. \n #Kubernetes provides an internal DNS mapping for services using the format <ServiceName>.<ServiceNamespace>.svc.cluster.local. \nspec:\n  host: {{ include \"test-app.fullname\" . }}.{{ .Release.Namespace }}.svc.cluster.local\n  trafficPolicy:\n    tls:\n      mode: SIMPLE VirtualService\n        Example apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: {{ include \"test-app.fullname\" . }}\n  namespace: {{ .Release.Namespace }}\n  labels:\n    {{- include \"test-app.labels\" . | nindent 4 }}\nspec:\n  gateways:\n    - {{ .Values.ezua.VirtualService.istioGateway }}\n  hosts:\n    - {{ .Values.ezua.VirtualService.endpoint }}\n  #The following VirtualService options are specific and depend on the application implementation.\n  #This example is a simple application with single service and simple match routes.\n  #The URL should point to the corresponding service. \n  #Kubernetes provides an internal DNS mapping for services using the format <ServiceName>.<ServiceNamespace>.svc.cluster.local. \n  http:\n    - match:\n        - uri:\n            prefix: /\n      rewrite:\n        uri: /\n      route:\n        - destination:\n            host: {{ include \"test-app.fullname\" . }}.{{ .Release.Namespace }}.svc.cluster.local\n            port:\n              number: {{ .Values.service.port }} On this page Internal Network Connection issue Oauth-2-proxy Pod in CrashLoopBackOff Error State Authentication Keycloak/LDAP User Authentication Test Keycloak Admin Web Console Bad HTTP Request Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-security.html",
        "title": "Security"
    },
    {
        "content": "\nGPU Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. GPU Describes how to identify and debug issues for GPU. GPU Not Working as Expected Upload and run Check_gpu_card.ipynb notebook file in GPU-enabled\n        notebook servers. See Creating GPU-Enabled Notebook Servers . If the output does not display the GPU card, follow these steps: To access the NVIDIA CLI in the hpecp-gpu-operator namespace,\n            run: kubectl exec -it -n hpecp-gpu-operator daemonset/nvidia-device-plugin-daemonset -- bash To show the Python 3 process, run: nvidia-smi If the output does not show the Python 3 process, contact Hewlett Packard Enterprise support. Ray Ray job hangs when you request more than available GPU resource in the Ray\n              cluster. When you request more than available GPU resource in the Ray cluster, the Ray job\n                  hangs. When you go to the logs in Ray Dashboard, you can see the following general log\n                entry. However, this log entry does not specify that the job is hanging as more than\n                available GPU resource is\n                requested. [2023-07-20 08:18:09,674 I 25723 25723] core_worker.cc:651: Waiting for joining a core worker io thread. If it hangs here, there might be deadlock or a high load in the core worker io service. To confirm that the job hanging has more than the available GPU resource requested,\n                you can perform the following checks: Run the following command to get the tasks\n                      summary: kubectl -n kuberay exec kuberay-head-2dj8n -- ray summary tasks Output: When you run the kubectl command to check\n                      the tasks summary, you can see the job is pending as\n                      follows: Defaulted container \"ray-head\" out of: ray-head, autoscaler, init (init)\n======== Tasks Summary: 2023-07-20 08:15:25.292285 ========\nStats:\n------------------------------------\ntotal_actor_scheduled: 12\ntotal_actor_tasks: 12\ntotal_tasks: 192\n                        \n                        \nTable (group by func_name):\n------------------------------------\nFUNC_OR_CLASS_NAME                              STATE_COUNTS                      TYPE\n0   fibonacci_distributed                       FINISHED: 160                     NORMAL_TASK\n                                                PENDING_NODE_ASSIGNMENT: 32\n1   RayFraudDetectionExperiment.run_experiment  FAILED: 2                         ACTOR_TASK\n                                                FINISHED: 10\n2   RayFraudDetectionExperiment.__init__        FAILED: 2                         ACTOR_CREATION_TASK\n                                                FINISHED: 10 Run the following command to check the job\n                      status: kubectl -n kuberay exec kuberay-head-2dj8n -- ray status Output: When you run the kubectl command to check the\n                      job status, you can see that job hangs until it gets the required resources as\n                      follows: Defaulted container \"ray-head\" out of: ray-head, autoscaler, init (init)\n======== Autoscaler status: 2023-07-20 08:16:04.958109 ========\nNode status\n---------------------------------------------------------------\nHealthy:\n1 head-group\n1 smallGroup\n1 workerGroup\nPending:\nno pending nodes)\nRecent failures:\nno failures)\n\nResources\n---------------------------------------------------------------\nUsage:\n0.0/3.0 CPU\n0.0/1.0 GPU\n0B/14.90GiB memory\n0B/4.36GiB object_store_memory\n                        \nDemands:\n{'GPU': 2.0}: 32+ pending tasks/actors Notebooks Notebook server creation will be in the pending state when you assign more than one\n              GPU resource. When you assign more than one GPU resource for notebook servers, the notebook\n                server creation will be in a pending state. If you hover over the spinner, you can\n                see the following message: Reissued from pod/test-nb-0: 0/8 nodes are available: 3 node(s) had untolerated\n                  taint {node-role.kubernetes.io/master: }, 8 Insufficient nvidia.com/gpu.\n                  preemption: 0/8 nodes are available: 3 Preemption is not helpful for scheduling, 5\n                  No preemption victims found for incoming pod. For example: Kale The Running Pipeline step will be in the pending state when you assign more than one\n              GPU resource for Kale. To confirm that the Running Pipeline step is in the pending\n                state as more than one GPU resource is assigned for Kale, follow these steps: Perform the steps to specify the GPU resource in the Kale extension. See Specifying GPU Resources in the Kale Extension . Run the notebook via Kale. Go to Running Pipeline and click View . You can see that the pipeline state is in a pending\n                    state. Click on the step in the pending state. For example: Test gpu is the pending\n                      step. Output: You can see the following message: This step is in Pending state with this message: Unschedulable: 0/8 nodes are\n                  available: 3 node(s) had untolerated taint {node-role.kubernetes.io/master: }, 8\n                  Insufficient nvidia.com/gpu. preemption: 0/8 nodes are available: 3 Preemption is\n                  not helpful for scheduling, 5 No preemption victims found for incoming\n                  pod. On this page GPU Not Working as Expected Ray Notebooks Kale Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-gpu.html",
        "title": "GPU"
    },
    {
        "content": "\nUser Interface Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Installation Describes how to identify and debug issues during installation. Host (Node) Management Describes how to identify and debug issues for hosts. Metering Describes how to identify and debug issues for metering. Monitoring Describes how to identify and debug issues for monitoring. Logging Describes how to identify and debug issues for logging. Airflow Describes how to identify and debug issues for Airflow. EzPresto Describes how to identify and debug issues for EzPresto . Superset Describes how to identify and debug issues for Superset. Spark Describes how to identify and debug issues for Spark. Importing Applications and Managing the Application Lifecycle Describes how to identify and debug issues while importing applications and managing     the application lifecycle. Security Describes how to identify and debug issues related to security. GPU Describes how to identify and debug issues for GPU. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. User Interface Describes how to identify and debug issues related to the HPE Ezmeral Unified Analytics Software UI. Installer UI Does Not Show Ingress Gateway Node IP Addresses (Required for DNS A Record\n        Configuration) When you install HPE Ezmeral Unified Analytics Software , you need the ingress gateway node IP addresses to configure your DNS\n        A record for access to the HPE Ezmeral Unified Analytics Software domain. However, due to a port conflict that can occur between the\n        istio ingress gateway and OpenShift ingress, the HPE Ezmeral Unified Analytics Software installer UI may not display the ingress gateway node\n        IP addresses after the installation completes. When this conflict occurs, the istio\n        ingressgateway pods go into a pending state, and the function that\n        retrieves the node IPs returns empty. To resolve this issue, complete the following steps: SSH into the HPE Ezmeral Unified Analytics Software master node or have access to the kubeconfig of\n            the HPE Ezmeral Unified Analytics Software cluster. To identify the nodes running the OpenShift ingress pods, run: kubectl get pod -n   openshift-ingress -o wide Example [core@master0 ~]$ kubectl get pod -n   openshift-ingress -o wide\nNAME                             READY   STATUS    RESTARTS   AGE   IP               NODE                        NOMINATED NODE   READINESS GATES\nrouter-default-b6c47bcf6-5nlcm   1/1     Running   0          37h   10.227.209.134 worker2.pooja.ezfab.local <none>           <none>\nrouter-default-b6c47bcf6-w7vcv   1/1     Running   0          38h   10.227.209.135   worker3.pooja.ezfab.local   <none>           <none>\n[core@master0 ~]$ To identify the nodes with the \"ezkf.hpe.com/ingress-gateway=true\" label,\n              run: kubectl get node --show-labels | grep ingress-gateway NOTE The\n              conflict occurs on the node(s) running OpenShift ingress pods that also have the \"ezkf.hpe.com/ingress-gateway=true\" label. Example [core@master0 ~]$ kubectl get node --show-labels | grep ingress-gateway worker2.pooja.ezfab.local Ready    worker                 46h   v1.25.16+5c97f5b   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,ezkf.hpe.com/ingress-gateway=true,hpe.com/compute=true,hpe.com/dataplatform=true,hpe.com/exclusivecluster=none,hpe.com/pin-dataplatform-cldb=true,hpe.com/pin-dataplatform-zk=true,hpe.com/status=available,hpe.com/usenode=true,kubernetes.io/arch=amd64,kubernetes.io/hostname=worker1.pooja.ezfab.local,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.openshift.io/os_id=rhcos,nvidia.com/gpu.deploy.operands=true\nworker4.pooja.ezfab.local   Ready    worker                 46h   v1.25.16+5c97f5b   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,ezkf.hpe.com/ingress-gateway=true,hpe.com/compute=true,hpe.com/dataplatform=true,hpe.com/exclusivecluster=none,hpe.com/status=available,hpe.com/usenode=true,kubernetes.io/arch=amd64,kubernetes.io/hostname=worker4.pooja.ezfab.local,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.openshift.io/os_id=rhcos,nvidia.com/gpu.deploy.operands=true In this example output, the conflicting node is worker2.pooja.ezfab.local because this node has the OpenShift ingress\n            pod running and also has the label. The \"ezkf.hpe.com/ingress-gateway=true\" label on this node must be\n            deleted and then added to a different worker node. On each node with the conflict, complete the following steps: To remove the label,\n                  run: kubectl label node <nodename> ezkf.hpe.com/ingress-gateway- NOTE The - at the end of ingress-gateway- is included\n                  to indicate deletion of the label. To list all worker nodes,\n                  run: kubectl get node Example [core@master0 ~]$ kubectl get node\nNAME                        STATUS   ROLES                  AGE   VERSION\nmaster0.pooja.ezfab.local   Ready    control-plane,master   46h   v1.25.16+5c97f5b\nmaster1.pooja.ezfab.local   Ready    control-plane,master   46h   v1.25.16+5c97f5b\nmaster2.pooja.ezfab.local   Ready    control-plane,master   46h   v1.25.16+5c97f5b\nworker0.pooja.ezfab.local   Ready    worker                 46h   v1.25.16+5c97f5b worker1.pooja.ezfab.local Ready    worker                 46h   v1.25.16+5c97f5b\nworker2.pooja.ezfab.local   Ready    worker                 46h   v1.25.16+5c97f5b\nworker3.pooja.ezfab.local   Ready    worker                 46h   v1.25.16+5c97f5b\nworker4.pooja.ezfab.local   Ready    worker                 46h   v1.25.16+5c97f5b worker5.pooja.ezfab.local Ready    worker                 46h   v1.25.16+5c97f5b Identify one worker node that does not have the ingress gateway or the \"ezkf.hpe.com/ingress-gateway=true\" label and then run the\n                following command to add the label to that\n                node: kubectl label --overwrite node <nodename>  ezkf.hpe.com/ingress-gateway=true In\n                the example, the following nodes qualify as worker nodes that could have the \"ezkf.hpe.com/ingress-gateway=true\" label\n                added: worker0.pooja.ezfab.local\nworker1.pooja.ezfab.local\nworker5.pooja.ezfab.local To verify that there are two running istio-ingressgateway pods,\n              run: kubectl get pod -n istio-system NOTE An OpenShift cluster\n              with three worker nodes has only one \u200b istio-ingressgateway pod in the Running state. To get the ingressgateway IPs, run: kubectl -n istio-system get pod -l app=istio-ingressgateway -o jsonpath='{.items[*].status.hostIP}' Use\n              the IP address to configure the DNS A records. UI Sign-Out/Timeout Causes Issues in Open Applications If you explicitly sign out of the HPE Ezmeral Unified Analytics Software UI or the system signs you out because the session hit the idle\n        duration limit, you may experience issues in the other applications that you opened through\n        the HPE Ezmeral Unified Analytics Software UI in the\n        same session, or you may see the following message: Bad Message 431 Reason: Request Header Fields Too Large To prevent or resolve this issue, follow these recommendations: If you are not working directly in the HPE Ezmeral Unified Analytics Software UI, close the UI tab to avoid having the system\n          automatically sign you out. When you explicitly sign out of the HPE Ezmeral Unified Analytics Software UI, close all of the application tabs that you opened\n          through the UI. If you get the 431 message, clear the browser cookies for that particular HPE Ezmeral Unified Analytics Software cluster. On this page Installer UI Does Not Show Ingress Gateway Node IP Addresses (Required for DNS A Record\n        Configuration) UI Sign-Out/Timeout Causes Issues in Open Applications Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Troubleshooting/ts-user-interface.html",
        "title": "User Interface"
    },
    {
        "content": "\nSupport Matrix Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system\n      versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Tools and Frameworks HPE Ezmeral Unified Analytics Software supports the\n        following Tools & Frameworks in the versions listed: HPE Ezmeral Unified Analytics Software Airflow EzPresto Feast Kubeflow Livy MLflow HPE MLDE Ray Spark Applications Spark History Server Spark Operator Superset 1.3.0 2.7.3 0.281 0.34.1 1.8 0.8.0 2.8.1 0.26.7 2.7.0 3.5.0 3.5.0 1.3.8.4-hpe 3.0.1 1.2.0 2.7.0 0.281 0.34.1 1.7 0.7.0 2.7.1 N/A 2.6.1 3.4.1 3.3.1 3.4.1 1.3.8.3-hpe 2.1.1 1.1.0 2.6.1 0.269 0.31.0 1.7.0 0.7.0.302 2.4.0 N/A 2.4.0 3.4.0 3.3.1 3.4.0 1.3.8.2-hpe 2.1.0 1.0.0 2.5.1 0.269 0.29.0 1.6.0 0.7.0 2.1.1 N/A 2.2.0 3.3.1 3.3.1 1.3.8.2-hpe 2.0.1 Notebook Images The following table lists the default notebook images and their packages in HPE Ezmeral Unified Analytics Software 1.3.0: Notebook Images Libraries General Packages gcr.io/mapr-252711/kubeflow/notebooks/jupyter-scipy:ezaf-fy24-q1-r5 SciPy 1.11.3 JupyterLab 3.6.6 mlflow 2.8.1 kserve 0.11.2 kubeflow-katib 0.16.0 presto-python-client 0.8.3 ray 2.7.0 The following packages are installed in a separate Ray kernel, ray[tune] 2.7.0 ray[default] 2.7.0 ray[client] 2.7.0 Conda Python 23.3.1-1 gcr.io/mapr-252711/kubeflow/notebooks/jupyter-pytorch-full:ezaf-fy24-q1-r5 PyTorch (CPU) torch 2.1.0 torchvision 0.16.0 torchaudio 2.1.0 gcr.io/mapr-252711/kubeflow/notebooks/jupyter-pytorch-cuda-full:ezaf-fy24-q1-r5 PyTorch (CUDA) cuda 12.1 torch 2.1.0 torchvision 0.16.0 torchaudio 2.1.0 gcr.io/mapr-252711/kubeflow/notebooks/jupyter-tensorflow-full:ezaf-fy24-q1-r5 Tensorflow (CPU) tensorflow 2.13.0 gcr.io/mapr-252711/kubeflow/notebooks/jupyter-tensorflow-cuda-full:ezaf-fy24-q1-r5 TensorFlow (CUDA) tensorflow 2.13.0 cuda 11.8 gcr.io/mapr-252711/kubeflow/notebooks/jupyter-data-science:ezaf-fy24-q1-r5 N/A gcr.io/mapr-252711/kubeflow/notebooks/codeserver:ezaf-fy24-q1-r5 code-server 4.17.1 (Visual Studio Code) Python extension 2023.18.0 NOTE This is not the Python language\n                        version. To learn more about descriptions and uses of Notebook images, see Notebook Images Overview . HPE Ezmeral Data Fabric The following table lists the versions of HPE Ezmeral Data Fabric that you\n        can connect HPE Ezmeral Unified Analytics Software to externally: HPE Ezmeral Unified Analytics Software HPE Ezmeral Data Fabric 1.3.0 7.4.0 1 1.2.0 6.2.0, 7.0.0, 7.1.0, 7.2.0, 7.3.0, 7.4.0 1.1.0 6.2.0, 7.0.0, 7.2.0 1.0.0 7.0.0, 7.2.0 1 In HPE Ezmeral Unified Analytics Software 1.3, Hewlett Packard Enterprise recommends connecting externally to HPE Ezmeral Data Fabric 7.4.0. In previous releases, the following HPE Ezmeral Data Fabric versions were tested: 6.2.0, 7.0.0, 7.1.0, 7.2.0,\n        7.3.0. Operating System HPE Ezmeral Unified Analytics Software supports the\n        following operating systems in the versions listed: HPE Ezmeral Unified Analytics Software RHEL Version Rocky Version 1.3.0 8.8 1 8.7 2 1.2.0 8.x 1 8.x 2 1.1.0 8.x 1 8.x 2 1 Only RHEL 8.8 is supported on GPU hosts. 2 There is no GPU support for Rocky 8.x, as NVIDIA does not support the GPU\n        operator running on Rocky 8.x. GPU Models HPE Ezmeral Unified Analytics Software supports the\n        following GPU models: HPE Ezmeral Unified Analytics Software GPU Model 1.3.0 NVIDIA A100 1.2.0 NVIDIA A100 1.1.0 NVIDIA A100 On this page Tools and Frameworks Notebook Images HPE Ezmeral Data Fabric Operating System GPU Models Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Reference/support-matrices.html",
        "title": "Support Matrix"
    },
    {
        "content": "\nRelease Notes Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Installation Provides links to HPE Ezmeral Unified Analytics Software installation and service activation topics. Identity and Access Management Describes identity and access management in HPE Ezmeral Unified Analytics Software . Expanding the Cluster Describes how to add additional user-provided hosts to the management cluster to increase resource capacity and how     to expand the cluster to include the additional user-provided hosts. Shutting Down an HPE Ezmeral Unified Analytics Software Cluster Describes how to gracefully shut down an HPE Ezmeral Unified Analytics Software cluster when you want to perform maintenance or upgrade     tasks. Importing Applications and Managing the Application Lifecycle Describes how to import, manage, and secure applications and frameworks in HPE Ezmeral Unified Analytics Software . Connecting to External S3 Object Stores Describes how to connect HPE Ezmeral Unified Analytics Software to external S3 object storage in AWS, MinIO, and HPE Ezmeral Data Fabric Object Store . Connecting to External HPE Ezmeral Data Fabric Clusters Describes how to connect HPE Ezmeral Unified Analytics Software to an external HPE Ezmeral Data Fabric cluster. Configuring Endpoints Describes the endpoints in HPE Ezmeral Unified Analytics Software and how to configure them. GPU Support Provides information about support for NVIDIA GPU, MIG partitioning, preparing hosts     for GPU-enabled environment, adding hosts and enabling GPU in HPE Ezmeral Unified Analytics Software . Troubleshooting Describes how to identify and debug issues in HPE Ezmeral Unified Analytics Software . Support Matrix The tables on this page show the tools and frameworks, HPE Ezmeral Data Fabric ,operating system       versions , and GPU models that are supported for HPE Ezmeral Unified Analytics Software releases. Release Notes This document provides a comprehensive overview of the latest updates and enhancements     in HPE Ezmeral Unified Analytics Software (version     1.3.0), including new features, improvements, bug fixes, and known issues. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Release Notes This document provides a comprehensive overview of the latest updates and enhancements\n    in HPE Ezmeral Unified Analytics Software (version\n    1.3.0), including new features, improvements, bug fixes, and known issues. HPE Ezmeral Unified Analytics Software provides\n      software foundations for enterprises to develop and deploy end-to-end data and advanced\n      analytics solutions from data engineering to data science and machine learning across hybrid\n      cloud infrastructures \u2013 delivered as a software-as-a-service model. New Features HPE Ezmeral Unified Analytics Software on\n              Openshift In this release, HPE Ezmeral Unified Analytics Software extends installation support to the OpenShift container\n                orchestration platform. The power of OpenShift makes HPE Ezmeral Unified Analytics Software deployment\n                agile, scalable, and efficient, enabling enterprises to streamline their analytics\n                workflows. For details, see Installing HPE Ezmeral Unified Analytics Software on OpenShift . Data Source Access Control With this release, HPE Ezmeral Unified Analytics Software introduces the ability to fine-tune data source access\n                permissions to individual users. Administrators can assign data access permissions\n                to entire data sources, specific schemas/tables, or buckets. New users are denied\n                access to any data source by default and admins can also make data sources public to\n                all users. Data access policies are enforced across all Unified Analytics applications and programmatic data access clients.\n                This feature allows administrators to safeguard sensitive data, ensuring that only\n                allowed personnel can access restricted information and operate in compliance with\n                corporate data and security policies. For details, see Managing Data Access . HPE MLDE as Part of Unified Analytics HPE Machine Learning Development Environment ( HPE MLDE )\n                is now integrated with HPE Ezmeral Unified Analytics Software . This collaboration brings together the capabilities of HPE machine learning tools within a\n                unified environment to provide a cohesive solution for machine learning (ML)\n                development. You can now directly leverage the features of HPE MLDE within HPE Ezmeral Unified Analytics Software , creating a unified ecosystem. This\n                integration enhances overall productivity, accelerates model development, and\n                maximizes the potential of ML and GenAI initiatives. For details, see HPE Machine Learning Development Environment . Enhancements Elevated Security with Advanced Access Management HPE Ezmeral Unified Analytics Software introduces a dual-layered approach to access management through access token renewal\n                and expiration. Within a user's workspace in a Unified Analytics cluster, automatic token renewal allows them to seamlessly engage in prolonged\n                activities, minimizing disruptions in their workflows. Concurrently, each access\n                token is set to expire quickly; if a token is obtained by some other party through\n                an exploit, the window in which it can be used to act as the authorized user is\n                minimized. This enhancement strengthens the overall security posture, instilling users with\n                increased confidence in safeguarding their analytics workloads and ensuring a secure\n                computing environment. Installation Experience In this release, the upgraded HPE Ezmeral Unified Analytics Software installation experience introduces a \u201cPrecheck\u201d\n                feature in the UI. You can now leverage the precheck option to run a preliminary\n                assessment of hardware and host requirements. This proactive step identifies and\n                addresses any potential issues or discrepancies before initiating the setup process\n                for a more efficient and reliable Unified Analytics installation\n                experience. Other Application Upgrades For a list of updated applications, including Airflow, Livy, MLflow, Ray, Spark,\n                and Superset, see Support Matrix . Resolved Issues This release introduces the ability to access infrastructure services log files through the\n        installer UI. Known Issues The following sections describe known issues with workarounds where applicable: Update the SPIFFE CSI driver After installing and deploying HPE Ezmeral Unified Analytics Software , run the following command to update the SPIFFE CSI\n                driver: kubectl -n spire set image ds spire-spiffe-csi-driver spiffe-csi-driver=ghcr.io/spiffe/spiffe-csi-driver:0.2.5 After a reboot, the Unified Analytics hosts may not be ready\n                due to an issue with the SPIFFE CSI driver; updating SPIFFE CSI may resolve it. For\n                details, see Host (Node) Management . EzPresto does not release memory when a query completes EzPresto retains allocated memory\n                after query completion for subsequent queries because of an open-source issue ( https://github.com/prestodb/presto/issues/15637 ).\n                For example, if a query uses 10GB of memory, EzPresto does not release the memory when the query completes and then\n                uses it for the next query. If the next query requires additional memory, for\n                instance, 12GB, EzPresto accumulates an extra 2GB and does not release it after query completion. For\n                assitance, contact HPE support. Configuration changes to long-running pods are\n              not applied in Ray Configuration changes or upgrades to long-running pods in Ray, such as adjusting\n                resource capacities or expanding persistent volume (PV) storage are not applied in\n                Ray. Workaround To ensure successful configuration changes or upgrades, manually delete relevant\n                pods after the reconfiguration or upgrade process. For details, see https://github.com/ray-project/kuberay/issues/527 . Worker nodes do not automatically spawn with JobSubmissionClient in the Ray cluster When submitting jobs to the Ray cluster using JobSubmissionClient ,\n                worker nodes do not spawn automatically. Workaround To ensure proper functionality when submitting Ray jobs using JobSubmissionClient , you must manually specify entry point\n                resources as follows: For CPU, set entrypoint_num_cpus to 1 For GPU, set entrypoint_num_gpus to 1 For details, see Using JobSubmissionClient to Submit Ray Jobs . HPE is actively engaging with the community to address this open-source issue\n                  ( https://github.com/ray-project/ray/issues/42436 ). Installation of Unified Analytics on Azure -PPH may get\n              stuck Installation of Unified Analytics on Azure -PPH may get stuck\n                because of a slower disk. A faster read/write disk (such as SSD) may overcome the\n                issue. Installer UI does not display the ingress gateway node IP addresses In rare instances, the installer UI might not display the ingress gateway node IP\n                addresses post installation. These IP addresses are needed for configuring the DNS A\n                record. If you encounter this issue, please refer to the provided guidelines here to\n                retrieve the IP address. For details, see User Interface . Long-running Spark applications exceed disk\n              quotas for Spark History Server Repeatedly running long-running Spark applications generates a large volume of logs\n                in the Spark History Server event log directory. This can exceed disk quotas,\n                causing failures in other Spark applications. You must monitor log sizes and manage\n                disk space to mitigate this issue. For details, see Spark . NVIDIA GPU Cannot Enforce SELinux Due to a known NVIDIA GPU issue ( https://github.com/NVIDIA/gpu-operator/issues/553 ),\n              SELinux cannot be enforced for GPU deployments. Workaround Set GPU hosts to either disabled or permissive mode until this issue is resolved. Ray Dashboard UI A known Ray issue prevents the Ray Dashboard UI from displaying the GPU worker group\n              details correctly. To see updates regarding resolution and to learn more, see https://github.com/ray-project/ray/issues/14664 . Spark Magic To leverage Spark magic ( %manage_spark ) on Jupyter Notebooks for\n              interactive Livy on GPU, users must manually configure GPU settings\n                ( %config_spark ). For details, see Enabling GPU Support for Livy Sessions . Installation Fails due to Insufficient GPU/CPU The installation process fails if the installation requests more GPU/CPU resources\n              than are available. To prevent installation failures, ensure that the resource\n              requests match the available GPU/CPU capacity. Installation Before you install or upgrade, HPE recommends that you back up your data. Install HPE Ezmeral Unified Analytics Software (version 1.3.0). For instructions, see Installing on User-Provided Hosts (Connected and Air-gapped Environments) . To upgrade from HPE Ezmeral Unified Analytics Software version 1.2.0 to version 1.3.0, please contact the HPE Support\n            Center. If you encounter any issues during or after the installation process, please contact\n        HPE support. We appreciate your feedback and strive to continually enhance your product\n        experience. Additional Resources Documentation Release note archives: 1.2.0 Release Notes Thank you for choosing HPE Ezmeral Unified Analytics Software . Enjoy the new features and improvements introduced in this\u202frelease. On this page New Features Enhancements Resolved Issues Known Issues Installation Additional Resources Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/ReleaseNotes/ua-rn-v1.3.0.html",
        "title": "Release Notes"
    },
    {
        "content": "\nObservability Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to     access log files for the platform and applications. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Observability Describes observability in HPE Ezmeral Unified Analytics Software . Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to     access log files for the platform and applications. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Observability/observability.html",
        "title": "Observability"
    },
    {
        "content": "\nMetering and Billing Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to     access log files for the platform and applications. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Metering involves the measurement and collection of metrics from monitored targets. The\n      metering process is essential for billing purposes and to monitor the usage of key resources\n      within the Kubernetes cluster, such as pods, PVCs, and jobs. Prometheus facilitates the\n      monitoring of these components. Prometheus is an open-source monitoring and alerting system designed for gathering\n      time-series data. Prometheus provides a flexible querying language (PromQL) to retrieve and\n      analyze metrics. HPE Ezmeral Unified Analytics Software consists of platform components and application\n      components such as Kubeflow, Airflow, and others. In HPE Ezmeral Unified Analytics Software ,\n      metering refers to tracking the resource usage, particularly CPU and\n        GPU usage of the components. Metering is used to support accurate billing and to\n      observe the aggregated usage of these components over a specific time period. There are four categories of component workloads (pods): Application core workloads The application core workloads are initialized by the application installer. These\n              workloads allows the instantiation of user-initiated workloads, such as notebooks and\n              jobs. Some examples of these workloads include notebook controllers, EzPresto core querying workloads, and inference job\n              controllers. Application user workloads The application user workloads refers to the user-initiated workloads. Some examples\n              of these workloads include notebooks, inference jobs, Spark jobs etc. Infrastructure or platform workloads The platform workloads perform core platform functions such as monitoring UI,\n              managing users, connecting to Data Fabric, and so on. Bring your own application workloads Bring your own application workloads refers to the workloads that are imported using Import Applications functionality. You must manually specify\n              the labels for workloads in the workload resource yaml files. Configure the resource metadata with the following labels: hpe-ezua/type=\"vendor-service\" hpe-ezua/app=\"<name_of_the_app>\" Pod labels are used to categorize each workload into the four types of workloads. CPU usage\n      is measured every five seconds. After obtaining the initial data, application-related pod\n      labels are used to retrieve the aggregate application usage. For example, the total Kubeflow\n      usage can be calculated by summing up the usage of all pods associated with Kubeflow. Billing and Metering In HPE Ezmeral Unified Analytics Software , billing is performed on an hourly basis. A cron\n        job runs at the top of each hour to compute the average of the aggregated application usage.\n        Daily and monthly aggregations are also calculated, and custom metrics are pushed back to\n        Prometheus. The billing feature leverages these custom metrics to calculate monthly\n        charges. Dashboard An administrator can view the Billing & vCPU Usage dashboard on the HPE Ezmeral Unified Analytics Software homepage. An overview of\n                the daily and monthly aggregated usages for applications is available through the Billing & vCPU Usage dashboard. In this dashboard, you see the daily usage for the Overall category, which includes all applications, including imported applications. To view\n                the resource usage charts for a specific application, select the application from\n                the dropdown. The left side provides the total estimated charges for the month with the daily\n                breakdown. The right side, displays the usage data. In HPE Ezmeral Unified Analytics Software , GPU usage is metered per\n                application and each vGPU counts as an individual GPU for metering. GPU metrics used for metering is DCGM_FI_PROF_GR_ENGINE_ACTIVE\u200b . GPU metrics sampling interval is every five seconds\u200b. The hourly usage is the average GPU utilization over a one hour\n                period\u200b. For example: With 7 small vGPUs and 4 applications using 6 vGPUs as\n                  follows: Applications Pods -vGPU Avg 1hr per vGPU Avg 1hr utilization per application App1 Pods11 - vGPU0 0.8 1.3 Pods12 - vGPU1 0.5 App2 Pods21 - vGPU2 0.8 0.8 App3 Pods31 - vGPU3 0.5 0.5 App4 Pods41 - vGPU4 0 0.5 Pods42 - vGPU5 0.5 Total GPU utilization for billing record is \u200b 1.3 + 0.8 + 0.5 + 0.5 = 3.1\n                vGPU-hour\u200b Top Frameworks provides the list of monthly aggregated usage\n                charges data for all applications in HPE Ezmeral Unified Analytics Software . The total usage for billing is aggregated for all included and imported\n                applications. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Observability/metering.html",
        "title": "Metering and Billing"
    },
    {
        "content": "\nMonitoring Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Model Monitoring Describes model monitoring metrics in HPE Ezmeral Unified Analytics Software . Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to     access log files for the platform and applications. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Monitoring and alerting play an integral role in the observability framework. They involve\n      monitoring the health, performance, and resource utilization of a Kubernetes cluster and its\n      components. Alerts are set up to notify administrators about potential issues. Monitoring and\n      alerting ensures optimal operation of the cluster and its applications while enabling timely\n      responses to critical events. NOTE You cannot configure notifications or turn on notifications. You must view alerts and\n        notifications in HPE Ezmeral Unified Analytics Software . Resource Events The combination of Prometheus and Alertmanager is used to track and to alert in case of\n        unusual resource events. Alerts are triggered for the following events: High resource CPU usage High resource memory usage Unusual pod restart Pods not in running state PVC status not Bound Failed jobs Failed cronjobs Node failures Unsual node memory or CPU usage behavior Kubelet failures Node filesystem issues Node network issues Prometheus issues Viewing Alerts and Notifications To view the list of alerts and notifications in HPE Ezmeral Unified Analytics Software ,\n          perform: Sign in to HPE Ezmeral Unified Analytics Software . Click the bell icon on top-right of HPE Ezmeral Unified Analytics Software homepage. To view all alerts and notifications, click View All . . To manage alerts, click the Actions menu. Dismiss To dismiss the alerts, select Dismiss . View Details To view the decsription and relevant metadata for alerts, select View Details . View Logs To view the pod logs, select View Logs . To download logs, click Download . To search for alerts, use the Search bar. To sort alerts, use Newest or Oldest sort options. To filter alerts, click the filter icon. Model Monitoring Describes model monitoring metrics in HPE Ezmeral Unified Analytics Software . On this page Resource Events Viewing Alerts and Notifications Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Observability/monitoring.html",
        "title": "Monitoring"
    },
    {
        "content": "\nModel Monitoring Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Model Monitoring Describes model monitoring metrics in HPE Ezmeral Unified Analytics Software . Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to     access log files for the platform and applications. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Model Monitoring Describes model monitoring metrics in HPE Ezmeral Unified Analytics Software . Model monitoring is the process of continuously observing and analyzing the performance and\n      behavior of machine learning models deployed in production environments. It is a critical\n      aspect of the machine learning lifecycle that ensures models remain reliable, accurate, and\n      aligned with the intended objectives. Model monitoring involves the collection, analysis, and visualization of various metrics and\n      data related to the model's performance and data characteristics. It is an iterative process\n      that helps ensure model reliability and enables timely adjustments or updates to maintain\n      optimal performance. Model monitoring plays a crucial role in building trust in machine\n      learning systems and making informed decisions based on model outputs. Model monitoring metrics are essential to track and measure the performance of the deployed\n      models. In HPE Ezmeral Unified Analytics Software , you can use KServe or MLflow for monitoring\n      operational performance and whylogs for functional performance. Collected Metrics Knative metrics Knative Serving does not have built-in native support for model monitoring metrics.\n                You can integrate Kserve with other monitoring and observability tools to collect\n                and analyze metrics related to the performance and behavior of your deployed\n                models.(Prometheus, Grafana, Kiali, ESK etc) To learn more, see Importing dashboards to Grafana . The following metrics are collected via KServe: Knative Serving: Revision HTTP Requests Knative Serving: Scaling Debugging Knative Serving: Revision CPU and Memory Usage Knative: Reconciler Knative Serving: Control Plane Efficiency MLflow metrics Use OTel to collect and export the telemetry data from MLflow applications,\n                including metrics, traces, and logs, to third-party or external monitoring systems\n                such as Prometheus, Jaeger, or Grafana for analysis and visualization. To learn\n                more, see Configuring Endpoints . The following metrics are collected via MLflow: mlflow_http_request_total : Total number of incoming HTTP\n                    requests. mlflow_http_request_duration_seconds_sum : Total duration in\n                    seconds of all incoming HTTP requests. mlflow_http_request_duration_seconds_count : Total count of\n                    all incoming HTTP requests. Model Monitoring with whylogs NOTE This feature is presented as a developer preview. Developer preview are not tested for\n          production environments, and should be used with caution. whylogs is an open-source library for logging any kind of data. With whylogs, you can\n        generate summaries of your datasets (data profiles) that you can use to: Track changes in the dataset and detect data drifts in the model input features. Create data constraints to validate data quality in model inputs or in a data\n            pipeline. Detect training-serving skew, concept drift, and model performance degradation. Perform exploratory data analysis of massive datasets. Track data distributions and data quality for ML experiments. Standardize data documentation practices across the organization. Visualize the key summary statistics about the datasets in HTML and JSON file\n            formats. To learn more about whylogs, see whylogs documentation . HPE Ezmeral Unified Analytics Software enables you to use an open-source library called\n        whylogs in the preview environment. whylogs is integrated into the Notebook as a third-party\n        package. You can access data from external S3 object store when using whylogs for\n        monitoring. To learn more about accessing data, see Accessing Data in External S3 Object Stores . The following applications and frameworks support whylogs in HPE Ezmeral Unified Analytics Software : Airflow. See Using whylogs with Airflow . MLflow. See Using whylogs with MLflow . NOTE HPE Ezmeral Unified Analytics Software supports external data sources such as AWS, MinIO for whylogs with MLflow. You can not\n              use S3 proxy as a data source. Ray. See Using whylogs with Ray . Spark. See Using whylogs with Spark . On this page Collected Metrics Model Monitoring with whylogs Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Observability/model-metrics-monitoring.html",
        "title": "Model Monitoring"
    },
    {
        "content": "\nLogging Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to     access log files for the platform and applications. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to\n    access log files for the platform and applications. Logging is crucial for monitoring and troubleshooting applications and the cluster\n      infrastructure. Logs capture, collect, and store data generated by applications, containers,\n      and Kubernetes components running in a Kubernetes cluster. In HPE Ezmeral Unified Analytics Software , you can easily access log files to monitor and troubleshoot issues. Log Rotation Logs are automatically rotated to ensure that the shared 1 directory does not exceed the limit of 10 MB per file to prevent storage issues. When the\n        file size surpasses 10 MB, the old copy is retained, and a new log file is created,\n        effectively managing storage and keeping it under control. NOTE Only one old copy of 10 MB\n          is retained at any time. For example, the airflow-ui.log undergoes renaming as airflow-ui.log.1 when it exceeds 10 MB in size. Simultaneously, a new log\n        file named airflow-ui.log is created. Similarly, if the size of the new airflow-ui.log file exceeds the 10 MB threshold, the current airflow-ui.log.1 log file is replaced with the new logs from the airflow-ui.log file. This log rotation process ensures efficient\n        management of log files while maintaining the specified size limit. 1 The shared directory is persistent volume storage shared by\n        all users. Accessing Log Files To access the log files: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, go to Data Engineering > Data\n              Sources . Select the Data Volumes tab. On the Data Volumes tab, select the shared folder. In the shared folder, select the logs/ directory. The logs/ directory contains the following subdirectories with logging data: apps/ Contains platform and application component logs. If you open this directory, it\n                  contains the following subdirectories: app-core/ Contains logs for core application pods. app-user/ Contains logs for user-initiated pods such as notebooks, inference jobs,\n                        Spark jobs, and others. platform/ Contains infrastructure pod logs. audit/ Contains the native Kubernetes audit logs. The native Kubernetes audit logs\n                  record requests made to the Kubernetes API server, such as which users or services\n                  requested access to cluster resources and why the requests were authorized or\n                  rejected. system/ Contains system node service logs. TIP The Actions column provides options that you can use on\n              directories and log files, for example: Open, rename, or delete a folder or directory Rename, download, or delete log files On this page Log Rotation Accessing Log Files Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Observability/logging.html",
        "title": "Logging"
    },
    {
        "content": "\nAudit Logging Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Metering and Billing Describes metering and billing in HPE Ezmeral Unified Analytics Software . Monitoring Describes monitoring and alerting in HPE Ezmeral Unified Analytics Software . Logging Describes how logging works in HPE Ezmeral Unified Analytics Software and how to     access log files for the platform and applications. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Audit Logging Describes auditing in HPE Ezmeral Unified Analytics Software and how to access audit logs. Auditing provides a chronological set of records that document the events that occur in an HPE Ezmeral Unified Analytics Software cluster. Auditing records user, application, and control plane events (that occur through the UI and\n      programmatic access via APIs or CLIs) in audit logs. Audit logs maintain records of actions\n      for accountability, tracking, and compliance purposes. Auditing provides the following information about actions in HPE Ezmeral Unified Analytics Software : Type of action User or application that triggered the action Timestamp (time the action occurred) Status of the action (Failed, Started, Success) Audited Actions The following tables lists the actions that auditing captures in the audit logs: Area Description Platform Captures successful and failed login attempts by users. Administration Captures the add/delete/modify user actions performed by a user assigned the\n                  administrator role. Billing & Licensing Captures the license related actions performed by the platform\n                  administrator. Captures the billing and activation related actions performed by the platform\n                    administrator, including: Creation of billing credentials and signing-key Creation billing and license credentials and signing-key in airgapped\n                        environments Downloading of metering usage in airgapped environments Uploading of metering usage Renewal of billing and license credentials Keycloak Captures Keycloak realm updates when the product is deactivated or activated\n                  (triggered from enabled to disabled and vice versa). Kubeflow Captures the creation of a notebook in Kubeflow. The audit message contains\n                  information about the name/namespace and whether the API call was a dry\n                  run. Captures the deletion of a notebook in Kubeflow. The audit message contains\n                  information about the name/namespace and whether the API call was a dry\n                  run. Captures the creation of a Create KServe Inference Service in Kubeflow. The\n                  audit message contains information about the name/namespace and whether the API\n                  call was a dry run. Captures the deletion of a Create KServe Inference Service in Kubeflow. The\n                  audit message contains information about the name/namespace and whether the API\n                  call was a dry run. Spark Spark application submitted using Spark operator. Spark application deleted using Spark operator. Scheduled Spark application submitted using Spark operator. Scheduled spark application deleted using Spark operator. NOTE Livy doesn't support audit logging. Airflow User disabled or enabled a DAG. Captures DAG ID and username. User started DAG execution. Captures DAG execution time, DAG ID, and\n                  username. DAG task scheduled after triggering the DAG. Captures DAG run ID, DAG ID, and\n                  task ID. DAG task running after scheduling. Captures DAG execution time, DAG ID, task\n                  ID, and username. DAG task succeeded after running. Captures DAG execution time, DAG ID, task\n                  ID, and username. DAG task failed after running. Captures DAG execution time, DAG ID, task ID,\n                  and username. EzPresto Query completed event. Audits the user, query, timestamp, status, type of\n                  query, and client-ip. Audits the data source name, data source type, user, timestamp, and\n                  status. Audits the user, create view query, timestamp, and status. Audtis the user, cache table details, remote table details, and\n                  status. Accessing Audit Logs Administrators can access audit logs by signing in to HPE Ezmeral Unified Analytics Software UI and selecting Administration >\n          Audit Logs in the left navigation bar. The list of audit logs display on the Audit Logs page. Viewing Audit Logs for a Period of Time You can view the audit logs for a given time period by clicking into the dropdown\n                field. The dropdown has the following options: Option Description 1 hour See the audit logs recorded during the past hour. 6 hours See the audit logs recorded during the past six hours. Today Today is the current date, starting at 12:00 am. For example, if you\n                          select Today and the date is July 19 th and the time is 5:00 pm,\n                          you will see all the audit logs that were recorded between 12:00am and\n                          5:00pm on July 19 th . Date and time is based on local time. If\n                          two people are in different time zones, each person will see results based\n                          on their respective time zones when they select Today. Custom Click the calendar icon and select one or more days. To select\n                          multiple days, click the first day and then click the last day. Select the\n                          start and end times. For multiple days, the start time is the start time\n                          on day one and the end time is the end time on the last day. Searching Audit Logs You can search audit logs for records that match specified search criteria. For\n              example, you can search on keywords and tags, including event type, users, date range,\n              and failed attempts. Filtering Audit Logs Clicking the filter icon opens the Filters drawer where you can select one or\n              more filter options. You can filter by: Actions Statuses Users Clicking Reset clears the filters. Click Apply after you click Reset to save the update. Downloading Audit Logs Clicking Download Logs downloads the audit logs for the given time period to\n              an Excel file. Moving Audit Logs You can use the OTel endpoint to move audit logs to a third-party application, such as\n        Grafana or ElasticSearch. You may want to move audit logs for the following reasons: Audit Log Expiration Audit logs are immutable and persist for sixty days. The system automatically\n              deletes audit logs after sixty days. If you want the audit logs to persist beyond\n              sixty days, use the OTel endpoint to move the logs to a third-party application. Multiple HPE Ezmeral Unified Analytics Software Instances If you have multiple instances of HPE Ezmeral Unified Analytics Software running, each instance maintains its own audit logs. You\n              can use OTel to fetch the audit logs from each instance and move them to your\n              monitoring environment. See Configuring Endpoints for more information. On this page Audited Actions Accessing Audit Logs Moving Audit Logs Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Observability/audit-logging.html",
        "title": "Audit Logging"
    },
    {
        "content": "\nData Engineering Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Data Engineering Data engineers can design and build pipelines that transform and transport data into\n    usable formats for data consumers. HPE Ezmeral Unified Analytics Software includes\n      connectors for several data sources that facilitate data virtualization by providing a single\n      point of uniform, controlled access to distributed data, regardless of the compute engine. \n      You can use open-source tools, such as Apache Spark and Apache Airflow, to extract data from\n      disparate sources and create transformed data sets for data consumption. For example, you can run a Spark job to move data from one data source (such as Snowflake)\n      into another data source (such as HPE Ezmeral Data Fabric ) and then connect HPE Ezmeral Unified Analytics Software to the HPE Ezmeral Data Fabric data source. Once connected to HPE Ezmeral Data Fabric , you can work with the data (join and transform) to create\n      consumable models for users and applications. Data consumers with appropriate permissions can use\n      data in their analytical workloads, data science workflows, dashboards, or for data\n      modeling. Working with Data The Data Engineering space provides access to interfaces that enable you to use EzPresto , the SQL query engine in HPE Ezmeral Unified Analytics Software , to work with data. The following list describes what you can do through each of the interfaces in the Data\n        Engineering space: Data Sources Connect HPE Ezmeral Unified Analytics Software to external data sources. Each connected data source displays as\n              a tile on the screen. You can also remove data sources or access the Query Editor from\n              each data source tile. See Connect Data Sources . When you connect HPE Ezmeral Unified Analytics Software to\n                various data sources, you can access the data in those data sources from Superset and then visualize the data. Data Catalog Select data sets (tables and views) from one or more data sources and run federated\n              queries. You can also cache data sets. Caching stores the data in a distributed\n              caching layer within the data fabric for accelerated access to the data. See Cache Data . Query Editor Run queries against the selected data sets. You can also create views and new\n              schemas. Cached Assets Lists the cached data sets (tables and views). See Cache Data . Airflow Pipelines Links to the Airflow interface where you can connect to data sets created in HPE Ezmeral Unified Analytics Software and\n              use them in your data pipelines. See Airflow . Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . More information Get Started Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/DataEngineering/data-engineering.html",
        "title": "Data Engineering"
    },
    {
        "content": "\nAccessing Data in External S3 Object Stores Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. Using Spark to Access S3 Object Storage Describes how to use Spark to access data in connected object storage. Using KServe to Deploy a Model on S3 Object Storage Describes how to deploy a KServe model on S3 object storage from a Kubeflow     notebook. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and\n    Kubeflow notebooks. After an administrator connects HPE Ezmeral Unified Analytics Software to an external object store in AWS, MinIO, or HPE Ezmeral Data Fabric Object Store , you can access data in those data sources through clients, such as\n      Spark or Kubeflow notebooks, without providing an access key or secret key. Your HPE Ezmeral Unified Analytics Software administrator provided\n      the access credentials when creating the data source connection. Your access to the data\n      source is authorized through HPE Ezmeral Unified Analytics Software . To connect a client to an object store, you provide the client with the data source name,\n      endpoint URL, and bucket that you want the client to access. You can find the data source name\n      and endpoint URL on the data source tile in the HPE Ezmeral Unified Analytics Software UI. Once connected, clients can: Read and download files in a bucket Upload files from a bucket Create buckets Getting the Data Source Name and Proxy Endpoint URL To get the data source name and proxy endpoint URL: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Data Engineering > Data Sources . On the Data Sources page, find the tile for the object store you want to connect\n          to. The following image shows an example of a tile for an AWS S3 data source with the\n            name aws-s3 and the enpoint URL: NOTE A local-s3 MinIO\n              tile is also displayed. This local version of MinIO is used internally by HPE Ezmeral Unified Analytics Software . Do not connect\n              to this data source. Note the data source name and endpoint URL and then use them to configure\n          the client. Using Spark to Access S3 Object Storage Describes how to use Spark to access data in connected object storage. Using KServe to Deploy a Model on S3 Object Storage Describes how to deploy a KServe model on S3 object storage from a Kubeflow     notebook. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/client-connect-s3.html",
        "title": "Accessing Data in External S3 Object Stores"
    },
    {
        "content": "\nUsing Spark to Access S3 Object Storage Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. Using Spark to Access S3 Object Storage Describes how to use Spark to access data in connected object storage. Using KServe to Deploy a Model on S3 Object Storage Describes how to deploy a KServe model on S3 object storage from a Kubeflow     notebook. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using Spark to Access S3 Object Storage Describes how to use Spark to access data in connected object storage. Spark can access object storage through the S3 proxy server or directly through the object\n        store endpoint, bypassing the proxy server. Spark needs a secret to securely pass configuration values. Use the S3 Proxy\n          Connection or Direct S3 Access method to create a secret and configure the\n        access information (access key and secret key). Then, update the Spark application YAML with\n        the secret and required connection properties. S3 Proxy Connection Run the following script in a notebook to generate the secret. You can also access a sample\n        script from your notebook server in the shared/ezua-tutorials/Data-Analytics/ directory. Example Script def deploy_s3_secret(namespace, spark_secret):\n    try:\n        #Run kubectl apply command using subprocess\n        subprocess.run(['kubectl', 'delete', 'secret', spark_secret, '-n', namespace], check=False)\n        subprocess.run(['kubectl', 'create', 'secret', 'generic', spark_secret, '-n', namespace , '--from-file=spark-defaults.conf'], check=True)\n        print(\"Secret creation successful!\")\n        except subprocess.CalledProcessError as e:\n        print(f\"Secret creation  failed. Error: {e}\")\n\n\ns3_access_data = \"spark.hadoop.fs.s3a.access.key EXAMPLE_ACCESS_KEY\"\ns3_secret_data = \"spark.hadoop.fs.s3a.secret.key EXAMPLE_SECRET_KEY\"\n\ns3_data = s3_access_data.replace('EXAMPLE_ACCESS_KEY', os.environ['AUTH_TOKEN'])\ns3_data += \"\\n\" + s3_secret_data.replace(\"EXAMPLE_SECRET_KEY\", \"s3\")    \n\nnamespace = os.environ['USER']\nspark_secret = \"spark-s3-secret\"\n\n#Save data to a file spark-defaults.conf\nwith open('spark-defaults.conf', 'w') as file:\n    file.write(s3_data)\n\n\n# Call the function to deploy the Kubernetes secret\ndeploy_s3_secret(namespace, spark_secret) Direct S3 Access (Bypass S3 Proxy Server) Create a spark-defaults.conf file to generate the secret. Provide the\n        object store access key and secret key as values for the spark.hadoop.fs.s3a.access.key and spark.hadoop.fs.s3a.secret.key properties in the file. Create a spark-defaults.conf file with the following\n            properties: spark.hadoop.fs.s3a.access.key EXAMPLE_ACCESS_KEY\nspark.hadoop.fs.s3a.secret.key EXAMPLE_SECRET_KEY Create a secret from the spark-defaults.conf file: kubectl create secret generic <k8s-secret-name> --from-file=spark-defaults.conf Connect the Spark Application to the Object Store Verify that the disable-chunk-encoding-334.jar file is in the shared/ezua-tutorials/Data-Analytics/Spark directory and then update the\n        Spark application YAML with the required connection properties, including the secret\n          name. IMPORTANT Regardless of how you generated the secret and whether you\n          used the S3 proxy or bypassed the proxy, you must complete the steps in this section to\n          connect the Spark application to the object store. If the disable-chunk-encoding-334.jar file is not in the shared/ezua-tutorials/Data-Analytics/Spark folder, navigate to the shared directory to get the file and then add it to shared/ezua-tutorials/Data-Analytics/Spark . Update the sparkConf section of the Spark application YAML to include\n            the following information: Secret Bucket name (name of the bucket in the S3 object store) Data source name Proxy endpoint URL For details, see Accessing Data in External S3 Object Stores . The following example shows the Spark application YAML configuration: sparkConf:\n  spark.mapr.extraconf.secret: \"<k8s-secret-name>\"\n  spark.hadoop.fs.s3a.s3.client.factory.impl: org.apache.hadoop.fs.s3a.NonChunkedDefaultS3ClientFactory\n  spark.driver.extraClassPath: /mounts/shared-volume/spark/disable-chunk-encoding-334.jar\n  spark.hadoop.fs.s3a.bucket.<my_bucket>.endpoint: http://<data-source-name>-<proxy-endpoint-url>\n\n//Example\nsparkConf:\n  spark.mapr.extraconf.secret: \"mysecret\"\n  spark.hadoop.fs.s3a.s3.client.factory.impl: org.apache.hadoop.fs.s3a.NonChunkedDefaultS3ClientFactory\n  spark.driver.extraClassPath: /mounts/shared-volume/spark/disable-chunk-encoding-334.jar\n  spark.hadoop.fs.s3a.bucket.bucket10.endpoint: http://s3-datafabric-service.ezdata.svc.cluster.local:30000 On this page S3 Proxy Connection Direct S3 Access (Bypass S3 Proxy Server) Connect the Spark Application to the Object Store Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/spark-object-store-access.html",
        "title": "Using Spark to Access S3 Object Storage"
    },
    {
        "content": "\nUsing KServe to Deploy a Model on S3 Object Storage Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. Using Spark to Access S3 Object Storage Describes how to use Spark to access data in connected object storage. Using KServe to Deploy a Model on S3 Object Storage Describes how to deploy a KServe model on S3 object storage from a Kubeflow     notebook. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using KServe to Deploy a Model on S3 Object Storage Describes how to deploy a KServe model on S3 object storage from a Kubeflow\n    notebook. You can deploy a KServe model on the S3 object storage that your administrator connected to HPE Ezmeral Unified Analytics Software . Add YAML configurations that perform the following actions and then run the code from a\n      Kubeflow notebook: Create a service account Create a secret IMPORTANT When you create the secret, note that the {os.environ['AUTH_TOKEN']} option assigns a value to the AWS_ACCESS_KEY_ID . The value assigned is the value on the JWT for the\n            current notebook user. Deploy a model ( InferenceService ) Apply the YAML ( !kubectl apply -f {yaml_name} ) The following example shows a YAML\n      configuration: best_model_uri =    '<path_to_the_model>'  # for example 's3://mlflow/2/0e4508d276a0427cb67da7630acb2e14/artifacts/model'\nsecret_name = 's3-proxy-kserve-secret'\nsa_name = 's3-proxy-kserve-sa'\ninference_service_name = \"service-name\"\nyaml_name = './s3-proxy-kserve.yaml'\n\n############################################\n\nwith open(yaml_name, 'w') as file:\n    text = f\"\"\"---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: \"{secret_name}\"\n  annotations:\n    serving.kserve.io/s3-cabundle: \"\"\n    serving.kserve.io/s3-endpoint: \"local-s3-service.ezdata-system.svc.cluster.local:30000/\"\n    serving.kserve.io/s3-useanoncredential: \"false\"\n    serving.kserve.io/s3-usehttps: \"0\"\n    serving.kserve.io/s3-verifyssl: \"0\"\nstringData:\n  AWS_ACCESS_KEY_ID: \"{os.environ['AUTH_TOKEN']}\"\n  AWS_SECRET_ACCESS_KEY: \"s3\"\ntype: Opaque\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: \"{sa_name}\"\nsecrets:\n  - name: \"{secret_name}\"\n\n---\napiVersion: \"serving.kserve.io/v1beta1\"\nkind: \"InferenceService\"\nmetadata:\n  name: \"{inference_service_name}\"\nspec:\n  predictor:\n    serviceAccountName: \"{sa_name}\"\n    sklearn:\n      protocolVersion: \"v2\"\n      storageUri: \"{best_model_uri}\"\n\"\"\"\n    file.write(text)\n   \n############################################\n!kubectl apply -f {yaml_name} Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/kserve-access-object-store.html",
        "title": "Using KServe to Deploy a Model on S3 Object Storage"
    },
    {
        "content": "\nEzPresto Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. EzPresto Describes the EzPresto SQL query engine\n    and its featues. EzPresto in HPE Ezmeral Unified Analytics Software EzPresto is an SQL query engine\n        based on the open-source, Linux foundation multi-parallel processing (MPP) query engine\n        PrestoDB, that is optimized to run federated queries across various data sources. Enterprise\n        BI applications such as Tableau, Power BI, and data processing engines, such as Spark, can\n        leverage EzPresto for rapid query performance\n        and prompt insights through federated data access. You can easily connect EzPresto to multiple\n        types of data sources from the Data Engineering space in HPE Ezmeral Unified Analytics Software by going to Data Engineering > Data Sources . Connections require a JDBC\n        connection URL and user credentials. Data sets available to the connected user display in the Data Catalog, which is accessible\n        by going to Data Engineering > Data Catalog . In the Data Catalog, you\n        select the data sets you want to work with. You can query or cache the selected datasets. When you opt to cache data sets, you can modify the data sets prior to caching them. For\n        example, you can edit table and column names, remove columns, and create new schema. Cached\n        data sets (tables and views) are accessible in the Cached Assets space of HPE Ezmeral Unified Analytics Software . You can access\n        cached assets by going to Data Engineering > Cached Assets . When you opt to query data sets, you can run federated queries (query across data sets in\n        multiple data sources) from the Query Editor. You can access the Query Editor by going to Data Engineering > Query Editor . Querying cached data sets\n        accelerates queries for significant performance gains. You can access the data in connected data sources from Superset and visualize the data that\n        results from complex, federated queries. Superset is accessible in HPE Ezmeral Unified Analytics Software by going to BI Reporting > Dashboards or Applications &\n          Frameworks > Data Engineering tab and clicking Open in the Superset\n        tile. See Superset . You can also monitor the state of queries\n        and query details, including the query plan and resource usage, by going to Administration > EzSQL Cluster Monitoring . Refer to the following tutorials to get started with EzPresto in HPE Ezmeral Unified Analytics Software : Data Source Connectivity and Exploration BI Reporting (Superset) Basics Retail Store Analysis Dashboard (Superset) EzPresto Key Features EzPresto provides the following key benefits\n        and features: Data Source Connectivity EzPresto includes connectors for\n              several data sources, including: HPE Ezmeral Data Fabric HDFS Data Lakes Hive Metastore (including managed HMS services such as AWS Glue) Object Stores Relational Databases NoSQL Databases Streaming data platforms Data warehouses Built-In Data Catalog The built-in data catalog provides dynamic registration of new data sources. Data\n              administrators can add new data sources as they become available without restarting\n              any services. When a data administrator adds a new data source, the data catalog\n              automatically refreshes so users, such as data analysts, can browse the new datasets\n              and perform upstream activities, such as reporting and dashboarding. Role-Based Access Controls Role-based access controls isolate queries such that members (non-admin users) can\n              only view and access their own queries. Admin users have full access to all queries.\n              For example, if a non-admin user runs a query that takes too long to complete or uses\n              too many resources, any admin in HPE Ezmeral Unified Analytics Software can stop the query. Optimized Federated Queries Access data across disparate data sources in a single, optimized query. Query\n              optimizations for accelerated performance include: Predicate pushdown - EzPresto pushes filters in the WHERE clause down to the data source for processing to\n                  reduce the number of rows returned. Projection pushdown - EzPresto pushes projects (scanning of selected columns) down to the data source for\n                  processing to reduce the amount of data returned. Dynamic filtering - EzPresto evaluates predicates on the right side of a join and pushes them to the left side\n                  of the join to reduce the number of rows scanned from the left table. Cost-based optimization - EzPresto uses table statistics to calculate the cost (resource usage) of various query\n                  plans and chooses the optimal plan (plan that uses the least resources) to run the\n                  query. Distributed Caching EzPresto accelerates federated queries\n              through distributed caching of commonly used datasets. EzPresto currently supports explicit\n                caching where you manually modify tables and select the data that you want\n              cached for fast query access. You can use explicitly cached data for data modeling. EzPresto stores cached data in a data\n              fabric volume. The cache expires based on the set TTL (time-to-live). See Connect Data Sources and Cache Data . Explicit Caching You manually modify tables and select the data in the tables that you want\n                    stored in the cache for fast query access. You can use explicitly cached data\n                    for data modeling. You can set a TTL (time to live) for the cache. Self-Service Data Access End-users can browse data sets they have access to and select the relevant data for\n              their queries and analytical applications and workloads. Run-Anywhere Architecture EzPresto has a run-anywhere\n              architecture; you can run EzPresto on-premises, on edge, in the cloud, or hybrid environments. EzPresto Architecture The EzPresto architecture consists of the\n        following main components: Presto EzPresto uses a modified version of\n              Presto as the query engine. Most of the modifications are in the query planning and\n              optimizer areas, as well as support for different data sources, such as Teradata and\n              Snowflake, and in-process caching based on Apache Geode, tuned for OLTP and OLAP\n              access. The cache provides a tuple store with specialized columnar formats. WebService Provides the API. Web UI Provides the ability to access EzPresto in applications. Client Connections Provides the ability to connect to BI tools and external data sources via the JDBC\n              client. KeyCloak KeyCloak provides the authentication mechanism and different authentication options,\n              such as LDAP and JWT. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. More information Data Source Connectivity and Exploration On this page EzPresto in HPE Ezmeral Unified Analytics Software EzPresto Key Features EzPresto Architecture Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/ezpresto.html",
        "title": "EzPresto"
    },
    {
        "content": "\nConnect Data Sources Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. HPE Ezmeral Unified Analytics Software includes\n      PrestoDB connectors for multiple types of data sources. Connecting to an external data source\n      is as simple as selecting the data source type and providing the required connection\n      parameters and credentials. Connecting data sources enables federated access to data for users\n      with the appropriate permissions. IMPORTANT Only HPE Ezmeral Unified Analytics Software administrators can create data source connections. Each data source connection that you create must have a unique name. For example, you\n            can create multiple Hive data source connections, but each connection created must have\n            a different name. Access to data in a data source is based on the username and password supplied when\n            creating the data source connection. Data sources are accessible to all users with\n            permission once they are connected. Complete the following steps to connect a data source: Log in to HPE Ezmeral Unified Analytics Software . Click Sign-in with SSO and enter your username and password. In the left navigation pane, select Data Engineering > Data Sources . Click Add New Data Source . Locate the tile with the type of data source that you want to connect, and click Create Connection . For example, if you want to connect to a Hive data source,\n          locate the Hive tile and click Create Connection in the Hive tile. In the drawer that opens, enter the connection parameters and then click Connect . TIP For every data source that you connect, you have the\n            option to select the following caching options: Enable Local Snapshot Table caches remote table data to accelerate\n                queries on the tables. The cache is active for the duration of the configured TTL\n                (time-to-live) or until the remote tables in the data source are altered. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/connect-data-sources.html",
        "title": "Connect Data Sources"
    },
    {
        "content": "\nDelta Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data\n    types. The following tables list the required and optional Delta connection parameters. Required Connection Parameters NOTE Delta connector values varies based on type of metastore. See https://prestodb.io/docs/current/connector/deltalake.html . Parameter Description Default Value Data Type Hive Metastore The type of Hive metastore to use thrift STRING Enable Local Snapshot Table Enable Caching while querying true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Delta Parquet Dereference Pushdown Enabled Enable pushing nested column dereferences into table scan so that only\n                      the required fields selected in a struct data type column are selected true BOOLEAN Delta Max Splits Batch Size Delta : Max split batch size 200 INTEGER Delta Max Partitions Per Writer Delta : Maximum number of partitions per writer 100 INTEGER Hive Metastore The type of Hive metastore to use thrift STRING Hive Insert Overwrite Immutable Partitions Enabled When enabled, insertion query will overwrite existing partitions when\n                      partitions are immutable. This config only takes effect with\n                      hive.immutable-partitions set to true false BOOLEAN Hive Create Empty Bucket Files For Temporary Table Create empty files when there is no data for temporary table buckets false BOOLEAN Hive Enable Parquet Batch Reader Verification Enable optimized parquet reader false BOOLEAN Hive Create Empty Bucket Files For Temporary Table Create empty files when there is no data for temporary table buckets false BOOLEAN Hive Min Bucket Count To Not Ignore Table Bucketing Ignore table bucketing when table bucket count is less than the value\n                      specified, otherwise, it is controlled by property hive.ignore-table-bucketing 0 INTEGER Hive Partition Statistics Based Optimization Enabled Enables partition statistics based optimization, including partition\n                      pruning and predicate stripping false BOOLEAN Hive Experimental Optimized Partition Update Serialization Enabled Serialize PartitionUpdate objects using binary SMILE encoding and\n                      compress with the ZSTD compression false BOOLEAN Hive Materialized View Missing Partitions Threshold Materialized views with missing partitions more than this threshold\n                      falls back to the base tables at read time 100 INTEGER Hive S3select Pushdown Max Connections The maximum number of client connections allowed for those operations\n                      from worker nodes 500 INTEGER Hive Temporary Staging Directory Enabled Should use (if possible) temporary staging directory for write\n                      operations true BOOLEAN Hive Temporary Staging Directory Path Location of temporary staging directory for write operations. Use\n                      ${USER} placeholder to use different location for each user. /tmp/presto-${USER} STRING Hive Temporary Table Storage Format The default file format used when creating new tables. ORC STRING Hive Temporary Table Compression Codec The compression codec to use when writing files for temporary tables SNAPPY STRING Hive Use Pagefile For Hive Unsupported Type Automatically switch to PAGEFILE format for materialized exchange when\n                      encountering unsupported types true BOOLEAN Hive Parquet Pushdown Filter Enabled Enable complex filter pushdown for Parquet false BOOLEAN Hive Range Filters On Subscripts Enabled Enable pushdown of range filters on subscripts (a[2] = 5) into ORC\n                      column readers false BOOLEAN Hive Adaptive Filter Reordering Enabled Enable adaptive filter reordering true BOOLEAN Hive Parquet Batch Read Optimization Enabled Is Parquet batch read optimization enabled false BOOLEAN Hive Enable Parquet Dereference Pushdown Is dereference pushdown expression pushdown into Parquet reader enabled false BOOLEAN Hive Max Metadata Updater Threads Maximum number of metadata updated threads 100 INTEGER Hive Partial_aggregation_pushdown_enabled Enable partial aggregation pushdown false BOOLEAN Hive Manifest Verification Enabled Enable verification of file names and sizes in manifest / partition\n                      parameters false BOOLEAN Hive Undo Metastore Operations Enabled Enable undo metastore operations true BOOLEAN Hive Verbose Runtime Stats Enabled Enable tracking all runtime stats. Note that this may affect query\n                      performance false BOOLEAN Hive Prefer Manifests To List Files Prefer to fetch the list of file names and sizes from manifests rather\n                      than storage false BOOLEAN Hive Partition Lease Duration Partition lease duration 0.00s DURATION Hive Size Based Split Weights Enabled Enable estimating split weights based on size in bytes true BOOLEAN Hive Minimum Assigned Split Weight Minimum weight that a split can be assigned when size based split\n                      weights are enabled 0.05 DOUBLE Hive Use Record Page Source For Custom Split Use record page source for custom split. By default, true. Used to query\n                      MOR tables in Hudi. true BOOLEAN Hive Split Loader Concurrency Number of maximum concurrent threads per split source 4 INTEGER Hive Domain Compaction Threshold Maximum ranges to allow in a tuple domain without compacting it 100 INTEGER Hive Max Concurrent File Renames Maximum concurrent file renames 20 INTEGER Hive Max Concurrent Zero Row File Creations Maximum number of zero row file creations 20 INTEGER Hive Recursive Directories Enable reading data from subdirectories of table or partition locations.\n                      If disabled, subdirectories are ignored. false BOOLEAN Hive User Defined Type Encoding Enabled Enable user defined type false BOOLEAN Hive Loose Memory Accounting Enabled When enabled relaxes memory accounting for queries violating memory\n                      limits to run that previously honored memory thresholds false BOOLEAN Hive Max Outstanding Splits Size Maximum amount of memory allowed for split buffering for each table scan\n                      in a query, before the query is failed 256MB DATASIZE Hive Max Split Iterator Threads Maximum number of iterator threads 1000 INTEGER Hive Allow Corrupt Writes For Testing Allow Hive connector to write data even when data will likely be corrupt false BOOLEAN Hive Create Empty Bucket Files Should empty files be created for buckets that have no data? true BOOLEAN Hive Max Partitions Per Writers Maximum number of partitions per writer 100 INTEGER Hive Write Validation Threads Number of threads used for verifying data after a write 16 INTEGER Hive Orc Tiny Stripe Threshold ORC: Threshold below which an ORC stripe or file will read in its\n                      entirety 8MB DATASIZE Hive Orc Lazy Read Small Ranges ORC read small disk ranges lazily true BOOLEAN Hive Orc Bloom Filters Enabled ORC: Enable bloom filters for predicate pushdown false BOOLEAN Hive Orc Default Bloom Filter Fpp ORC Bloom filter false positive probability 0.05 DOUBLE Hive Orc Optimized Writer Enabled Experimental: ORC: Enable optimized writer true BOOLEAN Hive Orc Writer Validation Percentage Percentage of ORC files to validate after write by re-reading the whole\n                      file 0.0 DOUBLE Hive Orc Writer Validation Mode Level of detail in ORC validation. Lower levels require more memory BOTH STRING Hive Rcfile Optimized Writer Enabled Experimental: RCFile: Enable optimized writer true BOOLEAN Hive Assume Canonical Partition Keys Assume canonical parition keys? false BOOLEAN Hive Parquet Fail On Corrupted Statistics Fail when scanning Parquet files with corrupted statistics true BOOLEAN Hive Parquet Max Read Block Size Parquet: Maximum size of a block to read 16MB DATASIZE Hive Optimize Mismatched Bucket Count Enable optimization to avoid shuffle when bucket count is compatible but\n                      not the same false BOOLEAN Hive Zstd Jni Decompression Enabled Use JNI based zstd decompression for reading ORC files false BOOLEAN Hive File Status Cache Size Hive file status cache size 0 LONG Hive File Status Cache Expire Time Hive file status cache : expiry time 0.00s DURATION Hive Per Transaction Metastore Cache Maximum Size Maximum number of metastore data objects in the Hive metastore cache per\n                      transaction 1000 INTEGER Hive Metastore Refresh Interval Asynchronously refresh cached metastore data after access if it is older\n                      than this but is not yet expired, allowing subsequent accesses to see fresh\n                      data. 0.00s DURATION Hive Metastore Cache Maximum Size Maximum number of metastore data objects in the Hive metastore cache 10000 INTEGER Hive Metastore Refresh Max Threads Maximum threads used to refresh cached metastore data 100 INTEGER Hive Partition Versioning Enabled false BOOLEAN Hive Metastore Impersonation Enabled Should Presto user be impersonated when communicating with Hive\n                      Metastore false BOOLEAN Hive Partition Cache Validation Percentage Percentage of partition cache validation 0.0 DOUBLE Hive Metastore Thrift Client Socks Proxy Metastore thrift client socks proxy null STRING Hive Metastore Timeout Timeout for Hive metastore requests 10.00s DURATION Hive Dfs Verify Checksum Verify checksum for data consistency true BOOLEAN Hive Metastore Cache Ttl Duration how long cached metastore data should be considered valid 0.00s DURATION Hive Metastore Recording Path Metastore recording path null STRING Hive Replay Metastore Recording Replay metastore recording false BOOLEAN Hive Metastore Recoding Duration Metastore recording duration 0.00m DURATION Hive Dfs Require Hadoop Native Hadoop native is required? true BOOLEAN Hive Metastore Cache Scope Metastore cache scope ALL STRING Hive Metastore Authentication Type Hive metastore authentication type. NONE STRING Hive Hdfs Authentication Type HDFS authentication type. NONE STRING Hive Hdfs Impersonation Enabled Should Presto user be impersonated when communicating with HDFS false BOOLEAN Hive Hdfs Wire Encryption Enabled Should be turned on when HDFS wire encryption is enabled false BOOLEAN Hive Skip Target Cleanup On Rollback Skip deletion of target directories when a metastore operation fails and\n                      the write mode is DIRECT_TO_TARGET_NEW_DIRECTORY false BOOLEAN Hive Bucket Execution Enable bucket-aware execution: only use a single worker per bucket true BOOLEAN Hive Bucket Function Type For Exchange Hash function type for exchange HIVE_COMPATIBLE STRING Hive Ignore Unreadable Partition Ignore unreadable partitions and report as warnings instead of failing\n                      the query false BOOLEAN Hive Max Buckets For Grouped Execution Maximum number of buckets to run with grouped execution 1000000 INTEGER Hive Sorted Write To Temp Path Enabled Enable writing temp files to temp path when writing to bucketed sorted\n                      tables false BOOLEAN Hive Sorted Write Temp Path Subdirectory Count Number of directories per partition for temp files generated by writing\n                      sorted table 10 INTEGER Hive Fs Cache Max Size Hadoop FileSystem cache size 1000 INTEGER Hive Non Managed Table Writes Enabled Enable writes to non-managed (external) tables false BOOLEAN Hive Non Managed Table Creates Enabled Enable non-managed (external) table creates true BOOLEAN Hive Table Statistics Enabled Enable use of table statistics true BOOLEAN Hive Partition Statistics Sample Size Specifies the number of partitions to analyze when computing table\n                      statistics. 100 INTEGER Hive Ignore Corrupted Statistics Ignore corrupted statistics rather than failing false BOOLEAN Hive Collect Column Statistics On Write Enables automatic column level statistics collection on write false BOOLEAN Hive S3select Pushdown Enabled Enable query pushdown to AWS S3 Select service false BOOLEAN Hive Max Initial Splits Max initial splits 200 INTEGER Hive Max Initial Split Size Max initial split size null DATASIZE Hive Writer Sort Buffer Size Write sort buffer size 64MB DATASIZE Hive Node Selection Strategy Node affinity selection strategy NO_PREFERENCE STRING Hive Max Split Size Max split size 64MB DATASIZE Hive Max Partitions Per Scan Maximum allowed partitions for a single table scan 100000 INTEGER Hive Max Outstanding Splits Target number of buffered splits for each table scan in a query, before\n                      the scheduler tries to pause itself 1000 INTEGER Hive Metastore Partition Batch Size Min Hive metastore : min batch size for partitions 10 INTEGER Hive Metastore Partition Batch Size Max Hive metastore : max batch size for partitions 100 INTEGER Hive Config Resources An optional comma-separated list of HDFS configuration files [] FILEPATH Hive Dfs Ipc Ping Interval The client will send ping when the interval is passed without receiving\n                      bytes 10.00s DURATION Hive Dfs Timeout DFS timeout 60.00s DURATION Hive Dfs Connect Timeout DFS connection timeout 500.00ms DURATION Hive Dfs Connect Max Retries DFS - max retries in case of connection issue 5 INTEGER Hive Storage Format The default file format used when creating new tables. ORC STRING Hive Compression Codec The compression codec to use when writing files GZIP STRING Hive Orc Compression Codec The preferred compression codec to use when writing ORC and DWRF files GZIP STRING Hive Respect Table Format Should new partitions be written using the existing table format or the\n                      default PrestoDB format? true BOOLEAN Hive Immutable Partitions Can new data be inserted into existing partitions? false BOOLEAN Hive Max Open Sort Files Maximum number of writer temporary files to read in one pass 50 INTEGER Hive Dfs Domain Socket Path This is a path in the filesystem that allows the client and the\n                      DataNodes to communicate. null STRING Hive S3 File System Type s3 file system type PRESTO STRING Hive Gcs Json Key File Path JSON key file used to access Google Cloud Storage null FILEPATH Hive Gcs Use Access Token Use client-provided OAuth token to access Google Cloud Storage false BOOLEAN Hive Orc Use Column Names Access ORC columns using names from the file false BOOLEAN Hive Orc Max Merge Distance ORC: Maximum size of gap between two reads to merge into a single read 1MB DATASIZE Hive Orc Max Buffer Size ORC: Maximum size of a single read 8MB DATASIZE Hive Orc Stream Buffer Size ORC: Size of buffer for streaming reads 8MB DATASIZE Hive Orc Max Read Block Size ORC: Soft max size of Presto blocks produced by ORC reader 16MB DATASIZE Hive Rcfile Writer Validate Validate RCFile after write by re-reading the whole file false BOOLEAN Hive Text Max Line Length Maximum line length for text files 100MB DATASIZE Hive Parquet Use Column Names Access Parquet columns using names from the file false BOOLEAN Hive File Status Cache Tables The tables that have file status cache enabled. Setting to '*' includes\n                      all tables STRING Hive Skip Deletion For Alter Skip deletion of old partition data when a partition is deleted and then\n                      inserted in the same transaction false BOOLEAN Hive Sorted Writing Enable writing to bucketed sorted tables true BOOLEAN Hive Ignore Table Bucketing Ignore table bucketing to enable reading from unbucketed partitions false BOOLEAN Hive Temporary Table Schema Schema where to create temporary tables default STRING Hive Pushdown Filter Enabled Experimental: enable complex filter pushdown false BOOLEAN Hive Pagefile Writer Stripe Max Size PAGEFILE: Max stripe size 24MB DATASIZE Hive File_renaming_enabled enable file renaming false BOOLEAN Hive Partial_aggregation_pushdown_for_variable_length_datatypes_enabled enable partial aggregation pushdown for variable length datatypes false BOOLEAN Hive Time Zone Sets the default time zone null STRING Hive Orc Writer Stripe Min Size ORC: Min stripe size 32MB DATASIZE Hive Orc Writer Stripe Max Size ORC: Max stripe size 64MB DATASIZE Hive Orc Writer Stripe Max Rows ORC: Max stripe row count 10000000 INTEGER Hive Orc Writer Row Group Max Rows ORC : Max rows in row group 10000 INTEGER Hive Orc Writer Dictionary Max Memory ORC: Max dictionary memory 16MB DATASIZE Hive Orc Writer String Statistics Limit ORC: Maximum size of string statistics; drop if exceeding 64B DATASIZE Hive Orc Writer Stream Layout Type ORC: Stream layout type BY_COLUMN_SIZE STRING Hive Orc Writer Dwrf Stripe Cache Mode Describes content of the DWRF stripe metadata cache. INDEX_AND_FOOTER STRING Hive Orc Writer Max Compression Buffer Size ORC : Max compression buffer size 256kB DATASIZE Hive Orc Writer Dwrf Stripe Cache Enabled DWRF stripe cache enabled? false BOOLEAN Hive Orc Writer Dwrf Stripe Cache Max Size DWRF stripe cache max size 8MB DATASIZE Hive Parquet Optimized Writer Enabled Parquet: Optimized writer enabled? false BOOLEAN Hive Parquet Writer Block Size Parquet: Writer block size 134217728B DATASIZE Hive Parquet Writer Page Size Parquet: Writer page size 1048576B DATASIZE Hive Security The type of access control to use legacy STRING Generic Cache Enabled Enable Caching while querying true BOOLEAN Transparent Cache Enabled Enable transparent caching while querying true BOOLEAN Generic Cache Table Ttl TTL for cache table expiry in minutes 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/delta-connect-fields.html",
        "title": "Delta Connection Parameters"
    },
    {
        "content": "\nDelta Thrift Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and\n    supported data types. The following tables list the required and optional Delta Thrift connection\n        parameters. NOTE Delta connector values varies based on type of metastore. Refer https://prestodb.io/docs/current/connector/deltalake.html . Required Connection Parameters Parameter Description Default Value Data Type Hive Metastore The type of Hive metastore to use thrift STRING Hive Metastore Uri Hive metastore URIs (comma separated) null STRING Hive S3 Aws Access Key Default AWS access key to use for bucket access null STRING Hive S3 Aws Secret Key Default AWS secret key to use for bucket access null STRING Enable Local Snapshot Table Enable Caching while querying true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Generic Cache Table Ttl TTL for cache table expiry in minutes 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/delta-thrift-metastore-connect-fields.html",
        "title": "Delta Thrift Connection Parameters"
    },
    {
        "content": "\nHive Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data\n    types. If you want to connect HPE Ezmeral Unified Analytics Software to a Hive data source that uses Kerberos for authentication, see Configuring a Hive Data Source with Kerberos Authentication . The following tables list the required and optional Hive connection parameters. NOTE Hive\n        connector values varies based on type of metastore. See https://prestodb.io/docs/current/connector/hive.html . Required Connection Parameters Parameter Description Default Value Data Type Hive Metastore The type of Hive metastore to use. thrift STRING Enable Local Snapshot Table Enable Caching while querying. true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Hive Insert Overwrite Immutable Partitions Enabled When enabled, insertion query will overwrite existing partitions when\n                      partitions are immutable. This config only takes effect when Hive Immutable\n                      Partitions is set to true. false BOOLEAN Hive Create Empty Bucket Files For Temporary Table Create empty files when there is no data for temporary table\n                      buckets. false BOOLEAN Hive Enable Parquet Batch Reader Verification Enable optimized parquet reader. false BOOLEAN Hive Create Empty Bucket Files For Temporary Table Create empty files when there is no data for temporary table\n                      buckets. false BOOLEAN Hive Min Bucket Count To Not Ignore Table Bucketing Ignore table bucketing when table bucket count is less than the value\n                      specified, otherwise, it is controlled by property\n                      hive.ignore-table-bucketing. 0 INTEGER Hive Partition Statistics Based Optimization Enabled Enables partition statistics based optimization, including partition\n                      pruning and predicate stripping. false BOOLEAN Hive Experimental Optimized Partition Update Serialization Enabled Serialize PartitionUpdate objects using binary SMILE encoding and\n                      compress with the ZSTD compression. false BOOLEAN Hive Materialized View Missing Partitions Threshold Materialized views with missing partitions more than this threshold falls\n                      back to the base tables at read time. 100 INTEGER Hive S3select Pushdown Max Connections The maximum number of client connections allowed for those operations\n                      from worker nodes. 500 INTEGER Hive Temporary Staging Directory Enabled Should use (if possible) temporary staging directory for write\n                      operations. true BOOLEAN Hive Temporary Staging Directory Path Location of temporary staging directory for write operations. Use ${USER}\n                      placeholder to use different location for each user. /tmp/presto-${USER} STRING Hive Temporary Table Storage Format The default file format used when creating new tables. ORC STRING Hive Temporary Table Compression Codec The compression codec to use when writing files for temporary\n                      tables. SNAPPY STRING Hive Use Pagefile For Hive Unsupported Type Automatically switch to PAGEFILE format for materialized exchange when\n                      encountering unsupported types. true BOOLEAN Hive Parquet Pushdown Filter Enabled Enable complex filter pushdown for Parquet. false BOOLEAN Hive Range Filters On Subscripts Enabled Enable pushdown of range filters on subscripts (a[2] = 5) into ORC column\n                      readers. false BOOLEAN Hive Adaptive Filter Reordering Enabled Enable adaptive filter reordering. true BOOLEAN Hive Parquet Batch Read Optimization Enabled Is Parquet batch read optimization enabled. false BOOLEAN Hive Enable Parquet Dereference Pushdown Is dereference pushdown expression pushdown into Parquet reader\n                      enabled. false BOOLEAN Hive Max Metadata Updater Threads Maximum number of metadata updated threads. 100 INTEGER Hive Partial_aggregation_pushdown_enabled Enable partial aggregation pushdown. false BOOLEAN Hive Manifest Verification Enabled Enable verification of file names and sizes in manifest / partition\n                      parameters. false BOOLEAN Hive Undo Metastore Operations Enabled Enable undo metastore operations. true BOOLEAN Hive Verbose Runtime Stats Enabled Enable tracking all runtime stats. Note that this may affect query\n                      performance. false BOOLEAN Hive Prefer Manifests To List Files Prefer to fetch the list of file names and sizes from manifests rather\n                      than storage false BOOLEAN Hive Partition Lease Duration Partition lease duration. 0.00s DURATION Hive Size Based Split Weights Enabled Enable estimating split weights based on size in bytes true BOOLEAN Hive Minimum Assigned Split Weight Minimum weight that a split can be assigned when size based split weights\n                      are enabled. 0.05 DOUBLE Hive Use Record Page Source For Custom Split Use record page source for custom split. By default, true. Used to query\n                      MOR tables in Hudi. true BOOLEAN Hive Split Loader Concurrency Number of maximum concurrent threads per split source. 4 INTEGER Hive Domain Compaction Threshold Maximum ranges to allow in a tuple domain without compacting it. 100 INTEGER Hive Max Concurrent File Renames Maximum concurrent file renames 20 INTEGER Hive Max Concurrent Zero Row File Creations Maximum number of zero row file creations. 20 INTEGER Hive Recursive Directories Enable reading data from subdirectories of table or partition locations.\n                      If disabled, subdirectories are ignored. false BOOLEAN Hive User Defined Type Encoding Enabled Enable user defined type. false BOOLEAN Hive Loose Memory Accounting Enabled When enabled relaxes memory accounting for queries violating memory\n                      limits to run that previously honored memory thresholds. false BOOLEAN Hive Max Outstanding Splits Size Maximum amount of memory allowed for split buffering for each table scan\n                      in a query, before the query is failed. 256MB DATASIZE Hive Max Split Iterator Threads Maximum number of iterator threads. 1000 INTEGER Hive Allow Corrupt Writes For Testing Allow Hive connector to write data even when data will likely be\n                      corrupt. false BOOLEAN Hive Create Empty Bucket Files Should empty files be created for buckets that have no data? true BOOLEAN Hive Max Partitions Per Writers Maximum number of partitions per writer. 100 INTEGER Hive Write Validation Threads Number of threads used for verifying data after a write. 16 INTEGER Hive Orc Tiny Stripe Threshold ORC: Threshold below which an ORC stripe or file will read in its\n                      entirety. 8MB DATASIZE Hive Orc Lazy Read Small Ranges ORC read small disk ranges lazily. true BOOLEAN Hive Orc Bloom Filters Enabled ORC: Enable bloom filters for predicate pushdown. false BOOLEAN Hive Orc Default Bloom Filter Fpp ORC Bloom filter false positive probability. 0.05 DOUBLE Hive Orc Optimized Writer Enabled Experimental: ORC: Enable optimized writer. true BOOLEAN Hive Orc Writer Validation Percentage Percentage of ORC files to validate after write by re-reading the whole\n                      file. 0 DOUBLE Hive Orc Writer Validation Mode Level of detail in ORC validation. Lower levels require more\n                      memory. BOTH STRING Hive Rcfile Optimized Writer Enabled Experimental: RCFile: Enable optimized writer. true BOOLEAN Hive Assume Canonical Partition Keys Assume canonical parition keys? false BOOLEAN Hive Parquet Fail On Corrupted Statistics Fail when scanning Parquet files with corrupted statistics. true BOOLEAN Hive Parquet Max Read Block Size Parquet: Maximum size of a block to read. 16MB DATASIZE Hive Optimize Mismatched Bucket Count Enable optimization to avoid shuffle when bucket count is compatible but\n                      not the same. false BOOLEAN Hive Zstd Jni Decompression Enabled Use JNI based zstd decompression for reading ORC files. false BOOLEAN Hive File Status Cache Size Hive file status cache size. 0 LONG Hive File Status Cache Expire Time Hive file status cache : expiry time. 0.00s DURATION Hive Per Transaction Metastore Cache Maximum Size Maximum number of metastore data objects in the Hive metastore cache per\n                      transaction. 1000 INTEGER Hive Metastore Refresh Interval Asynchronously refresh cached metastore data after access if it is older\n                      than this but is not yet expired, allowing subsequent accesses to see fresh\n                      data. 0.00s DURATION Hive Metastore Cache Maximum Size Maximum number of metastore data objects in the Hive metastore\n                      cache. 10000 INTEGER Hive Metastore Refresh Max Threads Maximum threads used to refresh cached metastore data. 100 INTEGER Hive Partition Versioning Enabled false BOOLEAN Hive Metastore Impersonation Enabled Should Presto user be impersonated when communicating with Hive\n                      Metastore. false BOOLEAN Hive Partition Cache Validation Percentage Percentage of partition cache validation. 0 DOUBLE Hive Metastore Thrift Client Socks Proxy Metastore thrift client socks proxy. null STRING Hive Metastore Timeout Timeout for Hive metastore requests. 10.00s DURATION Hive Dfs Verify Checksum Verify checksum for data consistency. true BOOLEAN Hive Metastore Cache Ttl Duration how long cached metastore data should be considered\n                      valid. 0.00s DURATION Hive Metastore Recording Path Metastore recording path. null STRING Hive Replay Metastore Recording Replay metastore recording. false BOOLEAN Hive Metastore Recoding Duration Metastore recording duration. 0.00m DURATION Hive Dfs Require Hadoop Native Hadoop native is required? true BOOLEAN Hive Metastore Cache Scope Metastore cache scope. ALL STRING Hive Metastore Authentication Type Hive metastore authentication type. NONE STRING Hive Hdfs Authentication Type HDFS authentication type. NONE STRING Hive Hdfs Impersonation Enabled Should Presto user be impersonated when communicating with HDFS. false BOOLEAN Hive Hdfs Wire Encryption Enabled Should be turned on when HDFS wire encryption is enabled. false BOOLEAN Hive Skip Target Cleanup On Rollback Skip deletion of target directories when a metastore operation fails and\n                      the write mode is DIRECT_TO_TARGET_NEW_DIRECTORY. false BOOLEAN Hive Bucket Execution Enable bucket-aware execution: only use a single worker per\n                      bucket. true BOOLEAN Hive Bucket Function Type For Exchange Hash function type for exchange. HIVE_COMPATIBLE STRING Hive Ignore Unreadable Partition Ignore unreadable partitions and report as warnings instead of failing\n                      the query. false BOOLEAN Hive Max Buckets For Grouped Execution Maximum number of buckets to run with grouped execution. 1000000 INTEGER Hive Sorted Write To Temp Path Enabled Enable writing temp files to temp path when writing to bucketed sorted\n                      tables. false BOOLEAN Hive Sorted Write Temp Path Subdirectory Count Number of directories per partition for temp files generated by writing\n                      sorted table. 10 INTEGER Hive Fs Cache Max Size Hadoop FileSystem cache size. 1000 INTEGER Hive Non Managed Table Writes Enabled Enable writes to non-managed (external) tables. false BOOLEAN Hive Non Managed Table Creates Enabled Enable non-managed (external) table creates. true BOOLEAN Hive Table Statistics Enabled Enable use of table statistics. true BOOLEAN Hive Partition Statistics Sample Size Specifies the number of partitions to analyze when computing table\n                      statistics. 100 INTEGER Hive Ignore Corrupted Statistics Ignore corrupted statistics rather than failing. false BOOLEAN Hive Collect Column Statistics On Write Enables automatic column level statistics collection on write. false BOOLEAN Hive S3select Pushdown Enabled Enable query pushdown to AWS S3 Select service. false BOOLEAN Hive Max Initial Splits Max initial splits. 200 INTEGER Hive Max Initial Split Size Max initial split size. null DATASIZE Hive Writer Sort Buffer Size Write sort buffer size. 64MB DATASIZE Hive Node Selection Strategy Node affinity selection strategy. NO_PREFERENCE STRING Hive Max Split Size Max split size. 64MB DATASIZE Hive Max Partitions Per Scan Maximum allowed partitions for a single table scan. 100000 INTEGER Hive Max Outstanding Splits Target number of buffered splits for each table scan in a query, before\n                      the scheduler tries to pause itself. 1000 INTEGER Hive Metastore Partition Batch Size Min Hive metastore : min batch size for partitions. 10 INTEGER Hive Metastore Partition Batch Size Max Hive metastore : max batch size for partitions. 100 INTEGER Hive Config Resources An optional comma-separated list of HDFS configuration files. [] FILEPATH Hive Dfs Ipc Ping Interval The client will send ping when the interval is passed without receiving\n                      bytes. 10.00s DURATION Hive Dfs Timeout DFS timeout. 60.00s DURATION Hive Dfs Connect Timeout DFS connection timeout. 500.00ms DURATION Hive Dfs Connect Max Retries DFS - max retries in case of connection issue. 5 INTEGER Hive Storage Format The default file format used when creating new tables. ORC STRING Hive Compression Codec The compression codec to use when writing files. GZIP STRING Hive Orc Compression Codec The preferred compression codec to use when writing ORC and DWRF\n                      files. GZIP STRING Hive Respect Table Format Should new partitions be written using the existing table format or the\n                      default PrestoDB format? true BOOLEAN Hive Immutable Partitions Can new data be inserted into existing partitions? false BOOLEAN Hive Max Open Sort Files Maximum number of writer temporary files to read in one pass. 50 INTEGER Hive Dfs Domain Socket Path This is a path in the filesystem that allows the client and the DataNodes\n                      to communicate. null STRING Hive S3 File System Type S3 file system type. PRESTO STRING Hive Gcs Json Key File Path JSON key file used to access Google Cloud Storage. null FILEPATH Hive Gcs Use Access Token Use client-provided OAuth token to access Google Cloud Storage. false BOOLEAN Hive Orc Use Column Names Access ORC columns using names from the file. false BOOLEAN Hive Orc Max Merge Distance ORC: Maximum size of gap between two reads to merge into a single read 1MB DATASIZE Hive Orc Max Buffer Size ORC: Maximum size of a single read. 8MB DATASIZE Hive Orc Stream Buffer Size ORC: Size of buffer for streaming reads. 8MB DATASIZE Hive Orc Max Read Block Size ORC: Soft max size of Presto blocks produced by ORC reader. 16MB DATASIZE Hive Rcfile Writer Validate Validate RCFile after write by re-reading the whole file. false BOOLEAN Hive Text Max Line Length Maximum line length for text files. 100MB DATASIZE Hive Parquet Use Column Names Access Parquet columns using names from the file. false BOOLEAN Hive File Status Cache Tables The tables that have file status cache enabled. Setting to '*' includes\n                      all tables. STRING Hive Skip Deletion For Alter Skip deletion of old partition data when a partition is deleted and then\n                      inserted in the same transaction. false BOOLEAN Hive Sorted Writing Enable writing to bucketed sorted tables. true BOOLEAN Hive Ignore Table Bucketing Ignore table bucketing to enable reading from unbucketed\n                      partitions. false BOOLEAN Hive Temporary Table Schema Schema where to create temporary tables. default STRING Hive Pushdown Filter Enabled Experimental: enable complex filter pushdown. false BOOLEAN Hive Pagefile Writer Stripe Max Size PAGEFILE: Max stripe size. 24MB DATASIZE Hive File_renaming_enabled Enable file renaming. false BOOLEAN Hive Partial_aggregation_pushdown_for_variable_length_datatypes_enabled Enable partial aggregation pushdown for variable length\n                      datatypes. false BOOLEAN Hive Time Zone Sets the default time zone. null STRING Hive Orc Writer Stripe Min Size ORC: Min stripe size. 32MB DATASIZE Hive Orc Writer Stripe Max Size ORC: Max stripe size. 64MB DATASIZE Hive Orc Writer Stripe Max Rows ORC: Max stripe row count. 10000000 INTEGER Hive Orc Writer Row Group Max Rows ORC : Max rows in row group. 10000 INTEGER Hive Orc Writer Dictionary Max Memory ORC: Max dictionary memory. 16MB DATASIZE Hive Orc Writer String Statistics Limit ORC: Maximum size of string statistics; drop if exceeding. 64B DATASIZE Hive Orc Writer Stream Layout Type ORC: Stream layout type. BY_COLUMN_SIZE STRING Hive Orc Writer Dwrf Stripe Cache Mode Describes content of the DWRF stripe metadata cache. INDEX_AND_FOOTER STRING Hive Orc Writer Max Compression Buffer Size ORC : Max compression buffer size. 256kB DATASIZE Hive Orc Writer Dwrf Stripe Cache Enabled DWRF stripe cache enabled? false BOOLEAN Hive Orc Writer Dwrf Stripe Cache Max Size DWRF stripe cache max size. 8MB DATASIZE Hive Parquet Optimized Writer Enabled Parquet: Optimized writer enabled? false BOOLEAN Hive Parquet Writer Block Size Parquet: Writer block size. 134217728B DATASIZE Hive Parquet Writer Page Size Parquet: Writer page size. 1048576B DATASIZE Hive Security The type of access control to use. legacy STRING Generic Cache Table Ttl TTL for cache table expiry in minutes. 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/hive-connect-fields.html",
        "title": "Hive Connection Parameters"
    },
    {
        "content": "\nHive Glue Metastore Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and\n    supported data types. The following tables list the required and optional Hive  Glue Glue connection parameters. Required Connection Parameters NOTE Hive connector values vary based on the type of metastore. See https://prestodb.io/docs/current/connector/hive.html . Parameter Description Default Value Data Type Hive Metastore The type of Hive metastore to use thrift STRING Hive Metastore Glue Region AWS region of the Glue Catalog null STRING Hive Metastore Glue Aws Access Key AWS access key to use to connect to the Glue Catalog. If specified along\n                      with hive.metastore.glue.aws-secret-key, this parameter takes precedence over\n                      hive.metastore.glue.iam-role. null STRING Hive Metastore Glue Aws Secret Key AWS secret key to use to connect to the Glue Catalog. If specified along\n                      with hive.metastore.glue.aws-access-key, this parameter takes precedence over\n                      hive.metastore.glue.iam-role. null STRING Hive S3 Aws Access Key Default AWS access key to use for bucket access null STRING Hive S3 Aws Secret Key Default AWS secret key to use for bucket access null STRING Enable Local Snapshot Table Enable Caching while querying true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Generic Cache Table Ttl TTL for cache table expiry in minutes 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/Hive-glue-metastore-connect-fields.html",
        "title": "Hive Glue Metastore Connection Parameters"
    },
    {
        "content": "\nHive Thrift Metastore Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and\n    supported data types. The following tables list the required and optional Hive Thrift Metastore connection parameters. Required Connection Parameters NOTE Hive connector values varies based on type of metastore. See https://prestodb.io/docs/current/connector/hive.html . Parameter Description Default Value Data Type Hive Metastore The type of Hive metastore to use thrift STRING Hive Metastore Uri Hive metastore URIs (comma separated) null STRING Enable Local Snapshot Table Enable Caching while querying true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Generic Cache Table Ttl TTL for cache table expiry in minutes 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/hive-thrift-metastore-connect-fields.html",
        "title": "Hive Thrift Metastore Connection Parameters"
    },
    {
        "content": "\nHive Discovery Metastore Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default\n    values, and supported data types. Use Hive discovery metastore to query CSV and Parquet files. Hive discovery metastore\n      automatically scans CSV files and Parquet footers in the specified directory to discover table\n      schema. Hive discovery metastore does not require a Hive metastore service. For\n      additional information, see Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector . The following tables list the required and optional Hive discovery metastore connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Data Dir Location of the directory where files are stored. STRING Optional Connection Parameters Parameter Description Default Value Data Type File Type Type of files stored CSV or Parquet. STRING Csv Header Specifies that the file contains a header line with the names of each\n                      column in the file. false BOOLEAN Csv Separator Specifies the string that separates columns within each row (line) of the\n                      file. , STRING Csv Date Format Specifies the format for date fields yyyy-MM-dd STRING Csv Timestamp Format Specifies the format for timestamp fields yyyy-MM-dd HH:mm:ss STRING Csv Row Count Specifies the number of rows used for schema discovery. 1000 INTEGER Csv Escape Specifies the escape character used in the csv file. \\ STRING Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/hive-discovery-metastore.html",
        "title": "Hive Discovery Metastore Connection Parameters"
    },
    {
        "content": "\nMySQL Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data\n    types. The following tables list the required and optional MySQL connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Connection Url JDBC connection url. null STRING Connection User Specifies the login name of the user for the connection. null STRING Connection Password Specifies the password of the user for the connection. null STRING Enable Local Snapshot Table Enable Caching while querying. true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Case Insensitive Name Matching Match schema and table names case insensitively. false BOOLEAN Case Insensitive Name Matching Cache Ttl Duration for which remote dataset and table names will be cached. Set to\n                      0ms to disable the cache. 1m DURATION Allow Drop Table Allow connector to drop tables. false BOOLEAN Mysql Auto Reconnect When auto reconnect is enabled, presto tries to reconnect to the mysql\n                      server if it finds that connection is down. When it is disabled it will throw\n                      an error without retrying if connection is down. true BOOLEAN Mysql Max Reconnects Number of connection retries. 3 INTEGER Mysql Connection Timeout The time to wait while trying to establish a connection before\n                      terminating the attempt and generating an error. 10 sec DURATION Generic Cache Table Ttl TTL for cache table expiry in minutes. 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/Mysql-connect-fields.html",
        "title": "MySQL Connection Parameters"
    },
    {
        "content": "\nOracle Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data\n    types. The following tables list the required and optional Oracle connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Connection Url JDBC connection url. null STRING Connection User Specifies the login name of the user for the connection. null STRING Connection Password Specifies the password of the user for the connection. null STRING Enable Local Snapshot Table Enable Caching while querying. true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Case Insensitive Name Matching Match schema and table names case insensitively. false BOOLEAN Case Insensitive Name Matching Cache Ttl Duration for which remote dataset and table names will be cached. Set to\n                      0ms to disable the cache. 1m DURATION Allow Drop Table Allow connector to drop tables. false BOOLEAN Oracle Synonyms Enabled Synonyms feature enabled? false BOOLEAN Oracle Number Default Scale Default scale for number. 10 INTEGER Oracle Number Rounding Mode Default number rounding mode. HALF_UP STRING Oracle Varchar Max Size Max size for varchar datatype. 4000 INTEGER Oracle Timestamp Precision Specify the number of digits in the fractional second portion of the\n                      datetime. 6 INTEGER Generic Cache Table Ttl TTL for cache table expiry in minutes. 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/Oracle-connect-fields.html",
        "title": "Oracle Connection Parameters"
    },
    {
        "content": "\nSnowflake Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported\n    data types. The following tables list the required and optional Snowflake connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Connection Url JDBC connection url. null STRING Connection User Specifies the login name of the user for the connection. null STRING Connection Password Specifies the password of the user for the connection. null STRING Snowflake Db Specifies the default database to use once connected. null STRING Enable Local Snapshot Table Enable Caching while querying. true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Case Insensitive Name Matching Match schema and table names case insensitively. false BOOLEAN Case Insensitive Name Matching Cache Ttl Duration for which remote dataset and table names will be cached. Set to\n                      0ms to disable the cache. 1m DURATION Snowflake Fetch Size Gives the JDBC driver a hint as to the number of rows that should be\n                      fetched from the database when more rows are needed for ResultSet objects\n                      genrated by this Statement. 1000 INTEGER Allow Drop Table Allow connector to drop tables. false BOOLEAN Generic Cache Table Ttl TTL for cache table expiry in minutes. 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/snowflake-connect-parameters.html",
        "title": "Snowflake Connection Parameters"
    },
    {
        "content": "\nSQL Server Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported\n    data types. The following tables list the required and optional SQL Server connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Connection Url JDBC connection url. null STRING Connection User Specifies the login name of the user for the connection. null STRING Connection Password Specifies the password of the user for the connection. null STRING Enable Local Snapshot Table Enable Caching while querying. true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Case Insensitive Name Matching Match schema and table names case insensitively. false BOOLEAN Case Insensitive Name Matching Cache Ttl Duration for which remote dataset and table names will be cached. Set to\n                      0ms to disable the cache. 1m DURATION Allow Drop Table Allow connector to drop tables. false BOOLEAN Generic Cache Table Ttl TTL for cache table expiry in minutes. 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/sqlserver-connect-fields.html",
        "title": "SQL Server Connection Parameters"
    },
    {
        "content": "\nTeradata Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported\n    data types. The following tables list the required and optional Teradata connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Connection Url JDBC connection url null STRING Connection User Specifies the login name of the user for the connection null STRING Connection Password Specifies the password of the user for the connection null STRING Enable Local Snapshot Table Enable Caching while querying true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Case Insensitive Name Matching Match schema and table names case insensitively false BOOLEAN Case Insensitive Name Matching Cache Ttl Duration for which remote dataset and table names will be cached. Set to\n                      0ms to disable the cache 1m DURATION Allow Drop Table Allow connector to drop tables false BOOLEAN Generic Cache Table Ttl TTL for cache table expiry in minutes 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/teradata-connect-parameters.html",
        "title": "Teradata Connection Parameters"
    },
    {
        "content": "\nPostgreSQL Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported\n    data types. The following tables list the required and optional PostgreSQL connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Connection Url JDBC connection url. null STRING Connection User Specifies the login name of the user for the connection. null STRING Connection Password Specifies the password of the user for the connection. null STRING Enable Local Snapshot Table Enable Caching while querying. true BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Allow Drop Table Allow connector to drop tables. false BOOLEAN Case Insensitive Name Matching Match schema and table names case insensitively. false BOOLEAN Case Insensitive Name Matching Cache Ttl Duration for which remote dataset and table names will be cached. Set to\n                      0ms to disable the cache. 1m DURATION Generic Cache Table Ttl TTL for cache table expiry in minutes. 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/postgresql.html",
        "title": "PostgreSQL Connection Parameters"
    },
    {
        "content": "\nIceberg Connection Parameters Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data\n    types. The following tables list the required and optional Iceberg connection parameters. Required Connection Parameters Parameter Description Default Value Data Type Possible Values Name Provide a unique name for the Iceberg data source connection. Iceberg Catalog Type The catalog type for Iceberg tables. hive STRING possibleValues(hive, hadoop) Iceberg File Format The storage file format for Iceberg tables. PARQUET STRING possibleValues(PARQUET, ORC) Iceberg Compression Codec The compression codec to use when writing files. The available values are\n                      NONE, SNAPPY, GZIP, LZ4, and ZSTD GZIP STRING possibleValues(NONE, SNAPPY, GZIP, LZ4, ZSTD) Iceberg Catalog Cached Catalog Num The number of Iceberg catalogs to cache, This property is required if the\n                      iceberg.catalog.type is hadoop 10 INTEGER Iceberg Max Partitions Per Writer The Maximum number of partitions handled per writer. 100 INTEGER Iceberg Minimum Assigned Split Weight A decimal value in the range (0, 1] used as a minimum for weights\n                      assigned to each split 0.05 DOUBLE Hive Metastore The type of Hive metastore to use thrift STRING possibleValues(thrift, file, glue) Hive Metastore Catalog Dir Hive file-based metastore catalog directory STRING Hive Metastore Uri Hive metastore URIs (comma separated). STRING Hive Metastore Service Principal The Kerberos principal of the Hive metastore service STRING Hive Metastore Client Principal The Kerberos principal that Presto will use when connecting to the Hive\n                      metastore service. STRING Hive Metastore Client Keytab Hive metastore client keytab location. FILEPATH Hive Hdfs Presto Principal The Kerberos principal that presto will use when connecting to\n                      HDFS STRING Hive Hdfs Presto Keytab HDFS client keytab location FILEPATH Security Config File Config file where rules are defined STRING Security Refresh Period Time after which rules will be refreshed from the file. DURATION Min(1ms) Enable Local Snapshot Table Enables local copy of database table for accelerated query\n                      performance TRUE BOOLEAN Optional Connection Parameters Parameter Description Default Value Data Type Possible Values Iceberg Hadoop Config Resources The path(s) for Hadoop configuration resources. FILEPATH Iceberg Catalog Warehouse The catalog warehouse root path for Iceberg tables. STRING Hive Metastore User Hive file-based metastore username for file access presto STRING Hive Metastore Glue Region AWS region of the Glue Catalog. STRING Hive Metastore Glue Endpoint Url Glue API endpoint URL STRING Hive Metastore Glue Pin Client To Current Region Should the Glue client be pinned to the current EC2 region FALSE BOOLEAN Hive Metastore Glue Max Connections Max number of concurrent connections to Glue 5 INTEGER Min(1) Hive Metastore Glue Max Error Retries Maximum number of error retries for the Glue client 10 INTEGER Min(0) Hive Metastore Glue Default Warehouse Dir Hive Glue metastore default warehouse directory STRING Hive Metastore Glue Catalogid The ID of the Glue Catalog in which the metadata database\n                      resides. STRING Hive Metastore Glue Partitions Segments Number of segments for partitioned Glue tables. 5 INTEGER Min(1), Max(10) Hive Metastore Glue Get Partition Threads Number of threads for parallel partition fetches from Glue. 20 INTEGER Min(1) Hive Metastore Glue Iam Role ARN of an IAM role to assume when connecting to the Glue Catalog. STRING Hive Metastore Glue Aws Access Key AWS access key to use to connect to the Glue Catalog. If specified along\n                      with hive.metastore.glue.aws-secret-key, this parameter takes precedence over\n                      hive.metastore.glue.iam-role. STRING Hive Metastore Glue Aws Secret Key AWS secret key to use to connect to the Glue Catalog. If specified along\n                      with hive.metastore.glue.aws-access-key, this parameter takes precedence over\n                      hive.metastore.glue.iam-role. STRING Hive Metastore Username Username for accessing the Hive metastore STRING Hive Metastore Load Balancing Enabled Enable load balancing between multiple Metastore instances FALSE BOOLEAN Hive Insert Overwrite Immutable Partitions Enabled When enabled, insertion query will overwrite existing partitions when\n                      partitions are immutable. This config only takes effect with\n                      hive.immutable-partitions set to true FALSE BOOLEAN Hive Create Empty Bucket Files For Temporary Table Create empty files when there is no data for temporary table\n                      buckets FALSE BOOLEAN Hive Enable Parquet Batch Reader Verification enable optimized parquet reader FALSE BOOLEAN Hive Create Empty Bucket Files For Temporary Table Create empty files when there is no data for temporary table\n                      buckets FALSE BOOLEAN Hive Min Bucket Count To Not Ignore Table Bucketing Ignore table bucketing when table bucket count is less than the value\n                      specified, otherwise, it is controlled by property\n                      hive.ignore-table-bucketing 0 INTEGER Hive Partition Statistics Based Optimization Enabled Enables partition statistics based optimization, including partition\n                      pruning and predicate stripping FALSE BOOLEAN Hive Experimental Optimized Partition Update Serialization\n                      Enabled Serialize PartitionUpdate objects using binary SMILE encoding and\n                      compress with the ZSTD compression FALSE BOOLEAN Hive Materialized View Missing Partitions Threshold Materialized views with missing partitions more than this threshold falls\n                      back to the base tables at read time 100 INTEGER Hive S3select Pushdown Max Connections The maximum number of client connections allowed for those operations\n                      from worker nodes 500 INTEGER Min(1) Hive Temporary Staging Directory Enabled Should use (if possible) temporary staging directory for write\n                      operations TRUE BOOLEAN Hive Temporary Staging Directory Path Location of temporary staging directory for write operations. Use ${USER}\n                      placeholder to use different location for each user. /tmp/presto-${USER} STRING Hive Temporary Table Storage Format The default file format used when creating new tables. ORC STRING possibleValues(ORC, DWRF, PARQUET, AVRO, RCBINARY, RCTEXT, SEQUENCEFILE,\n                      JSON, TEXTFILE, CSV, PAGEFILE) Hive Temporary Table Compression Codec The compression codec to use when writing files for temporary\n                      tables SNAPPY STRING possibleValues(NONE, SNAPPY, LZ4, ZSTD, GZIP) Hive Use Pagefile For Hive Unsupported Type Automatically switch to PAGEFILE format for materialized exchange when\n                      encountering unsupported types TRUE BOOLEAN Hive Parquet Pushdown Filter Enabled Enable complex filter pushdown for Parquet FALSE BOOLEAN Hive Range Filters On Subscripts Enabled enable pushdown of range filters on subscripts (a[2] = 5) into ORC column\n                      readers FALSE BOOLEAN Hive Adaptive Filter Reordering Enabled Enable adaptive filter reordering TRUE BOOLEAN Hive Parquet Batch Read Optimization Enabled Is Parquet batch read optimization enabled FALSE BOOLEAN Hive Enable Parquet Dereference Pushdown Is dereference pushdown expression pushdown into Parquet reader\n                      enabled FALSE BOOLEAN Hive Max Metadata Updater Threads Maximum number of metadata updated threads 100 INTEGER Min(1) Hive Partial_aggregation_pushdown_enabled enable partial aggregation pushdown FALSE BOOLEAN Hive Manifest Verification Enabled Enable verification of file names and sizes in manifest / partition\n                      parameters FALSE BOOLEAN Hive Undo Metastore Operations Enabled Enable undo metastore operations TRUE BOOLEAN Hive Verbose Runtime Stats Enabled Enable tracking all runtime stats. Note that this may affect query\n                      performance FALSE BOOLEAN Hive Prefer Manifests To List Files Prefer to fetch the list of file names and sizes from manifests rather\n                      than storage FALSE BOOLEAN Hive Partition Lease Duration Partition lease duration 0.00s DURATION Hive Size Based Split Weights Enabled Enable estimating split weights based on size in bytes TRUE BOOLEAN Hive Minimum Assigned Split Weight Minimum weight that a split can be assigned when size based split weights\n                      are enabled 0.05 DOUBLE Min(0, inclusive=false), Max(1) Hive Use Record Page Source For Custom Split Use record page source for custom split. By default, true. Used to query\n                      MOR tables in Hudi. TRUE BOOLEAN Hive Split Loader Concurrency Number of maximum concurrent threads per split source 4 INTEGER Min(1) Hive Domain Compaction Threshold Maximum ranges to allow in a tuple domain without compacting it 100 INTEGER Min(1) Hive Max Concurrent File Renames Maximum concurrent file renames 20 INTEGER Hive Max Concurrent Zero Row File Creations Maximum number of zero row file creations 20 INTEGER Min(1) Hive Recursive Directories Enable reading data from subdirectories of table or partition locations.\n                      If disabled, subdirectories are ignored. FALSE BOOLEAN Hive User Defined Type Encoding Enabled Enable user defined type FALSE BOOLEAN Hive Loose Memory Accounting Enabled When enabled relaxes memory accounting for queries violating memory\n                      limits to run that previously honored memory thresholds FALSE BOOLEAN Hive Max Outstanding Splits Size Maximum amount of memory allowed for split buffering for each table scan\n                      in a query, before the query is failed 256MB DATASIZE Min(1MB) Hive Max Split Iterator Threads Maximum number of iterator threads 1000 INTEGER Hive Allow Corrupt Writes For Testing Allow Hive connector to write data even when data will likely be\n                      corrupt FALSE BOOLEAN Hive Create Empty Bucket Files Should empty files be created for buckets that have no data? TRUE BOOLEAN Hive Max Partitions Per Writers Maximum number of partitions per writer 100 INTEGER Min(1) Hive Write Validation Threads Number of threads used for verifying data after a write 16 INTEGER Hive Orc Tiny Stripe Threshold ORC: Threshold below which an ORC stripe or file will read in its\n                      entirety 8MB DATASIZE Hive Orc Lazy Read Small Ranges ORC read small disk ranges lazily TRUE BOOLEAN Hive Orc Bloom Filters Enabled ORC: Enable bloom filters for predicate pushdown FALSE BOOLEAN Hive Orc Default Bloom Filter Fpp ORC Bloom filter false positive probability 0.05 DOUBLE Hive Orc Optimized Writer Enabled Experimental: ORC: Enable optimized writer TRUE BOOLEAN Hive Orc Writer Validation Percentage Percentage of ORC files to validate after write by re-reading the whole\n                      file 0 DOUBLE Min(0.0), Max(100.0) Hive Orc Writer Validation Mode Level of detail in ORC validation. Lower levels require more\n                      memory BOTH STRING possibleValues(HASHED, DETAILED, BOTH) Hive Rcfile Optimized Writer Enabled Experimental: RCFile: Enable optimized writer TRUE BOOLEAN Hive Assume Canonical Partition Keys Assume canonical parition keys? FALSE BOOLEAN Hive Parquet Fail On Corrupted Statistics Fail when scanning Parquet files with corrupted statistics TRUE BOOLEAN Hive Parquet Max Read Block Size Parquet: Maximum size of a block to read 16MB DATASIZE Hive Optimize Mismatched Bucket Count Enable optimization to avoid shuffle when bucket count is compatible but\n                      not the same FALSE BOOLEAN Hive Zstd Jni Decompression Enabled use JNI based zstd decompression for reading ORC files FALSE BOOLEAN Hive File Status Cache Size Hive file status cache size 0 LONG Hive File Status Cache Expire Time Hive file status cache : expiry time 0.00s DURATION Hive Per Transaction Metastore Cache Maximum Size Maximum number of metastore data objects in the Hive metastore cache per\n                      transaction 1000 INTEGER Min(1) Hive Metastore Refresh Interval Asynchronously refresh cached metastore data after access if it is older\n                      than this but is not yet expired, allowing subsequent accesses to see fresh\n                      data. 0.00s DURATION Hive Metastore Cache Maximum Size Maximum number of metastore data objects in the Hive metastore\n                      cache 10000 INTEGER Min(1) Hive Metastore Refresh Max Threads Maximum threads used to refresh cached metastore data 100 INTEGER Min(1) Hive Partition Versioning Enabled FALSE BOOLEAN Hive Metastore Impersonation Enabled Should Presto user be impersonated when communicating with Hive\n                      Metastore FALSE BOOLEAN Hive Partition Cache Validation Percentage Percentage of partition cache validation 0 DOUBLE Min(0.0), Max(100.0) Hive Metastore Thrift Client Socks Proxy metastore thrift client socks proxy STRING Hive Metastore Timeout Timeout for Hive metastore requests 10.00s DURATION Hive Dfs Verify Checksum Verify checksum for data consistency TRUE BOOLEAN Hive Metastore Cache Ttl Duration how long cached metastore data should be considered\n                      valid 0.00s DURATION Min(0ms) Hive Metastore Recording Path metastore recording path STRING Hive Replay Metastore Recording replay metastore recording FALSE BOOLEAN Hive Metastore Recoding Duration Metastore recording duration 0.00m DURATION Hive Dfs Require Hadoop Native hadoop native is required? TRUE BOOLEAN Hive Metastore Cache Scope Metastore cache scope ALL STRING possibleValues(ALL, PARTITION) Hive Metastore Authentication Type Hive metastore authentication type. NONE STRING possibleValues(NONE, KERBEROS) Hive Hdfs Authentication Type HDFS authentication type. NONE STRING possibleValues(NONE, KERBEROS) Hive Hdfs Impersonation Enabled Should Presto user be impersonated when communicating with HDFS FALSE BOOLEAN Hive Hdfs Wire Encryption Enabled Should be turned on when HDFS wire encryption is enabled FALSE BOOLEAN Hive Skip Target Cleanup On Rollback Skip deletion of target directories when a metastore operation fails and\n                      the write mode is DIRECT_TO_TARGET_NEW_DIRECTORY FALSE BOOLEAN Hive Bucket Execution Enable bucket-aware execution: only use a single worker per\n                      bucket TRUE BOOLEAN Hive Bucket Function Type For Exchange Hash function type for exchange HIVE_COMPATIBLE STRING possibleValues(HIVE_COMPATIBLE, PRESTO_NATIVE) Hive Ignore Unreadable Partition Ignore unreadable partitions and report as warnings instead of failing\n                      the query FALSE BOOLEAN Hive Max Buckets For Grouped Execution Maximum number of buckets to run with grouped execution 1000000 INTEGER Hive Sorted Write To Temp Path Enabled Enable writing temp files to temp path when writing to bucketed sorted\n                      tables FALSE BOOLEAN Hive Sorted Write Temp Path Subdirectory Count Number of directories per partition for temp files generated by writing\n                      sorted table 10 INTEGER Hive Fs Cache Max Size Hadoop FileSystem cache size 1000 INTEGER Hive Non Managed Table Writes Enabled Enable writes to non-managed (external) tables FALSE BOOLEAN Hive Non Managed Table Creates Enabled Enable non-managed (external) table creates TRUE BOOLEAN Hive Table Statistics Enabled Enable use of table statistics TRUE BOOLEAN Hive Partition Statistics Sample Size Specifies the number of partitions to analyze when computing table\n                      statistics. 100 INTEGER Min(1) Hive Ignore Corrupted Statistics Ignore corrupted statistics rather than failing FALSE BOOLEAN Hive Collect Column Statistics On Write Enables automatic column level statistics collection on write FALSE BOOLEAN Hive S3select Pushdown Enabled Enable query pushdown to AWS S3 Select service FALSE BOOLEAN Hive Max Initial Splits Max initial splits 200 INTEGER Hive Max Initial Split Size Max initial split size null DATASIZE Hive Writer Sort Buffer Size Write sort buffer size 64MB DATASIZE Min(1MB), Max(1GB) Hive Node Selection Strategy Node affinity selection strategy NO_PREFERENCE STRING possibleValues(HARD_AFFINITY, SOFT_AFFINITY, NO_PREFERENCE) Hive Max Split Size Max split size 64MB DATASIZE Hive Max Partitions Per Scan Maximum allowed partitions for a single table scan 100000 INTEGER Min(1) Hive Max Outstanding Splits Target number of buffered splits for each table scan in a query, before\n                      the scheduler tries to pause itself 1000 INTEGER Min(1) Hive Metastore Partition Batch Size Min hive metastore : min batch size for partitions 10 INTEGER Min(1) Hive Metastore Partition Batch Size Max hive metastore : max batch size for partitions 100 INTEGER Min(1) Hive Config Resources An optional comma-separated list of HDFS configuration files [] FILEPATH Hive Dfs Ipc Ping Interval The client will send ping when the interval is passed without receiving\n                      bytes 10.00s DURATION Hive Dfs Timeout DFS timeout 60.00s DURATION Min(1ms) Hive Dfs Connect Timeout DFS connection timeout 500.00ms DURATION Min(1ms) Hive Dfs Connect Max Retries DFS - max retries in case of connection issue 5 INTEGER Min(0) Hive Storage Format The default file format used when creating new tables. ORC STRING possibleValues(ORC, DWRF, PARQUET, AVRO, RCBINARY, RCTEXT, SEQUENCEFILE,\n                      JSON, TEXTFILE, CSV, PAGEFILE) Hive Compression Codec The compression codec to use when writing files GZIP STRING possibleValues(NONE, SNAPPY, LZ4, ZSTD, GZIP) Hive Orc Compression Codec The preferred compression codec to use when writing ORC and DWRF\n                      files GZIP STRING possibleValues(NONE, SNAPPY, LZ4, ZSTD, GZIP) Hive Respect Table Format Should new partitions be written using the existing table format or the\n                      default PrestoDB format? TRUE BOOLEAN Hive Immutable Partitions Can new data be inserted into existing partitions? FALSE BOOLEAN Hive Max Open Sort Files Maximum number of writer temporary files to read in one pass 50 INTEGER Min(2), Max(1000) Hive Dfs Domain Socket Path This is a path in the filesystem that allows the client and the DataNodes\n                      to communicate. null STRING Hive S3 File System Type s3 file system type PRESTO STRING possibleValues(PRESTO, EMRFS, HADOOP_DEFAULT) Hive S3 Use Instance Credentials Use the EC2 metadata service to retrieve API credentials (defaults to\n                      true). This works with IAM roles in EC2. FALSE BOOLEAN Hive S3 Encryption Materials Provider Use a custom encryption materials provider for S3 data encryption STRING Hive S3 Multipart Min File Size Minimum file size for an S3 multipart upload 16MB DATASIZE Hive S3 Multipart Min Part Size Minimum part size for an S3 multipart upload 5MB DATASIZE Hive S3 Pin Client To Current Region Pin S3 requests to the same region as the EC2 instance where Presto is\n                      running FALSE BOOLEAN Hive S3 Upload Acl Type Canned ACL type for S3 uploads PRIVATE STRING possibleValues(AUTHENTICATED_READ, AWS_EXEC_READ,\n                      BUCKET_OWNER_FULL_CONTROL, BUCKET_OWNER_READ, LOG_DELIVERY_WRITE, PRIVATE,\n                      PUBLIC_READ, PUBLIC_READ_WRITE) Hive S3 User Agent Prefix The user agent prefix to use for S3 calls STRING Hive S3 Skip Glacier Objects Ignore Glacier objects rather than failing the query. This will skip data\n                      that may be expected to be part of the table or partition FALSE BOOLEAN Hive S3 Sse Enabled Use S3 server-side encryption FALSE BOOLEAN Hive S3 Sse Type The type of key management for S3 server-side encryption S3 STRING possibleValues(S3, KMS) Hive S3 Max Client Retries Maximum number of read attempts to retry 5 INTEGER Min(0) Hive S3 Max Error Retries Maximum number of error retries, set on the S3 client 10 INTEGER Min(0) Hive S3 Max Backoff Time Use exponential backoff starting at 1 second up to this maximum value\n                      when communicating with S3 10.00m DURATION Min(1s) Hive S3 Max Retry Time Maximum time to retry communicating with S3 10.00m DURATION Min(1ms) Hive S3 Connect Timeout The default timeout for creating new connections. 5.00s DURATION Min(1ms) Hive S3 Socket Timeout The default timeout for reading from a connected socket. 5.00s DURATION Min(1ms) Hive S3 Max Connections Sets the maximum number of allowed open HTTP connections 500 INTEGER Min(1) Hive S3 Staging Directory Local staging directory for data written to S3. STRING Hive S3 Aws Access Key Default AWS access key to use. STRING Hive S3 Aws Secret Key Default AWS secret key to use. STRING Hive S3 Endpoint The S3 storage endpoint server. STRING Hive S3 Storage Class The S3 storage class to use when writing the data. STANDARD STRING possibleValues(STANDARD, INTELLIGENT_TIERING) Hive S3 Signer Type Specify a different signer type for S3-compatible storage STRING possibleValues(S3SignerType, AWS3SignerType, AWS4SignerType,\n                      AWSS3V4SignerType, CloudFrontSignerType, QueryStringSignerType) Hive S3 Path Style Access Use path-style access for all requests to the S3-compatible\n                      storage FALSE BOOLEAN Hive S3 Iam Role IAM role to assume STRING Hive S3 Iam Role Session Name AWS STS session name when IAM role to assume to access S3 buckets presto-session STRING Hive S3 Ssl Enabled Use HTTPS to communicate with the S3 API TRUE BOOLEAN Hive S3 Kms Key Id If set, use S3 client-side encryption and use the AWS KMS to store\n                      encryption keys and use the value of this property as the KMS Key ID for newly\n                      created objects STRING Hive S3 Sse Kms Key Id The KMS Key ID to use for S3 server-side encryption with KMS-managed\n                      keys STRING Hive Gcs Json Key File Path JSON key file used to access Google Cloud Storage FILEPATH Hive Gcs Use Access Token Use client-provided OAuth token to access Google Cloud Storage FALSE BOOLEAN Hive Orc Use Column Names Access ORC columns using names from the file FALSE BOOLEAN Hive Orc Max Merge Distance ORC: Maximum size of gap between two reads to merge into a single\n                      read 1MB DATASIZE Hive Orc Max Buffer Size ORC: Maximum size of a single read 8MB DATASIZE Hive Orc Stream Buffer Size ORC: Size of buffer for streaming reads 8MB DATASIZE Hive Orc Max Read Block Size ORC: Soft max size of Presto blocks produced by ORC reader 16MB DATASIZE Hive Rcfile Writer Validate Validate RCFile after write by re-reading the whole file FALSE BOOLEAN Hive Text Max Line Length Maximum line length for text files 100MB DATASIZE Min(1B), Max(1GB) Hive Parquet Use Column Names Access Parquet columns using names from the file FALSE BOOLEAN Hive File Status Cache Tables The tables that have file status cache enabled. Setting to '*' includes\n                      all tables STRING Hive Skip Deletion For Alter Skip deletion of old partition data when a partition is deleted and then\n                      inserted in the same transaction FALSE BOOLEAN Hive Sorted Writing Enable writing to bucketed sorted tables TRUE BOOLEAN Hive Ignore Table Bucketing Ignore table bucketing to enable reading from unbucketed\n                      partitions FALSE BOOLEAN Hive Temporary Table Schema Schema where to create temporary tables default STRING Hive Pushdown Filter Enabled Experimental: enable complex filter pushdown FALSE BOOLEAN Hive Pagefile Writer Stripe Max Size PAGEFILE: Max stripe size 24MB DATASIZE Hive File_renaming_enabled enable file renaming FALSE BOOLEAN Hive\n                      Partial_aggregation_pushdown_for_variable_length_datatypes_enabled enable partial aggregation pushdown for variable length datatypes FALSE BOOLEAN Hive Time Zone Sets the default time zone STRING Hive Orc Writer Stripe Min Size ORC: Min stripe size 32MB DATASIZE Hive Orc Writer Stripe Max Size ORC: Max stripe size 64MB DATASIZE Hive Orc Writer Stripe Max Rows ORC: Max stripe row count 10000000 INTEGER Hive Orc Writer Row Group Max Rows ORC : Max rows in row group 10000 INTEGER Hive Orc Writer Dictionary Max Memory ORC: Max dictionary memory 16MB DATASIZE Hive Orc Writer String Statistics Limit ORC: Maximum size of string statistics; drop if exceeding 64B DATASIZE Hive Orc Writer Stream Layout Type ORC: Stream layout type BY_COLUMN_SIZE STRING possibleValues(BY_STREAM_SIZE, BY_COLUMN_SIZE) Hive Orc Writer Dwrf Stripe Cache Mode Describes content of the DWRF stripe metadata cache. INDEX_AND_FOOTER STRING possibleValues (NONE, INDEX, FOOTER, INDEX_AND_FOOTER) Hive Orc Writer Max Compression Buffer Size ORC : Max compression buffer size 256kB DATASIZE Hive Orc Writer Dwrf Stripe Cache Enabled DWRF stripe cache enabled? FALSE BOOLEAN Hive Orc Writer Dwrf Stripe Cache Max Size DWRF stripe cache max size 8MB DATASIZE Hive Parquet Optimized Writer Enabled Parquet: Optimized writer enabled? FALSE BOOLEAN Hive Parquet Writer Block Size Parquet: Writer block size 134217728B DATASIZE Hive Parquet Writer Page Size Parquet: Writer page size 1048576B DATASIZE Hive Allow Add Column Allow Hive connector to add column FALSE BOOLEAN Hive Allow Drop Column Allow Hive connector to drop column FALSE BOOLEAN Hive Allow Drop Table Allow Hive connector to drop table FALSE BOOLEAN Hive Allow Rename Table Allow Hive connector to rename table FALSE BOOLEAN Hive Allow Rename Column Allow Hive connector to rename column FALSE BOOLEAN Hive Security The type of access control to use legacy STRING possibleValues(legacy, file, read-only, sql-standard) Generic Cache Table Ttl TTL for cache table expiry in minutes 1440 INTEGER Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/connect-iceberg.html",
        "title": "Iceberg Connection Parameters"
    },
    {
        "content": "\nConfiguring a Hive Data Source with Kerberos Authentication Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Delta Connection Parameters List of Delta connection parameters, descriptions, default values, and supported data     types. Delta Thrift Connection Parameters List of  Delta Thrift connection parameters, descriptions, default values, and     supported data types. Hive Connection Parameters List of Hive connection parameters, descriptions, default values, and supported data     types. Hive Glue Metastore Connection Parameters List of Hive Glue Metastore connection parameters, descriptions, default values, and     supported data types. Hive Thrift Metastore Connection Parameters List of Hive Thrift Metastore connection parameters, descriptions, default values, and     supported data types. Hive Discovery Metastore Connection Parameters Lists Hive discovery metastore connection parameters, parameter descriptions, default     values, and supported data types. MySQL Connection Parameters List of MySQL connection parameters, descriptions, default values, and supported data     types. Oracle Connection Parameters List of Oracle connection parameters, descriptions, default values, and supported data     types. Snowflake Connection Parameters List of  Snowflake connection parameters, descriptions, default values, and supported     data types. SQL Server Connection Parameters List of SQL Server connection parameters, descriptions, default values, and supported     data types. Teradata Connection Parameters List of  Teradata connection parameters, descriptions, default values, and supported     data types. PostgreSQL Connection Parameters List of PostgreSQL connection parameters, descriptions, default values, and supported     data types. Iceberg Connection Parameters List of Iceberg connection parameters, descriptions, default values, and supported data     types. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source     that uses Kerberos authentication. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Configuring a Hive Data Source with Kerberos Authentication Describes the required prerequisite steps to complete before you connect HPE Ezmeral Unified Analytics Software to a Hive data source\n    that uses Kerberos authentication. You can connect HPE Ezmeral Unified Analytics Software to a Hive data source that uses a Hive metastore and Kerberos for authentication. However,\n      before you create the connection, manually complete the following steps: Step 1 - Upload a krb5 configuration file to the shared location Step 2 - Configure EzPresto to use the krb5.conf file Step 3 - Connect HPE Ezmeral Unified Analytics Software to the Hive data source Step 1 - Upload a krb5 configuration file to the shared location The krb5.conf file contains Kerberos configuration information, including\n        the locations of the KDCs and admin servers for the Kerberos realms used in the Hive\n        configuration. To upload the krb5.conf file to a shared location, complete\n        the following steps: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, go to Data Engineering > Data Sources > Data\n              Volumes. . Select the shared directory. Upload a krb5.conf file to the shared directory. TIP The\n              name of the file must be krb5.conf . Step 2 - Configure EzPresto to use the krb5.conf file In the left navigation bar, go to Tools & Frameworks > Data Engineering\n              > EzPresto . Click on the three dots and select Configure . In the window that appears, remove the entire cmnConfigMaps section\n            and replace it with the following JVM properties: cmnConfigMaps:\n  # Configmaps common to both Presto Master and Worker\n  logConfig:\n    log.properties: |\n      # Enable verbose logging from Presto\n      #com.facebook.presto=DEBUG\n  prestoMst:\n    cmnPrestoCoordinatorConfig:\n      config.properties: |\n        http-server.http.port={{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        discovery.uri=http://{{ tpl .Values.ezsqlPresto.locatorService.fullname $ }}:{{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        coordinator=true\n        node-scheduler.include-coordinator=false\n        discovery-server.enabled=true\n        catalog.config-dir = {{ .Values.ezsqlPresto.stsDeployment.volumeMount.mountPathCatalog }}\n        catalog.disabled-connectors-for-dynamic-operation=drill,parquet,csv,salesforce,sharepoint,prestodb,raptor,kudu,redis,accumulo,elasticsearch,redshift,localfile,bigquery,prometheus,mongodb,pinot,druid,cassandra,kafka,atop,presto-thrift,ampool,hive-cache,memory,blackhole,tpch,tpcds,system,example-http,jmx\n        generic-cache-enabled=true\n        transparent-cache-enabled=false\n        generic-cache-catalog-name=cache\n        generic-cache-change-detection-interval=300\n        catalog.config-dir.shared=true\n        node.environment=production\n        plugin.dir=/usr/lib/presto/plugin\n        log.output-file=/data/presto/server.log\n        log.levels-file=/usr/lib/presto/etc/log.properties\n        query.max-history=1000\n        query.max-stage-count=1000\n        query.max-memory={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        query.max-total-memory={{ mulf 0.7 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        # query.max-memory-per-node={{ mulf 0.5 ( tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.maxHeapSize . ) | floor }}MB\n        # query.max-total-memory-per-node={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.maxHeapSize . ) | floor }}MB\n        # memory.heap-headroom-per-node={{ mulf 0.3 ( tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.maxHeapSize . ) | floor }}MB\n        experimental.spill-enabled=false\n        experimental.spiller-spill-path=/tmp\n        orm-database-url=jdbc:sqlite:/data/cache/metadata.db\n        plugin.disabled-connectors=accumulo,atop,cassandra,example-http,kafka,kudu,localfile,memory,mongodb,pinot,presto-bigquery,prestodb,presto-druid,presto-elasticsearch,prometheus,raptor,redis,redshift\n        log.max-size=100MB\n        log.max-history=10\n        discovery.http-client.max-requests-queued-per-destination=10000\n        dynamic.http-client.max-requests-queued-per-destination=10000\n        event.http-client.max-requests-queued-per-destination=10000\n        exchange.http-client.max-requests-queued-per-destination=10000\n        failure-detector.http-client.max-requests-queued-per-destination=10000\n        memoryManager.http-client.max-requests-queued-per-destination=10000\n        node-manager.http-client.max-requests-queued-per-destination=10000\n        scheduler.http-client.max-requests-queued-per-destination=10000\n        workerInfo.http-client.max-requests-queued-per-destination=10000\n    jvmConfig:\n      jvm.config: |\n        -server\n        -Xms{{ tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.minHeapSize . | floor }}M\n        -Xmx{{ tpl .Values.ezsqlPresto.configMapProp.mst.jvmProp.maxHeapSize . | floor }}M\n        -XX:-UseBiasedLocking\n        -XX:+UseG1GC\n        -XX:G1HeapRegionSize={{ .Values.ezsqlPresto.configMapProp.mst.jvmProp.G1HeapRegionSize }}\n        -XX:+ExplicitGCInvokesConcurrent\n        -XX:+HeapDumpOnOutOfMemoryError\n        -XX:+UseGCOverheadLimit\n        -XX:+ExitOnOutOfMemoryError\n        -XX:ReservedCodeCacheSize={{ .Values.ezsqlPresto.configMapProp.mst.jvmProp.ReservedCodeCacheSize }}\n        -XX:PerMethodRecompilationCutoff=10000\n        -XX:PerBytecodeRecompilationCutoff=10000\n        -Djdk.attach.allowAttachSelf=true\n        -Djdk.nio.maxCachedBufferSize={{ .Values.ezsqlPresto.configMapProp.jvmProp.maxCachedBufferSize }}\n        -Dcom.amazonaws.sdk.disableCertChecking=true\n        -Djava.security.krb5.conf=/data/shared/krb5.conf\n  prestoWrk:\n    prestoWorkerConfig:\n      config.properties: |\n        coordinator=false\n        http-server.http.port={{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        discovery.uri=http://{{ tpl .Values.ezsqlPresto.locatorService.fullname $ }}:{{ tpl .Values.ezsqlPresto.locatorService.locatorSvcPort $ }}\n        catalog.config-dir = {{ .Values.ezsqlPresto.stsDeployment.volumeMount.mountPathCatalog }}\n        catalog.disabled-connectors-for-dynamic-operation=drill,parquet,csv,salesforce,sharepoint,prestodb,raptor,kudu,redis,accumulo,elasticsearch,redshift,localfile,bigquery,prometheus,mongodb,pinot,druid,cassandra,kafka,atop,presto-thrift,ampool,hive-cache,memory,blackhole,tpch,tpcds,system,example-http,jmx\n        generic-cache-enabled=true\n        transparent-cache-enabled=false\n        generic-cache-catalog-name=cache\n        catalog.config-dir.shared=true\n        node.environment=production\n        plugin.dir=/usr/lib/presto/plugin\n        log.output-file=/data/presto/server.log\n        log.levels-file=/usr/lib/presto/etc/log.properties\n        query.max-memory={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        query.max-total-memory={{ mulf 0.7 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) ( .Values.ezsqlPresto.stsDeployment.wrk.replicaCount ) | floor }}MB\n        query.max-memory-per-node={{ mulf 0.5 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) | floor }}MB\n        query.max-total-memory-per-node={{ mulf 0.6 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) | floor }}MB\n        memory.heap-headroom-per-node={{ mulf 0.2 ( tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . ) | floor }}MB\n        experimental.spill-enabled=false\n        experimental.spiller-spill-path=/tmp\n        orm-database-url=jdbc:sqlite:/data/cache/metadata.db\n        plugin.disabled-connectors=accumulo,atop,cassandra,example-http,kafka,kudu,localfile,memory,mongodb,pinot,presto-bigquery,prestodb,presto-druid,presto-elasticsearch,prometheus,raptor,redis,redshift\n        log.max-size=100MB\n        log.max-history=10\n        discovery.http-client.max-requests-queued-per-destination=10000\n        event.http-client.max-requests-queued-per-destination=10000\n        exchange.http-client.max-requests-queued-per-destination=10000\n        node-manager.http-client.max-requests-queued-per-destination=10000\n        workerInfo.http-client.max-requests-queued-per-destination=10000\n    jvmConfig:\n      jvm.config: |\n        -server\n        -Xms{{ tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.minHeapSize . | floor }}M\n        -Xmx{{ tpl .Values.ezsqlPresto.configMapProp.wrk.jvmProp.maxHeapSize . | floor }}M\n        -XX:-UseBiasedLocking\n        -XX:+UseG1GC\n        -XX:G1HeapRegionSize={{ .Values.ezsqlPresto.configMapProp.wrk.jvmProp.G1HeapRegionSize }}\n        -XX:+ExplicitGCInvokesConcurrent\n        -XX:+HeapDumpOnOutOfMemoryError\n        -XX:+UseGCOverheadLimit\n        -XX:+ExitOnOutOfMemoryError\n        -XX:ReservedCodeCacheSize={{ .Values.ezsqlPresto.configMapProp.wrk.jvmProp.ReservedCodeCacheSize }}\n        -XX:PerMethodRecompilationCutoff=10000\n        -XX:PerBytecodeRecompilationCutoff=10000\n        -Djdk.attach.allowAttachSelf=true\n        -Djdk.nio.maxCachedBufferSize={{ .Values.ezsqlPresto.configMapProp.jvmProp.maxCachedBufferSize }}\n        -Dcom.amazonaws.sdk.disableCertChecking=true\n        -Djava.security.krb5.conf=/data/shared/krb5.conf\n### values_cmn_configmap.yaml contents END Click Configure . This updates the configuration on each of the presto pods and\n            restarts the pods. This operation can take a few minutes. Step 3 - Connect HPE Ezmeral Unified Analytics Software to the Hive data source In the left navigation bar, go to Data Engineering > Data\n              Sources . Click Add New Data Source . In the Hive tile, click Create Connection . Using the following connection properties as an example, add the connection properties\n            for your environment and then Connect. Name = kdchive\nHive Metastore = Thrift\nHive Metastore Uri = thrift://m2-dev.mip.storage.mycorp.net:9083\nHive Metastore Authentication Type=KERBEROS\nHive Metastore Service Principal=hive/_HOST@MYCORP.NET\nHive Metastore Client Principal=supergroup@MYCORP.NET\nHive Metastore Client Keytab=<Uploaded the keytab file for supergroup user>\nHive Hdfs Authentication Type=KERBEROS\nHive Hdfs Presto Principal=supergroup@MYCORP.NET\nHive Hdfs Presto Keytab=<Uploaded the keytab file for supergroup user> On this page Step 1 - Upload a krb5 configuration file to the shared location Step 2 - Configure EzPresto to use the krb5.conf file Step 3 - Connect HPE Ezmeral Unified Analytics Software to the Hive data source Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/hive-kerberos-auth.html",
        "title": "Configuring a Hive Data Source with Kerberos Authentication"
    },
    {
        "content": "\nConnect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and\n    Parquet data in S3-based external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector You can connect HPE Ezmeral Unified Analytics Software to any external S3-based data source through the Hive connector and Presto to access CSV and\n      Parquet data. For example, you can connect HPE Ezmeral Unified Analytics Software to an external Data Fabric, Iceberg, or Spark cluster to access\n      CSV and Parquet data in S3 storage within these data sources. Connection Requirements Connecting to an S3-based external data source has the following requirements: You must have read/write access on the S3 data source. You must provide the required information to connect, including the: Access key Secret key S3 directory where files are stored S3 endpoint Connection fields vary depending on the type of data source you connect to (Data\n        Fabric, Iceberg, Spark, etc.); however, the S3-related fields (credentials, directory, and\n        endpoint) are always required regardless of the data source you are accessing S3 data\n          through. IMPORTANT A Hive Metastore is not required. HPE Ezmeral Unified Analytics Software scans the files in\n          the S3 data source to get metadata and determine data types. For more information about the PrestoDB Hive connector, see Hive Connector . Connecting to an S3-Based Data Source To connect to an S3-based data source: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Data Engineering > Data\n            Sources . Click Add New Data Source . In the Hive tile, click Create Connection . In the drawer that opens, enter values in the required fields. An asterisk (*) denotes a\n          required field. For Hive Metastore , select Discovery . In the Optional Fields search field, find and add the following fields: Field Name Description Hive S3 AWS Access Key Enter the AWS access key. Hive S3 AWS Secret Key Enter the AWS secret key. Hive S3 Endpoint Enter the S3 endpoint. Hive S3 Path Style Access Select the checkbox. Click Connect . Upon successful connection, the data source is available on the Data Sources page. In the left navigation bar, select Data Engineering > Data\n            Sources . In the data source tile, click Query using Data Catalog to access the S3\n          data. On the Data Catalog page, identify the data source and select the schema to view\n          the data. Example: Connect to Data Fabric Object Store to access\n        Parquet files The objective of this example is to demonstrate how to connect HPE Ezmeral Unified Analytics Software to Parquet\n        data in the Data Fabric Object Store (S3-based data store). TIP To connect to\n          Data Fabric Object Store, you need working knowledge of Data Fabric Object Store,\n          read/write access to a bucket (granted via IAM policies), and the ability to generate the\n          access key and secret key in Data Fabric Object Store. In this example, a\n        bucket named prestodemo exists in Data Fabric Object Store. Inside the bucket is a tpch002 directory with nation and nationalhistory sub-directories\n        that contain Parquet files. The following image shows the Data Fabric Object Store prestodemo bucket and directories within the bucket: To create\n        the HPE Ezmeral Unified Analytics Software connection\n        to Data Fabric Object Store, the following information from Data Fabric Object Store is\n          required: Access key Secret key S3 directory where files are stored (Example: s3://prestodemo/tpch002 ) S3 endpoint (This is the Data Fabric Object Store IP address and port, for example: https://10.10.10.100:9000 Connecting HPE Ezmeral Unified Analytics Software to an S3 Directory in Data Fabric Object Store To connect to the S3 directory in the external Data Fabric Object Store\n                cluster: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Data Engineering > Data Sources . Click Add New Data Source . In the Hive tile, click Create Connection . In the drawer that opens, complete the required fields: TIP You have to search for and add some fields in the drawer. Use the search\n                        field under Optional Fields to find and add these fields. No external Hive Metastore is required; HPE Ezmeral Unified Analytics Software internally parses and scans the files to get the data types and\n                        metadata. Field Name Example Notes Name demoparquet Unique name for the data source connection. Hive Metastore Discovery System scans files to discover metadata and data types. Data Dir s3://prestodemo/tpch002 S3 directory where files are stored. File Type Parquet You can select Parquet or CSV depending on the type of data in\n                              the S3 directory. Hive S3 AWS Access Key The access key generated by the Data Fabric Object Store. Under Optional Fields, search for this field in the search box\n                              and select it. Hive S3 AWS Secret Key The secret key generated by the Data Fabric Object Store. Under Optional Fields, search for this field in the search box\n                              and select it. Hive S3 Endpoint https://10.10.10.100:9000 The Data Fabric Object Store connection URL. Under Optional\n                              Fields, search for this field in the search box and select it. Hive S3 Path Style Access Select the checkbox. Under Optional Fields, search for this field in the search box\n                              and select it. Click Connect . The system displays the message, \"Successfully\n                    added data source,\" and the new data source ( demoparquet ) tile\n                  appears on the Data Sources page. In the new data source tile ( demoparquet ), click Query using Data\n                    Catalog . You can see the demoparquet source\n                      listed. Select the schema ( default ) under the data source to view the data\n                    sets. NOTE Each subdirectory in the S3 directory displays as a table in HPE Ezmeral Unified Analytics Software , and each\n                    Parquet file in the subdirectory is a row in the table. Click on a table ( nation ) and then click the Data Preview tab to\n                  view the Parquet data. On this page Connection Requirements Connecting to an S3-Based Data Source Example: Connect to Data Fabric Object Store to access\n        Parquet files Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/connect-external-s3-data-source.html",
        "title": "Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector"
    },
    {
        "content": "\nConnect to External Applications via JDBC Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and\n    PowerBI, to EzPresto through the EzPresto JDBC endpoint. Connecting applications to EzPresto provides\n      users with the convenience of using their preferred applications and the ability to leverage\n      the high performance SQL query engine to quickly build out powerful executive charts and\n      dashboards from massive amounts of data. You can connect external applications to EzPresto using the JDBC connection URL or code. Getting the JDBC Endpoint You can get the JDBC endpoint in Unified Analytics by going to Administration > Settings in the\n        left navigation bar. On the Configurations tab, select JDBC Endpoint . The JDBC\n        endpoint is displayed. JDBC Connection URL Use the following URL to connect EzPresto to external applications, replacing the domain with your Unified Analytics cluster\n        domain: jdbc:presto://ezpresto.<unified-analytics-cluster-domain>:443 JDBC Connection Code To programmatically connect external applications to EzPresto , use the following code and enter values specific to your Unified Analytics cluster domain and user: String url = \"jdbc:presto://ezpresto.unified-analytics-cluster-domain:443\";\nProperties properties = new Properties();\nproperties.setProperty(\"user\", \"ua-user\");\nproperties.setProperty(\"password\", \"ua-user-password\");\nproperties.setProperty(\"SSL\", \"true\");\nConnection connection = DriverManager.getConnection(url, properties); Tableau Connection Example The following example shows you how to connect Tableau to EzPresto : Server : ezpresto.<unified-analytics-cluster-domain-name>\nPort : 443\nCatalog : <catalog-from-presto to which user wants to connect>\nAuthentication : LDAP\nUsername : <ua-user-name>\nPassword: <ua-user-password>\nRequire SSL : true NOTE The Tableau connector does not support SSO. The\n          username and password are required On this page Getting the JDBC Endpoint JDBC Connection URL JDBC Connection Code Tableau Connection Example Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/jdbc-connection.html",
        "title": "Connect to External Applications via JDBC"
    },
    {
        "content": "\nUsing Spark to Query EzPresto Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Spark images packaged with HPE Ezmeral Unified Analytics Software include the Presto client library required to connect Spark to EzPresto . Spark runtimes do not have the EzPresto certificate in the truststore; therefore, when you connect Spark to EzPresto , you must set the IgnoreSSLChecks option to true . For open-source Spark use cases, the CA certificate must be available in the JVM truststore.\n      You can set a custom path to the truststore using the jdbc SSLTrustStorePath option. Note that you must use JKS format. The following example shows you how to use Spark to submit a dataframe to\n      query EzPresto : DOMAIN='<your-unified-analytics-domain-name>'\n\ndf = spark.read.format(\"jdbc\").\\\n      option(\"driver\", \"com.facebook.presto.jdbc.PrestoDriver\").\\\n      option(\"url\", \"jdbc:presto://ezpresto.{DOMAIN}.com:443/cache/default>\").\\\n      option(\"user\", \"<username>\").\\\n      option(\"SSL\", \"true\").\\\n      option(\"IgnoreSSLChecks\", \"true\").]\\\n      option(\"query\", \"select * from cache.information_schema.columns\").]\\\n      load().show() Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/connect-spark-ezpresto.html",
        "title": "Using Spark to Query EzPresto"
    },
    {
        "content": "\nConnect to EzPresto via Python Client Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Connecting to EzPresto from a Python client is\n            useful for Notebooks. Use the presto-python-client and presto packages to connect to EzPresto from a Python client. Required Packages Run the following commands to install the presto-python-client and presto packages: pip install presto-python-client\n\npip install presto Example The following code example shows you how to connect to EzPresto from a Python\n                client: import urllib3\nimport uuid\nimport requests\nfrom requests.packages.urllib3.exceptions import InsecureRequestWarning\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\nimport warnings\nwarnings.filterwarnings('ignore')  #This will ignore the warnings. Warnings will not display in the notebook.\nimport prestodb\nimport getpass\n\n\nclass DBComponentEzsql(object):\n    def __init__(self, **args):\n        self._db_version = str\n        self._http_scheme = args['http_scheme']\n        self._schema = args['schema']\n        self._catelog = args['catelog']\n        self._host = args['host']\n        self._user = args['user']\n        self._pwd = args['password']\n        self._port = args['port']\n        self._test_query= \"select database();\"\n        self._cursor = object\n        self._connection = object\n        self._err = \"Exception while connecting to PrestoDB, there, check with your Administrator !!!\"\n    \n    # this is the prestodb connect component user defined function.\n    def _connect(self)->object:\n        try:\n            with prestodb.dbapi.connect(host=self._host, port=self._port, user=self._user, catalog=self._catelog, schema= self._schema, http_scheme=self._http_scheme, auth=prestodb.auth.BasicAuthentication(self._user, self._pwd)) as self._connection:\n                self._connection._http_session.verify = False\n\n            if self._connection:\n                return self._connection\n\n        except Exception as e:\n            print(self._err, e)\n            exit(0)\n\n        finally:\n            if self._connection:\n                self._connection.close()\n    \n    # this is the prestodb connect component user defined function.\n    def _old_connect(self)->object:\n        try:\n            with prestodb.dbapi.connect(host=self._host, port=self._port, user=self._user, catalog=self._catelog, schema=self._schema, http_scheme=self._http_scheme, auth=prestodb.auth.BasicAuthentication(self._user, self._pwd)) as self._connection:\n                self._connection._http_session.verify = False\n\n            if self._connection:\n                return self._connection\n\n        except Exception as e:\n            print(self._err, e)\n            exit(0)\n\n        finally:\n            if self._connection:\n                self._connection.close()\n    \n    #returns sql schema consisted table details                \n    def _get_sql_schema(self, **args)->list:\n        try:\n            self._cursor = self._connection.cursor()\n            # self._cursor.execute('show catalogs')\n            self._cursor.execute('SHOW SCHEMAS')\n            _db_list = self._cursor.fetchall()\n            return _db_list\n        except Exception as e:\n            print(self._err, e)\n        finally:\n            if self._connection:\n                self._connection.close()\n                self._cursor.close()\n\n    #returns sql schema consisted table details                \n    def _get_sql_tables(self, **args)->list:\n        try:\n            self._connection.close()\n            if self._schema != None and args[\"run_schema\"] != None:\n                self._schema = args[\"run_schema\"]\n                self._connection = self._connect()\n                self._cursor = self._connection.cursor()\n                self._cursor.execute('show tables')\n                _table_list = self._cursor.fetchall()\n                return _table_list\n        except Exception as e:\n            print(self._err, e)\n        finally:\n            if self._connection:\n                self._connection.close()\n                self._cursor.close()\n    \n    #returns sql table persisted data\n    def _get_data(self,**args)->list:\n        try:\n            if args['table_name']!= None:\n                ''' This generalized sql query we must need to extend '''\n                str_query = f\"SELECT * FROM {args['table_name']}\"\n                self._cursor = self._connection.cursor()\n                self._cursor.execute(str_query)\n                res_data = self._cursor.fetchall()\n                return res_data\n        except Exception as e:\n            print(self._err, e)\n        finally:\n            if self._connection:\n                self._connection.close()\n                self._cursor.close()\n\nif __name__ == \"__main__\":\n    try:\n        # config to validate the schema name:\n        config = {\n            \"host\":\"ezsql.hpe-qa1-ezaf.com\", \n            \"catelog\":\"mysql\",\n            \"user\":\"hpedemo-user01\", \n            \"password\":\"Hpepoc@123\", \n            \"schema\":\"retailstore\",\n            \"http_scheme\":\"https\",\n            \"port\":443,\n            \"table\": \"call_center\"\n        }\n        \n        ezobj = DBComponentEzsql(\n            host=config.get(\"host\"), \n            catelog=config.get(\"catelog\"),\n            schema=\"default\",\n            user= config.get(\"user\"),\n            password=config.get(\"password\"), \n            http_scheme = config.get(\"http_scheme\"),\n            port=config.get(\"port\"))\n        conn = ezobj._connect()\n        print(\"-\"*100, conn)\n        \n        ''' How we can use the developed core Ezmeral unified analytics Ezsql component explained bellow !!!'''\n        if conn:\n            print(\"-\"*100,\" print list of schams \", ezobj._get_sql_schema())\n            for item in range(0, len(ezobj._get_sql_schema())):\n                # validate desired scema:\n                if config.get(\"schema\") in ezobj._get_sql_schema()[item]:\n                    print(ezobj._get_sql_tables(run_schema=config.get(\"schema\")))\n                    print(ezobj._get_data(table_name=config.get(\"table\")))\n                    \n    except Exception as e:\n        print(ezobj._err, e) On this page Required Packages Example Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/connect-python-ezpresto.html",
        "title": "Connect to EzPresto via Python Client"
    },
    {
        "content": "\nCache Data Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Caching data reduces latency. You can pre-load frequently accessed data into the cache to\n      improve the performance of queries on the data. Caching is useful when network latency is an\n      issue due to firewalls. When queries run against data or tables, the query engine automatically checks for cached\n      data and uses it if present. Cache optimization works when queries reference remote tables.\n      Queries issued against cached data do not require optimization. The cache lasts for the duration of the TTL (time-to-live). The user that connects HPE Ezmeral Unified Analytics Software to a data source\n      selects the caching option ( Enable Local Snapshot Table ) and sets the TTL for the\n      cache. The default TTL is one day (set in minutes). HPE Ezmeral Unified Analytics Software stores cached\n      data in an HPE Ezmeral Data Fabric volume. You can view and access cached data in the HPE Ezmeral Unified Analytics Software UI by going to Data Engineering > Cached Assets in the left navigation bar. When you cache data, you can modify the data sets before caching them. The following list\n      describes some of the changes that you can make to a data set: Edit the data set name Remove columns from the data set Edit column names Change the schema or add a new schema Apply a schema to the selected data sets IMPORTANT Cached data is only available to the user that cached the data. Other users that sign\n            in to HPE Ezmeral Unified Analytics Software cannot access the data that you cache. If data in the underlying data sources change, HPE Ezmeral Unified Analytics Software does not automatically update the cache. You\n            must cache the data again to refresh the cache. How to Cache Data HPE Ezmeral Unified Analytics Software must be\n        connected to the data sources with the data sets that you want to cache. See Connect Data Sources . To cache data, complete the following steps: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Data Engineering > Data\n              Catalog. In the Connected Data Sources area, select the data sources with the data that\n            you want to cache. The data sets available to you in the selected data sources displays\n            in the All Datasets area. Optionally, search or filter the data sets to find the data set(s) that you want to\n            cache. Click + Select for each of the data sets that you want to cache. Click Selected Datasets . The Selected Datasets drawer opens and displays\n            the selected data sets. Click Cache Datasets . The Manage Datasets screen appears. Each data set\n            that you selected appears on its own tab. Optionally, modify the data set(s). Use the pencil icon to modify data set and column names. Use the check boxes next to the column names to remove columns from the\n                data set. Use the Schema dropdown to change the schema or add a new schema. If you have selected multiple data sets, use the connector icon next to the\n                schema dropdown to apply the schema to all of the selected data sets. Click Cache Overview and compare the original data sets (Input Assets) to the\n            modified data sets (Output Assets) to verify the changes. If the changes to a data set are incorrect, click the pencil icon to edit the\n            data set. To cache the data set(s), click Save to cache . The system displays the\n            following message: Successfully initiating cache If an error\n            appears, correct the issue and continue. To view the cached data sets, go to Data Engineering > Cached Assets in the\n            left navigation bar of the HPE Ezmeral Unified Analytics Software UI. NOTE Depending on the size of the data sets, it may take a\n              minute or so for them to appear as cached assets. Enable or Disable a Cache You can enable or\n        disable caching through the Enable Local Snapshot Table option when you create a data\n        source connection. See Connect Data Sources . You cannot disable caching\n      by setting the TTL to zero. If the TTL is set to zero, the cache expires immediately but still\n      consumes resources. On this page How to Cache Data Enable or Disable a Cache Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/cache-data.html",
        "title": "Cache Data"
    },
    {
        "content": "\nSubmitting Presto Queries from Notebook Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Connect Data Sources Provides instructions for connecting HPE Ezmeral Unified Analytics Software to external data sources. Connect to CSV and Parquet Data in an External S3 Data Source via Hive Connector Describes how to use the Hive connector with Presto in HPE Ezmeral Unified Analytics Software to connect to CSV and     Parquet data in S3-based external data sources. EzPresto/connect-external-s3-data-source.html Connect to External Applications via JDBC Describes how to connect external applications and BI tools, such as Tableau and     PowerBI, to EzPresto through the EzPresto JDBC endpoint. Using Spark to Query EzPresto Describes how to use Spark to query EzPresto . Connect to EzPresto via Python Client Provides information for connecting to EzPresto from a Python client. Cache Data Describes data caching and provides the steps for caching data in HPE Ezmeral Unified Analytics Software . Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Submitting Presto Queries from Notebook Describes how to submit Presto queries from the notebook. In HPE Ezmeral Unified Analytics Software , you can connect to SQL databases and submit\n      queries through EzPresto using the %sql or %%sql magic. . Depending on the public or private access to databases, you can use one of the\n      following ways to submit Presto queries from the notebook: Private Access to SQL Databases Public Access to SQL Databases To learn about the public and private access to databases, see Managing Data Access . Private Access to SQL Databases If you have private access to SQL databases, you need to establish an authenticated\n        connection to EzPresto and then submit queries. For example: from sqlalchemy import create_engine\nfrom sqlalchemy import text\nfrom sqlalchemy import event\n \n%update_token\n \nauth_token=os.environ[\"AUTH_TOKEN\"]\nsession = requests.Session()\nsession.headers[\"Authorization\"] = \"Bearer \" + f\"{auth_token}\"\n \nengine = create_engine(\n        \"presto://ezpresto-sts-mst-0.ezpresto-svc-hdl.ezpresto.svc.cluster.local:8081\",\n        connect_args={\"protocol\": \"https\",\"requests_kwargs\": {\"verify\": False}, \"requests_session\": session},\n    )\n \nQUERY = \"SELECT * FROM mysql.tpch_partitioned_orc_2.nation\"\n \nwith engine.connect() as connection:\n    with connection.begin():\n        # run statements in a \"begin once\" block\n        result = connection.execute(text(QUERY))\n        for row in result:\n            print(row)\n        # connection.execute(text(\"CREATE TABLE some_table (x int, y int)\"))\n        # connection.execute(\n        #     text(\"INSERT INTO some_table (x, y) VALUES (:x, :y)\"),\n        #     [{\"x\": 1, \"y\": 1}, {\"x\": 2, \"y\": 4}],\n        # )\n        # connection.commit() Public Access to SQL Databases If you have public access to SQL databases, you can use the %sql or %%sql magic to submit Presto queries from the notebook. For details, %sql and %%sql . On this page Private Access to SQL Databases Public Access to SQL Databases Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/EzPresto/submit-presto-queries-from-notebook.html",
        "title": "Submitting Presto Queries from Notebook"
    },
    {
        "content": "\nAirflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in     Airflow. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to DAGs. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . You can use Airflow to author, schedule, or monitor workflows and data pipelines. A workflow is a Directed Acyclic Graph (DAG) of tasks used to handle big data processing\n      pipelines. The workflows are started on a schedule or triggered by an event. DAGs define the\n      order to run tasks or rerun tasks in case of failures. The tasks define the actions to be\n      performed, such as ingest, monitor, report, and others. To learn more, see Airflow documentation . Airflow Functionality Airflow in HPE Ezmeral Unified Analytics Software supports the following functionality: Extracting data from multiple data sources and running Spark jobs or other data\n            transformations.\u200b Training machine learning models.\u200b Automated generation of reports.\u200b Backups and other DevOps tasks.\u200b Airflow Architecture In HPE Ezmeral Unified Analytics Software , Airflow\n        consists of the following parts: Airflow Operator Manages and maintains Airflow Base and Airflow Cluster Kubernetes Custom Resources\n                by creating and updating Kubernetes objects. Airflow Base Manages the PostgreSQL database that stores Airflow metadata. Airflow Cluster Deploys the UI and scheduler components of Airflow. In HPE Ezmeral Unified Analytics Software , there is\n        only one instance of Airflow per cluster and Airflow DAGs are accessed by all authenticated\n        users. Airflow Components Airflow consists of the following components: Scheduler Triggers the scheduled workflows and submits the tasks to an executor to run. Executor Executes the tasks or delegates the tasks to workers for execution. Worker Executes the tasks. Web Server Provides a user interface to analyze, schedule, monitor, and visualize the tasks and\n              DAG. The Web Server enables you to manage users, roles, and set configuration\n              options. DAG Directory Contains DAG files read by Scheduler, Executor, and Web Server. Metadata Database Stores the metadata about DAGs\u2019 state, runs, and Airflow configuration options. Airflow Limitations Airflow in HPE Ezmeral Unified Analytics Software has the following limitations: The CPU and memory resource limits for executors cannot be modified (CPU: 1, memory:\n            2Gi). To use the Spark Operator, you must provide the username by specifying it under the\n            \"username\" key in the DAG Run Configuration. The logs of successfully run DAGs are available until the corresponding pods are\n            deleted. To learn more about Airflow, see Airflow Concepts . Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in     Airflow. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to DAGs. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. More information Financial Time Series Workflow MNIST Digits Recognition Workflow On this page Airflow Functionality Airflow Architecture Airflow Components Airflow Limitations Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Airflow/airflow.html",
        "title": "Airflow"
    },
    {
        "content": "\nAirflow DAGs Git Repository Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in     Airflow. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to DAGs. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in\n    Airflow. Airflow DAGs are pulled from the GitHub repository that you specify when you configure\n      Airflow. HPE Ezmeral Unified Analytics Software supports both private and public GitHub repositories. HPE Ezmeral Unified Analytics Software can only read DAGs from a GitHub repository on a\n      specified branch from a specified subdirectory. If the GitHub repository is located behind a\n      proxy, you can configure a proxy for the GitHub repository in Airflow. In an air-gapped environment where there is no pre-configured proxy to forward outgoing\n      cluster connections to the internet, the installation of Airflow will not function properly.\n      To resolve this issue, the administrator of the HPE Ezmeral Unified Analytics Software must either manually set up an HTTP proxy or configure\n      Airflow with an internal Git repository. IMPORTANT Best practice is to use Git\n        submodules if multiple users have DAGs in their own repositories. To manage multiple users\n        within the same GitHub repository, the HPE Ezmeral Unified Analytics Software platform administrator can create a root GitHub repository and\n        then add all user GitHub repositories as submodules. As owner of the root GitHub repository,\n        the platform administrator can update the Git submodules after users add/remove/modify\n        files. For example, when a user modifies files, the user can ask the platform administrator\n        to update the latest commit hash of the user's Git submodule in the root repository. For\n        additional information, refer to GitHub - About code owners and Working with submodules . Configuring a Git Repository for Airflow To configure Airflow with the GitHub repository where DAGs are stored: Sign in to HPE Ezmeral Unified Analytics Software as Administrator. In the left navigation bar, click Applications &\n            Frameworks . Select the Data Engineering tab. On the Airflow tile, click the three-dots menu and then\n            select Configure . The YAML file editor opens. In the editor, find the git: section. Configure the following parameters in the git: section: repo: The repository URL for private or public Git repository which stores the DAGs.\n                    If you are using an air-gapped system without a proxy, specify your internal Git\n                    repository here. branch: The name of the branch within the repository to use. subDir: The path to the directory where the DAGs are located. If you are using an air-gapped system, and Git cannot be accessed without a\n              proxy, configure the following fields: http The address of HTTP proxy. https The address of HTTPS proxy. If the git repository is private, configure the following fields: username The username of the user who has access to the private git repository. password The token or password of the user who has access to the private git\n                      repository. Alternatively, if you have created a secret in the airflow-hpe namespace under key:\n                        'password' that contains the password or token information, you can\n                      specify the name of that secret in the secretName field under\n                      the cred section instead of using the password field directly. Click Configure and wait until Airflow is configured. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Airflow/airflow-dags-git-repos.html",
        "title": "Airflow DAGs Git Repository"
    },
    {
        "content": "\nConfiguring Airflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in     Airflow. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to DAGs. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Modifying the Maximum Number of Simultaneous Jobs To modify the maximum number of tasks from DAGs that can be run simultaneously, perform: Sign in to HPE Ezmeral Unified Analytics Software . Click the Applications & Frameworks icon on the left\n            navigation bar. Navigate to the Airflow tile under the Data Engineering tab and click Open . Click Admin and select Pools . Click Edit Record and update the value of Slots . Click Save . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Airflow/configure-airflow.html",
        "title": "Configuring Airflow"
    },
    {
        "content": "\nSubmitting Spark Applications by Using DAGs Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in     Airflow. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to DAGs. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Prerequisites Prepare the DAG for your Spark application. Add your DAG to the Git repository. NOTE If you do not have the repository to store\n            Airflow DAGs, request an administrator to configure the Git repository now. For details,\n            see Airflow DAGs Git Repository . After your DAG is available in the Git repository, sign in to HPE Ezmeral Unified Analytics Software as a member. About this task To run the DAG to submit the Spark applications in Airflow, follow these steps: Navigate to the Airflow screen using either of the following methods: Click Data Engineering > Airflow Pipelines . Click Applications & Frameworks , select the Data Engineering tab, and click Open in the Airflow tile. In Airflow , verify that you are on the DAGs screen. Click <your-spark-application> DAG. For example: Click Code to view the DAG code. Click Graph to view the graphical representation of the DAG. Click Run (play button) and select Trigger DAG w/ config to specify the\n            custom configuration. To run a DAG after making configuration changes, click Trigger. To view details for the DAG, click Details . Under DAG Details , you can see green, red, and/or yellow buttons with\n            the number of times the DAG ran successfully or failed. Click the Success button. To find your job, sort by End Date to see the latest jobs that have run, and\n            then scroll to the right and click the log icon under Log URL for that run. Note that\n            jobs run with the\n              configuration: Conf \"username\":\"your_username\" When running Spark applications using Airflow,\n              you can see the logs. IMPORTANT The cluster clears the logs that result\n                from the DAG runs. The duration after which the cluster clears the logs depends on\n                the Airflow task, cluster configuration, and policy. Results Once you have triggered the DAG, you can view the Spark application in the Spark\n          Applications screen. To view the Spark application, go to Analytics > Spark\n        Applications . Alternatively, you can go to Applications & Frameworks and then\n        click on the Analytics tab. On the Analytics tab, select the Spark tile and click Open . Example Financial Time Series Workflow MNIST Digits Recognition Workflow Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Airflow/submitting-spark-apps-using-airflow-dags.html",
        "title": "Submitting Spark Applications by Using DAGs"
    },
    {
        "content": "\nDefining RBACs on DAGs Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in     Airflow. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to DAGs. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs\n    to permit access to DAGs. Role-based access controls (RBACs) are an authorization system based on policies, user roles,\n      and bindings between the roles and policies that protect resources. With the introduction of\n      RBACs, HPE Ezmeral Unified Analytics Software users\n      (admins and members) can grant users access to their DAGs through access controls that they\n      define in the DAG constructors. Admin Role The following list describes DAG access for admins and the admin-related tasks that\n            impact user access to DAGs: HPE Ezmeral Unified Analytics Software admins have full access to all Airflow DAGs regardless of the access controls set. Admins can assign a member the admin role in HPE Ezmeral Unified Analytics Software to give the\n                user full access to DAGs; however, this action must occur before the user signs in\n                to the HPE Ezmeral Unified Analytics Software UI and accesses Airflow. See User Roles . If an admin removes a user from HPE Ezmeral Unified Analytics Software , that user's access to Airflow is automatically\n                revoked. Other users can no longer access the DAGs that the removed user\n                  shared. CAUTION HPE only supports user role changes made through the HPE Ezmeral Unified Analytics Software UI. Role changes made in HPE Ezmeral Unified Analytics Software are automatically propagated to Airflow. HPE does not\n                  support role changes made directly in Airflow because the changes do not propagate\n                  back to HPE Ezmeral Unified Analytics Software , which can cause unexpected system behaviors. TIP Best practice is to use Git submodules if multiple users have DAGs in\n                  their own repositories. To manage multiple users within the same GitHub\n                  repository, the HPE Ezmeral Unified Analytics Software platform administrator can create a root GitHub repository\n                  and then add all user GitHub repositories as submodules. As owner of the root\n                  GitHub repository, the platform administrator can update the Git submodules after\n                  users add, remove, or modify files. For example, when a user modifies files, the\n                  user can ask the platform administrator to update the latest commit hash of the\n                  user's Git submodule in the root repository. For additional information, refer to GitHub - About code owners and Working with submodules . Member Role The following list describes DAG access for members: Members can access DAGs: When DAGs do not have any access controls defined. When permitted to do so through access controls (either defined on their\n                    username or defined through the All user role). Members can define access controls on the DAGs they create. Supported Access Controls The following table lists and describes the access controls that admins and users can\n        define in the DAG constructor, as well as the associated access control values to use when\n        configuring the access controls on a user in the DAG constructor. Access Control Type Access Control Value Description Read can_read The specified user can see the source code but cannot launch the DAG. Edit can_edit The specified user can launch the DAG and add some notes. Delete can_delete The specified user can delete the DAG; however, DAGs repopulate in the GitHub\n                  repository every few seconds. Define the access controls on a username through the access_control parameter in the DAG constructor, as shown in the following example for user01 : access_control={\n\t\t'role_user01': {\n\t\t\t'can_read',\n\t\t\t'can_edit',\n\t\t\t'can_delete'\n\t\t}\n\t} If you want to grant all users access to a DAG, define access\n        controls on All instead of a specific username, as shown in the following\n        example: access_control={\n\t\t'All': {\n\t\t\t'can_read',\n\t\t\t'can_edit',\n\t\t\t'can_delete'\n\t\t}\n\t} Defining RBACs on Users You can define access controls on a user (username) that exists or does not yet exist in HPE Ezmeral Unified Analytics Software . Adding a\n        user to HPE Ezmeral Unified Analytics Software after\n        you define roles on the user (username) in the DAG constructor will not cause any issues\n        between the systems. An HPE Ezmeral Unified Analytics Software admin can add or create the user. See Adding and Removing Users . IMPORTANT The DAG must exist in the GitHub repository or a Git submodule that\n          the Airflow instance in HPE Ezmeral Unified Analytics Software points to. To define access controls on a user in the DAG constructor: Go to the GitHub repository and add the following access_control parameters and values to the DAG constructor, as shown in the following\n              example: }\nwith DAG{\n\tdag_id='example_kubernetes_operator',\n\tdafault_args=default_args,\n\tschedule_interval=None,\n\ttags=['example'], access_control={\n\t\t'role_<username>': {\n\t\t\t'can_read',\n\t\t\t'can_edit',\n\t\t\t'can_delete'\n\t\t}\n\t} } as dag: TIP If you commit a DAG without the access_control annotation, all\n                  users (admins and members) can view and access the DAG. Only include the access role(s) that you want the user to have. For example, if\n                  you do not want the user to launch the DAG, do not assign the user the can_edit access control. Commit and push the changes to the DAG. Viewing Access Controls on Users HPE Ezmeral Unified Analytics Software admins can go\n        to the Security page in Airflow to view access controls on users. Members cannot\n        access the Security page. To view access controls on users: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, select Tools and Frameworks . On the Data Engineering tab, click Open in the Airflow tile. In Airflow , click the Security tab and select List\n            Roles . On this page Supported Access Controls Defining RBACs on Users Viewing Access Controls on Users Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Airflow/rbac-airflow.html",
        "title": "Defining RBACs on DAGs"
    },
    {
        "content": "\nUsing whylogs with Airflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Airflow DAGs Git Repository Describes how HPE Ezmeral Unified Analytics Software reads DAGs and how to configure a GitHub repository in     Airflow. Configuring Airflow Describes how to configure Airflow in HPE Ezmeral Unified Analytics Software . Submitting Spark Applications by Using DAGs Describes how to submit the Spark applications by using DAGs in Airflow. Defining RBACs on DAGs Describes role-based access controls (RBACs) with respect to Airflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to DAGs. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using whylogs with Airflow Describes how to use whylogs with Airflow DAGs. Prerequisites Sign in to HPE Ezmeral Unified Analytics Software as a\n            member. About this task In HPE Ezmeral Unified Analytics Software , whylogs is integrated to work with\n                Airflow DAGs. You can use whylogs with Airflow to profile and monitor the data and\n                detect drifts as data flows through the data pipelines. To use whylogs with Airflow DAGs, refer to Airflow DAG example in GitHub.\n                The basic steps are outlined as follows: Import the required libraries and modules from whylogs in your Airflow DAG\n                        script. You can use notebooks to create your Airflow DAG. To learn about\n                        notebooks, see Creating and Managing Notebook Servers . Define your Airflow DAG that can profile and monitor the data to detect\n                        drifts. Add your DAG to the Git repository. NOTE If you do not have the repository\n                            to store Airflow DAGs, request an administrator to configure the Git\n                            repository now. For details, see Airflow DAGs Git Repository . Navigate to the Airflow screen using either of the\n                        following methods: Click Data Engineering > Airflow\n                                Pipelines . Click Tools & Frameworks , select the Data Engineering tab, and click Open in the Airflow tile. In Airflow , verify that you are on the DAGs screen and your defined DAG is available in\n                        the DAGs screen. To run your DAG, click the play button. Once your DAG run completes, navigate back to the HPE Ezmeral Unified Analytics Software home screen. In the left navigation bar, go to Data Engineering > Data\n                            Sources . Click Browse . Go to the /shared/<airflow-whylogs> folder which is a\n                        path set in your DAG to store the logs from whylogs. You can see that the\n                        data pro\ufb01les and the drift summary report are stored in the shared volume in\n                        the .html and .bin formats. To download a summary report, select Download from\n                        the Actions menu. Results You can analyze the summary report to detect drifts and monitor your data. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Airflow/airflow-whylogs-integration.html",
        "title": "Using whylogs with Airflow"
    },
    {
        "content": "\nSuperset Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Defining RBACs in Superset Describes role-based access controls (RBACs) with respect to Superset in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to Superset dashboards. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Superset is a cloud-native business intelligence web application that collects and processes\n      large volumes of data that can be used in the data visualizations and dashboards that you\n      create within it. Superset is accessible in HPE Ezmeral Unified Analytics Software by going to BI Reporting > Dashboards or Applications & Frameworks > Data Engineering in the left\n      navigation panel. When you connect HPE Ezmeral Unified Analytics Software to various data sources, you can access the data in those data sources\n      from Superset. For example, you can create any type of chart in Superset and specify query\n      conditions on a selected data set to visualize the query results in the chart. Superset works\n      with EzPresto , the HPE Ezmeral Unified Analytics Software accelerated SQL query engine, to process the query and display results\n      in the chart. You can then add the chart to a dashboard and continue this process to build out\n      a dashboard that visualizes your analytical workloads. Underlying Superset and EzPresto is a Presto\n      database that unifies the data sources connected to HPE Ezmeral Unified Analytics Software . The unified data source connection enables you to: Add the data sets you create in the HPE Ezmeral Unified Analytics Software Data Engineering space to Superset. Connect Superset directly to the Presto database for direct access to the unified data\n          sources. You can also connect Superset to external databases (those that are not part of the unified\n      data source connection in HPE Ezmeral Unified Analytics Software ). Refer to the following tutorials to get started with Superset in HPE Ezmeral Unified Analytics Software : BI Reporting (Superset) Basics Retail Store Analysis Dashboard (Superset) For additional information about Superset, see Apache\n        Superset and EzPresto . Defining RBACs in Superset Describes role-based access controls (RBACs) with respect to Superset in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to Superset dashboards. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Superset/superset.html",
        "title": "Superset"
    },
    {
        "content": "\nDefining RBACs in Superset Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Accessing Data in External S3 Object Stores Describes how to access data in external object stores from clients, such as Spark and     Kubeflow notebooks. EzPresto Describes the EzPresto SQL query engine     and its featues. Airflow Provides an overview of Apache Airflow in HPE Ezmeral Unified Analytics Software . Superset Provides a brief overview of  Superset in HPE Ezmeral Unified Analytics Software . Defining RBACs in Superset Describes role-based access controls (RBACs) with respect to Superset in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to Superset dashboards. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Defining RBACs in Superset Describes role-based access controls (RBACs) with respect to Superset in HPE Ezmeral Unified Analytics Software and how to define RBACs\n    to permit access to Superset dashboards. Role-based access controls (RBACs) are an authorization system based on policies, user roles,\n      and bindings between the roles and policies that protect resources. With the introduction of\n      RBAC, HPE Ezmeral Unified Analytics Software maps the HPE Ezmeral Unified Analytics Software admin and\n      member roles to Superset Admin and AlphaDbAccess roles respectively. The following user role mapping is defined in the Superset HELM chart (YAML file): User Type Mapping Parameter Admin AUH_ROLE_ADMIN = 'Admin' Member AUTH_USER_REGISTRATION_ROLE = \"AlphaDbAccess\" TIP You cannot edit the role mappings in the HELM chart. Admin Role (Admin) The following list describes admin access and the admin-related tasks that impact\n            users in Superset: Admins can edit (add or remove) roles in the Superset UI. Admins can change a member's role in HPE Ezmeral Unified Analytics Software to admin . Admins can view all user activity and data, including all dashboards created by\n                all users, as well as all of the data in the dashboards. Admins can access the security settings in Superset, such as viewing user\n                profiles, including user roles and access controls. Admins can edit a user in Superset and change the user's roles. Member Role (AlphaDbAccess) The following list describes Superset access for members (AlphaDbAccess): Members can create their own database connections in Superset. Members can view charts and datasets created by other users, but cannot view\n                dashboards unless explicitly permitted to do so. Members can access dashboards they create and dashboards that other users have\n                shared with them. NOTE Access to a dashboard does not grant access to data. The user\n                  must have permission on the data itself to view the data in a dashboard. If the\n                  user does not have access to certain data, that data does not display in their\n                  view of the dashboard. Members cannot see the Superset security settings, such as user roles and access\n                permissions. CAUTION HPE only supports user role changes made through the HPE Ezmeral Unified Analytics Software UI. Role\n                changes made in HPE Ezmeral Unified Analytics Software are automatically propagated to Superset. HPE does not support\n                role changes made directly in Superset because the changes do not propagate back to HPE Ezmeral Unified Analytics Software ,\n                which can cause unexpected system behaviors. Supported Access Controls HPE Ezmeral Unified Analytics Software supports the\n        following access controls in Superset: Admin Public AlphaDbAccess Gamma granter sql_lab Sharing Dashboards To share a dashboard: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, go to Tools & Frameworks . On the Data Engineering tab, click Open in the Superset tile. Click the Dashboards tab. In the Actions column of the dashboard you want to share, select Edit (pencil icon). Under Access , click into the field and select the roles you want to assign the\n            user. Alternatively, you can also remove roles from the user. Viewing Role Descriptions To see the access a role permits: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, go to Tools & Frameworks . On the Data Engineering tab, click Open in the Superset tile. Go to Settings and select List Roles . Click Show record (magnifying glass icon) next to a role to view the role\n            description. Viewing and Editing Access Controls on Users To view the access controls on a user or edit access controls on a user: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation bar, go to Tools & Frameworks . On the Data Engineering tab, click Open in the Superset tile. Go to Settings and select List Users . (Optional) To edit the user's role(s), click the edit icon next to the username and\n            then add or remove roles using the dropdown menu in the Role field. On this page Supported Access Controls Sharing Dashboards Viewing Role Descriptions Viewing and Editing Access Controls on Users Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Superset/rbac-superset.html",
        "title": "Defining RBACs in Superset"
    },
    {
        "content": "\nData Analytics Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . HPE Ezmeral Unified Analytics Software provides a\n      single place where data engineers and data scientists can run analytical workloads through the\n      Apache Spark Operator, interactive sessions in Apache Livy, and schedule jobs using Apache\n      Airflow. ACID (Atomicity, Consistency, Isolation and Durability) transactions for Spark applications\n      are supported out of box with Delta Lake. Delta Lake has a well-defined open protocol called Delta Transaction Protocol that provides ACID transactions to Apache\n      Spark applications. You can use any Apache Spark APIs to read and write data with Delta Lake.\n      Delta Lake stores the data in Parquet format as versioned Parquet files. HPE Ezmeral Unified Analytics Software simplifies data\n      access and data workflows and pipelines. HPE Ezmeral Unified Analytics Software connects to multiple types of internal and external data sources\n      that you can easily explore with federated SQL queries that you\n      visualize in Superset (dashboards). You can also use Spark to transform raw data sets into\n      consumable formats like data lakehouses. Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . More information Get Started Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/DataAnalytics/data-analytics.html",
        "title": "Data Analytics"
    },
    {
        "content": "\nSpark Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Spark is a unified analytics engine with high data processing speed that offers high-level\n        APIs in Java, Scala, Python, and R. Spark provides the in-memory computing and optimized\n        query execution for fast data processing. In HPE Ezmeral Unified Analytics Software , there are\n        two controllers for running Spark workloads. These controllers are Spark Operator and Livy\n        server. HPE Ezmeral Unified Analytics Software supports\n        multi-version Spark Operator. You can submit Spark Applications for different versions of\n        Apache Spark using a single Spark Operator. You can choose to use one of the supported Spark images to submit your Spark\n        application using the Spark Operator workflow. See Using Spark Images . To see the list of the Spark images distributed by HPE Ezmeral Unified Analytics Software , see List of Spark Images . Livy server uses the Rest API and Spark images (supporting Data Fabric services) provided\n        by HPE Ezmeral Unified Analytics Software to submit\n        the Spark applications. To learn about the supported version of Spark, see Support Matrix . NOTE Livy does not support Spark OSS images or\n            your own open-source Spark images on HPE Ezmeral Unified Analytics Software . Features and Functionality HPE Ezmeral Unified Analytics Software provides an\n          enterprise-ready, unified Spark experience that supports an Apache Livy-based interactive\n          sessions.. Spark in HPE Ezmeral Unified Analytics Software supports the following features and functionality: ACID transactions for Spark applications with Delta Lake. Details for both Spark applications and Livy sessions are stored in Spark History\n              Server. See Spark History Server . Run Spark jobs from HPE Ezmeral Unified Analytics Software using the following components: Spark Operator: The following are entry points for the Spark Operator: Airflow Spark Operator GUI in HPE Ezmeral Unified Analytics Software . See Creating Spark Applications . Livy Server: The following are entry points for the Livy server: Kubeflow Notebook: You can use Spark Magics to run Livy sessions using\n                      Kubeflow notebooks. See Notebook Magic Functions . Interactive Spark Sessions GUI available in HPE Ezmeral Unified Analytics Software . See Creating Interactive Sessions . Livy REST API (with basic authentication). Livy native UI (with platform\n                        SSO authentication): You can use the Livy native UI to troubleshoot\n                      such as checking the state of the session or state of statements. You cannot\n                      submit Spark applications using the Livy native UI. Spark applications and Livy sessions are preconfigured in such a way that both user and shared volumes are mounted to driver and\n              executor runtimes and you can use these folders to pass files into Spark runtime when\n              using the HPE Ezmeral Unified Analytics Software GUI. However, user and shared volumes are not mounted to driver and executor runtimes when using the Livy\n              REST API to create Livy sessions. Dynamically set user context to prevent impersonation calls for better\n              security. Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. More information Submitting a Spark Wordcount Application Financial Time Series Workflow MNIST Digits Recognition Workflow Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/spark_overview.html",
        "title": "Spark"
    },
    {
        "content": "\nUsing Spark Images Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . Using HPE-Curated Spark Images Describes how to use HPE-curated Spark images to submit     Spark applications. Using Spark OSS Images Describes how to use Spark Open-Source Software (OSS) images to submit Spark     applications. Using Your Own Open-Source Spark Images Describes how to use your own open-source Spark images to submit Spark     applications. Setting the User Context Describes how to set the user context when using the     Spark OSS     images. List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . HPE Ezmeral Unified Analytics Software packages two different types of images: HPE-curated Spark images. For details, see Using HPE-Curated Spark Images . Spark Open-Source Software (OSS) images ( Spark OSS images). For details, see Using Spark OSS Images . The following table compares the two different types of Spark images packaged with HPE Ezmeral Unified Analytics Software . Capabilities HPE-Curated Spark Images Spark OSS Images Packaged by HPE Yes Yes Data Fabric (Filesystem, Database, Streams) Yes No Data Fabric Security (data-fabric SASL ( maprsasl )) Yes No Workloads from Spark Operator Yes Yes Workloads from Livy Yes No However, you can also bring your own open-source Spark images compatible with the Kubernetes\n      version supported on HPE Ezmeral Unified Analytics Software . See Using Your Own Open-Source Spark Images . Using HPE-Curated Spark Images Describes how to use HPE-curated Spark images to submit     Spark applications. Using Spark OSS Images Describes how to use Spark Open-Source Software (OSS) images to submit Spark     applications. Using Your Own Open-Source Spark Images Describes how to use your own open-source Spark images to submit Spark     applications. Setting the User Context Describes how to set the user context when using the     Spark OSS     images. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/spark-images.html",
        "title": "Using Spark Images"
    },
    {
        "content": "\nUsing HPE-Curated Spark Images Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . Using HPE-Curated Spark Images Describes how to use HPE-curated Spark images to submit     Spark applications. Using Spark OSS Images Describes how to use Spark Open-Source Software (OSS) images to submit Spark     applications. Using Your Own Open-Source Spark Images Describes how to use your own open-source Spark images to submit Spark     applications. Setting the User Context Describes how to set the user context when using the     Spark OSS     images. List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using HPE-Curated Spark Images Describes how to use HPE-curated Spark images to submit\n    Spark applications. HPE-Curated Spark images are Apache Spark images that are\n      customized to support Data Fabric filesystem, Data Fabric Streams, and any other Data Fabric\n      sources and sinks that require a Data Fabric client. These Spark images also support Data\n      Fabric-specific security features (data-fabric SASL ( maprsasl )). HPE-curated Spark images are the images used by GUI for\n      default experience. See List of Spark Images . You can use HPE-curated Spark images with four different\n      workflows as follows: Spark Operator workflow using the Create Spark Application GUI.\n          See Using the Create Spark Application GUI . Spark Operator workflow using Airflow. See Using Airflow . Livy workflow using the Spark Interactive Sessions GUI. See Using the Spark Interactive Sessions GUI . Livy workflow using Jupyter Notebooks. See Using Notebooks . Using the Create Spark Application GUI To use HPE-curated Spark images, choose one of the following\n        option in the GUI: Using New application If you choose the New application option in the Application Details step of the Create Spark\n                  Application wizard, your Spark application will be configured with HPE-curated Spark image. The List of Spark Images page also lists the default HPE-curated Spark images used for GUI experience. Using Upload YAML If you choose the Upload YAML option, your Spark application\n                will be configured with your chosen Spark image on your YAML\n                file. image: <base-repository>/<image-name>:<image-tag> To learn about how to submit Spark applications by using GUI,  see Creating Spark Applications . Using the Spark Interactive Sessions GUI To use HPE-curated Spark images when using the Spark\n        Interactive Sessions, follow these steps: Perform the creating interactive sessions instructions until you reach the Spark Configurations box in the Session\n              Configurations and Dependencies step. See Creating Interactive Sessions . In the Spark Configurations box, you have two options: If you leave the Key and Value boxes empty, the Spark interactive sessions will be\n                created with the HPE-curated Spark image. The List of Spark Images page also lists the default HPE-curated Spark images used for GUI experience. If you set the Key and Value boxes for the Spark image of your choice by adding\n                the following key-value pairs, your Spark interactive session will be created with\n                the Spark image of your choice. Key: spark.kubernetes.container.image\nValue: <spark-image-of-your-choice> To specify the details for other boxes or options in the Session\n                Configurations and Dependencies step and to complete creating\n              interactive sessions, see Creating Interactive Sessions . Using Notebooks To use HPE-curated Spark images when using Spark magic\n          ( %manage_spark ) to create Livy sessions, follow these steps: Run %manage_spark to connect to the Livy server and start a new\n            session. See %manage_spark for details. Once you run %manage_spark , you have two options: Creating sessions with the default Spark configurations. This will use the HPE-curated Spark image to create an interactive\n                session. The List of Spark Images page also lists the default HPE-curated Spark images used for GUI experience. Running %config_spark and updating the value of spark.kubernetes.container.image to the Spark image of your\n                choice. This will use the Spark image of your choice to create an interactive\n                session. To specify the details for the other boxes or options in the Create\n              Session step and to complete creating Livy session, see %manage_spark . Using Airflow When you submit the Spark application by using Airflow, your Spark application will be\n        configured with your chosen Spark image on your YAML file. This YAML file is set in the\n        Airflow DAG. For example: submit = SparkKubernetesOperator(\n    task_id='submit',\n    namespace=\"example\", application_file=\"example.yaml\", dag=dag,\n    api_group=\"sparkoperator.hpe.com\",\n    enable_impersonation_from_ldap_user=True\n) To learn about how to submit Spark applications by using Airflow DAG, see Submitting Spark Applications by Using DAGs . On this page Using the Create Spark Application GUI Using the Spark Interactive Sessions GUI Using Notebooks Using Airflow Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/using-default-spark-images.html",
        "title": "Using HPE-Curated Spark Images"
    },
    {
        "content": "\nUsing Spark OSS Images Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . Using HPE-Curated Spark Images Describes how to use HPE-curated Spark images to submit     Spark applications. Using Spark OSS Images Describes how to use Spark Open-Source Software (OSS) images to submit Spark     applications. Using Your Own Open-Source Spark Images Describes how to use your own open-source Spark images to submit Spark     applications. Setting the User Context Describes how to set the user context when using the     Spark OSS     images. List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using Spark OSS Images Describes how to use Spark Open-Source Software (OSS) images to submit Spark\n    applications. Spark OSS are Apache Spark images that do not\n      support Data Fabric filesystem, Data Fabric Streams, and any other Data Fabric sources and\n      sinks that require a Data Fabric client. These Spark images also do not support Data\n      Fabric-specific security features (data-fabric SASL ( maprsasl )). You can use Spark OSS images with two different\n      workflows as follows: Spark Operator workflow using the Create Spark Application GUI.\n          See Using the Create Spark Application GUI . Spark Operator workflow using Airflow. See Using Airflow . Using the Create Spark Application GUI To use Spark OSS images, choose one of the\n        following option in the GUI: Using Upload YAML in GUI Select the Spark OSS image from the List of Spark Images . Configure your Spark YAML file with the Spark OSS image. image: gcr.io/mapr-252711/apache-spark:<image-tag> To set the logged-in user\u2019s context, add the following configuration in the sparkConf section. spark.hpe.webhook.security.context.autoconfigure: \"true\" To\n                    learn more about user context, see Setting the User Context . Perform the instructions to create a Spark application as described in Creating Spark Applications until you reach the Application\n                      Details step. In the Application Details step, choose the Upload YAML option. Click Select File and, browse and upload the YAML\n                    file. To specify the details for other boxes or options in the Application Details step and to complete creating the\n                    Spark application, see Creating Spark Applications . Using New application in GUI Perform the instructions to create a Spark application as described in Creating Spark Applications until you reach the Review step. To open an editor to change the application configuration using YAML in the\n                    GUI, click Edit YAML . Select the Spark OSS image from the List of Spark Images . Replace the default Spark image in YAML with the Spark OSS image. image: gcr.io/mapr-252711/apache-spark:<image-tag> To set the logged-in user\u2019s context, add the following configuration in the sparkConf section. spark.hpe.webhook.security.context.autoconfigure: \"true\" To\n                    learn more about user context, see Setting the User Context . To submit the application with the Spark OSS image, click Create\n                      Spark Application on the bottom right of the Review step. To learn about how to submit Spark applications by using GUI,  see Creating Spark Applications . Using Airflow When you submit the Spark application by using Airflow, your Spark application will be\n        configured with your chosen Spark image on your YAML file. This YAML file is set in the\n        Airflow DAG. For example: submit = SparkKubernetesOperator(\n    task_id='submit',\n    namespace=\"example\", application_file=\"example.yaml\", dag=dag,\n    api_group=\"sparkoperator.hpe.com\",\n    enable_impersonation_from_ldap_user=True\n) To learn about how to submit Spark applications by using Airflow DAG, see Submitting Spark Applications by Using DAGs . On this page Using the Create Spark Application GUI Using Airflow Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/using-spark-oss-images.html",
        "title": "Using Spark OSS Images"
    },
    {
        "content": "\nUsing Your Own Open-Source Spark Images Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . Using HPE-Curated Spark Images Describes how to use HPE-curated Spark images to submit     Spark applications. Using Spark OSS Images Describes how to use Spark Open-Source Software (OSS) images to submit Spark     applications. Using Your Own Open-Source Spark Images Describes how to use your own open-source Spark images to submit Spark     applications. Setting the User Context Describes how to set the user context when using the     Spark OSS     images. List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using Your Own Open-Source Spark Images Describes how to use your own open-source Spark images to submit Spark\n    applications. Your own open-source Spark images compatible with the Kubernetes version supported on HPE Ezmeral Unified Analytics Software . With the\n      support of bringing your own open-source Spark, you can build Spark with any profile of your\n      choice; however, there will be no support for Data Fabric filesystem, Data Fabric Streams, and\n      any other Data Fabric sources and sinks that require a Data Fabric client. These Spark images\n      will not support Data Fabric-specific security features (data-fabric SASL\n        ( maprsasl )). To use your own open-source Spark images, follow the next steps: Build Spark. See Building Spark . Build Spark images to run in HPE Ezmeral Unified Analytics Software . See Building Images . Choose one of the following: Using the Create Spark Application GUI Using Airflow Using the Create Spark Application GUI To use your own open-source Spark images, choose one of the following option in the GUI: Using Upload YAML Configure your Spark YAML file with the built Spark image of your\n                    choice. image: <base-repository>/<image-name>:<image-tag> To set the logged-in user\u2019s context, add the following configuration in the sparkConf section. spark.hpe.webhook.security.context.autoconfigure: \"true\" To\n                    learn more about user context, see Setting the User Context . Perform the instructions to create a Spark application as described in Creating Spark Applications until you reach the Application\n                      Details step. In the Application Details step, choose the Upload YAML option. Click Select File and, browse and upload the YAML\n                    file. To specify the details for other boxes or options in the Application Details step and to complete creating the\n                    Spark application, see Creating Spark Applications . Using New application Perform the instructions to create a Spark application as described in Creating Spark Applications until you reach the Review step. To open an editor to change the application configuration using YAML in the\n                    GUI, click Edit YAML . Replace the default Spark image in YAML with your built open-source Spark\n                    image. image: <base-repository>/<image-name>:<image-tag> To set the logged-in user\u2019s context, add the following configuration in the sparkConf section. spark.hpe.webhook.security.context.autoconfigure: \"true\" To\n                    learn more about user context, see Setting the User Context . To submit the application with the your own Spark image, click Create Spark Application on the bottom right of the Review step. Using Airflow When you submit the Spark application by using Airflow, your Spark application will be\n        configured with your chosen Spark image on your YAML file. This YAML file is set in the\n        Airflow DAG. For example: submit = SparkKubernetesOperator(\n    task_id='submit',\n    namespace=\"example\", application_file=\"example.yaml\", dag=dag,\n    api_group=\"sparkoperator.hpe.com\",\n    enable_impersonation_from_ldap_user=True\n) To learn about how to submit Spark applications by using Airflow DAG, see Submitting Spark Applications by Using DAGs . On this page Using the Create Spark Application GUI Using Airflow Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/using-your-own-images.html",
        "title": "Using Your Own Open-Source Spark Images"
    },
    {
        "content": "\nSetting the User Context Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . Using HPE-Curated Spark Images Describes how to use HPE-curated Spark images to submit     Spark applications. Using Spark OSS Images Describes how to use Spark Open-Source Software (OSS) images to submit Spark     applications. Using Your Own Open-Source Spark Images Describes how to use your own open-source Spark images to submit Spark     applications. Setting the User Context Describes how to set the user context when using the     Spark OSS     images. List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Setting the User Context Describes how to set the user context when using the\n    Spark OSS\n    images. User context is not configured automatically for the\n      Spark OSS\n      images. If you do not set the user context, the user identity that is set in the image is used to\n      access the data sources like persistent volumes. This can cause your Spark application to fail\n      due to a lack of proper permissions. To set the logged-in user\u2019s context when using the\n      Spark OSS\n      images, add the following configuration in the sparkConf section of your Spark application YAML\n      file. spark.hpe.webhook.security.context.autoconfigure: \"true\" Once you add this configuration to the YAML file, HPE Ezmeral Unified Analytics Software automatically defines and sets the user context for the logged-in user, and your Spark\n      application runs successfully. NOTE Do not add this configuration to your Spark application YAML file if you are using the\n        default Spark images that support Data Fabric services. To learn more about pod security context, see Configure a Security Context for a Pod or\n      Container . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/setting-user-context.html",
        "title": "Setting the User Context"
    },
    {
        "content": "\nList of Spark Images Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These\n        images enables you to run the Spark applications in an air-gapped environment. The images follow the following\n            format: <base-repository>/<image-name>:<image-tag> HPE Ezmeral Unified Analytics Software uses two different types of image tags as follows: Timestamped image tags These image tags are static, and they are not updated when new changes\n                            are pushed to the image. For\n                            example: gcr.io/mapr-252711/spark-gpu-3.4.1:202309070600R Non-timestamped image tags These image tags are dynamic, and they are updated when new changes are\n                            pushed to the image. For\n                            example: gcr.io/mapr-252711/spark-gpu-3.4.0:v3.4.0 Images for HPE Ezmeral Unified Analytics Software 1.3.0 The following images are required in order to install and run Spark and Spark based services: Spark Operator Images gcr.io/mapr-252711/spark-operator-1.3.8:1.3.8.4-hpe\ngcr.io/mapr-252711/autoticketgen-2.0.2:202401101515MG Livy Server Images gcr.io/mapr-252711/livy-0.8.0:202401202202R Spark History Server Images gcr.io/mapr-252711/spark-hs-3.5.0:202401050731R HPE-Curated Spark 3.5.0 Workload\n                            Images (Supporting Data Fabric Services) gcr.io/mapr-252711/spark-base-3.5.0:202401202202R\ngcr.io/mapr-252711/spark-3.5.0:202401202202R\ngcr.io/mapr-252711/spark-gpu-3.5.0:202401202202R\ngcr.io/mapr-252711/spark-py-3.5.0:202401202202R\ngcr.io/mapr-252711/spark-r-3.5.0:202401202202R Spark OSS 3.5.0 Images (Not\n                            Supporting Data Fabric Services) gcr.io/mapr-252711/apache-spark:3.5.0\ngcr.io/mapr-252711/apache-spark:3.5.0-py\ngcr.io/mapr-252711/apache-spark:3.5.0-r\ngcr.io/mapr-252711/apache-spark:3.5.0-gpu (Default) HPE-Curated Spark Images\n                            When Using GUI (Supporting Data Fabric Services) gcr.io/mapr-252711/spark-3.5.0:v3.5.0\ngcr.io/mapr-252711/spark-gpu-3.5.0:v3.5.0\ngcr.io/mapr-252711/spark-py-3.5.0:v3.5.0\ngcr.io/mapr-252711/spark-r-3.5.0:v3.5.0 Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/spark-images-list.html",
        "title": "List of Spark Images"
    },
    {
        "content": "\nCreating Spark Applications Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Prerequisites Sign in to HPE Ezmeral Unified Analytics Software . Must have a main application file (for example, compiled jar file for Java or\n                    Scala). Must know the runtime dependencies of your application that are not built-in to\n                    the main application file. Must know your application arguments. About this task Create and submit Spark applications in HPE Ezmeral Unified Analytics Software . Procedure To start creating Spark applications, you can choose one of the following\n                    options: Click the Analytics icon and click Spark Applications on the left navigation bar\n                            of the HPE Ezmeral Unified Analytics Software screen. Click the Tools & Frameworks icon on the\n                            left navigation bar. Navigate to the Spark\n                                Operator tile under the Analytics tab and click Open . Click Create Application on the Spark Applications\n                    screen. Navigate through each step within the Create Spark\n                        Application wizard: Application Details : Create an application or\n                            upload a preconfigured YAML file. Set the following boxes: YAML File: When you select Upload YAML , you can\n                                        upload a preconfigured YAML file from your local system.\n                                        Click Select File to upload the\n                                        YAML. The fields in the wizard are populated with the information\n                                        from YAML. Name: Enter the application name. Description: Enter the application description. Configure Spark Application : Set the following\n                            boxes: Type: Select the application type from Java, Scala, Python, or\n                                        R. Source: Select the location of the main application file from User Directory , Shared Directory , S3 , and Other . HPE Ezmeral Unified Analytics Software preconfigures Spark applications\n                                            and Livy sessions in such a way that both user and shared volumes are mounted to driver and executor runtimes. Uploading Files to the User and Shared\n                                                  Directories To upload files to the user and shared directories: Open a different HPE Ezmeral Unified Analytics Software browser. In the left navigation bar, select Data Engineering \u2192 Data\n                                                  Sources and then select the Data\n                                                  Volumes tab. On the Data Volumes tab, select your\n                                                  user directory or the shared directory. NOTE The following image shows an\n                                                  example of a user ( bob ) directory\n                                                  and a shared directory: If you do\n                                                  not see your user directory or the shared directory, contact your\n                                                  administrator. Click Upload to upload the Spark\n                                                  application files to the user/ or shared/ directory. Return to the browser you were working in with\n                                                  the Configure Spark\n                                                  Application wizard. Click Browse , and\n                                                  navigate to the location where you uploaded files. Select the Spark application files. Using S3 To use S3 as the source,\n                                                  manually set the Spark configurations for S3 in\n                                                  Spark application YAML file. For example: Update your Spark application YAML\n                                                  with the following\n                                                  configurations: sparkConf:\n    spark.hadoop.fs.s3a.access.key: <S3-ACCESS_KEY>\n    spark.hadoop.fs.s3a.connection.ssl.enabled: \"true\"\n    spark.hadoop.fs.s3a.endpoint: <S3-endpoint>\n    spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem\n    spark.hadoop.fs.s3a.path.style.access: \"true\"\n    spark.hadoop.fs.s3a.secret.key: <S3-SECRET-KEY> Alternatively, you can set ACCESS_KEY and\n                                                  SECRET_KEY as environment\n                                                  variables: spark.kubernetes.driverEnv.AWS_ACCESS_KEY_ID: <ACCESS_KEY>\nspark.kubernetes.driverEnv.AWS_ACCESS_KEY_ID: <SECRET_KEY>\nspark.kubernetes.executorEnv.AWS_ACCESS_KEY_ID: <ACCESS_KEY>\nspark.kubernetes.executorEnv.AWS_SECRET_ACCESS_KEY: <SECRET_KEY> NOTE When you are using these options,\n                                                  tokens from the Secret mounted into the pod are\n                                                  not automatically refreshed. To learn more\n                                                  about configuration options, see Hadoop S3\n                                                  Client . However, for HPE-Curated Spark , you\n                                                  can use EzSparkAWSCredentialProvider which automatically sets credentials from the file\n                                                  automatically mounted in driver and executor pods\n                                                  by Kyverno policy. sparkConf:\n    spark.hadoop.fs.s3a.endpoint: <S3-endpoint>\n    spark.hadoop.fs.s3a.connection.ssl.enabled: \"true\"\n    spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem spark.hadoop.fs.s3a.aws.credentials.provider: \"org.apache.spark.s3a.EzSparkAWSCredentialProvider\" spark.hadoop.fs.s3a.path.style.access: \"true\" If you are using Amazon S3, add the following\n                                                  configurations in addition to the previous\n                                                  configurations options to the sparkConf section. spark.driver.extraJavaOptions: -Djavax.net.ssl.trustStore=/etc/pki/java/cacerts\nspark.executor.extraJavaOptions: -Djavax.net.ssl.trustStore=/etc/pki/java/cacerts If S3 server is behind the proxy server, add\n                                                  the following configurations in addition to the\n                                                  previous configurations\n                                                  options. spark.hadoop.fs.s3a.proxy.host: \"web-proxy.corp.hpecorp.net\"\nspark.hadoop.fs.s3a.proxy.port: \"8080\" To create the Kubernetes Secret with\n                                                  Base64-encoded values for AWS_ACCESS_KEY_ID\n                                                  (username) and AWS_SECRET_ACCESS_KEY (password),\n                                                  use notebook. See Creating and Managing Notebook Servers . For example: Run kubectl apply\n                                                  -f for the following\n                                                  YAML: apiVersion: v1 \nkind: Secret\ndata: \n  AWS_ACCESS_KEY_ID: <Base64-encoded value; example: dXNlcg== >\n  AWS_SECRET_ACCESS_KEY: <Base64-encoded value; example:cGFzc3dvcmQ= > \nmetadata: \n  name: <K8s-secret-name-for-S3> \ntype: Opaque To learn more, see Securely Passing Spark Configuration Values . Using Other Select Other as the data\n                                                  source, to reference other locations of the\n                                                  application file. For example, to refer to main application files\n                                                  and dependency files, or to refer to a file inside\n                                                  the specific Spark image, use the local:// schema. local:///opt/mapr/spark/spark-3.2.0/examples/jars/spark-examples_2.12-3.2.0.16-eep-810.jar File Name: Manually enter the location and file name of the\n                                            application for the S3 and Other sources. For example: s3a://apps/my_application.jar For User Directory and Shared Directory , click Browse , and browse and select\n                                            files. NOTE Ensure the extension of the main application file\n                                                matches the selected application type. The extension\n                                                must be .py for Python, .jar for Java and Scala, and .r for R applications. Class Name: Enter main class of the application for Java or Scala\n                                        applications. Arguments: Click + Add Argument to add input\n                                        parameters as required by the application. NOTE To refer to data in mounted folders from application source\n                                        code, use file:// schema. If a Spark\n                                            application is reading a file from the shared or user volume and is taking a path to the file as an\n                                            application argument, the argument will be file://[mount-path]/path/to/input/file .\n                                            For\n                                            example: User Directory: file:///mounts/<user-name>-volume/\nShared Directory: file:///mounts/shared-volume/ Dependencies: Add dependencies in\n                            the Dependencies step. To add dependencies required to run your applications, select a\n                                dependency type from excludePackages, files, jars, packages,\n                                pyfiles, or repositories, and enter the value of the dependency. To\n                                add more than one dependency, click Add\n                                    Dependency . For example: Enter the package names as the values for the\n                                        excludePackages dependency type. Enter the locations of file, for example, s3://<path-to\n                                        file>, local://<path-to-file> as the values for files,\n                                        jars, pyfiles, or repositories. Driver Configuration: Configure the number of cores, core limits, and\n                                memory. The number of cores\n                            must be less than or equal to the core limit. See Configuring Memory for Spark Applications . When boxes in this wizard are left blank, the default values are set.\n                                The default values are as follows: Number of Cores: 1 Core Limit: unlimited Memory: 1g Executor Configuration: Configure the number of executors, number of cores,\n                                core limits, and memory. The number of\n                            cores must be less than or equal to the core limit. See Configuring Memory for Spark Applications . When boxes in this wizard are left blank, the default values are set.\n                                The default values are as follows: Number of Executors: 1 Number of Cores per Executor: 1 Core Limit per Executor: unlimited Memory per Executor: 1g Schedule Application: To schedule a Spark\n                            application to run at a certain time, toggle Schedule to\n                                Run . You can configure the frequency intervals and set\n                            the concurrency policy, successful run history limit, and failed run\n                            history limit. Set the Frequency Interval in two ways: To choose from predefined intervals, select Predefined Frequency Interval and\n                                    click Update to open a dialog with\n                                    predefined intervals. To set the frequency interval, select Custom\n                                        Frequency Interval . The Frequency\n                                        Interval accepts any of the following values: CRON expression with Field 1: minute (0\u201359) Field 2: hour (0\u201323) Field 3: day of the month (1\u201331) Field 4: month (1\u201312, JAN - DEC) Field 5: day of the week (0\u20136, SUN - SAT) Example: 0 1 1 * * , 02\n                                                  02 ? * WED, THU Predefined macro @yearly @monthly @weekly @daily @hourly Interval using @every <duration> Units: nanosecond (ns), microsecond (us, \u00b5s),\n                                                  millisecond (ms), second (s), minute (m), and hour\n                                                  (h). Example: @every 1h , @every 1h30m10s Review: Review the application details. Click\n                            the pencil icon in each section to navigate to\n                            the specific step to change the application configuration. To open an editor to change the application configuration using YAML\n                            in the GUI, click Edit YAML . You can use the\n                            editor to add the extra configuration options not available through the\n                            application wizard. To apply the changes, click Save\n                                Changes . To cancel the changes, click Discard\n                                Changes . To submit the application, click Create Spark\n                        Application on the bottom right of the Review step. Results The Spark application is created and will immediately run,\n            or will wait to run at its scheduled time. You can view it on the Spark\n                Applications screen. More information Submitting a Spark Wordcount Application Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/creating_spark_application.html",
        "title": "Creating Spark Applications"
    },
    {
        "content": "\nManaging Spark Applications Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . About this task View and manage the status of all the Spark applications and scheduled Spark\n                applications. Procedure To view and manage Spark applications, you can choose one of the following\n                    options: Click the Analytics icon and click Spark Applications on the left navigation bar\n                            of the HPE Ezmeral Unified Analytics Software screen. Click the Applications & Frameworks icon on\n                            the left navigation bar. Navigate to the Spark tile under the Analytics tab and click Open . To view actions that you can perform on the Applications and Scheduled Applications tab, click the menu icon in the Actions column. View Details: To view the details of an application, and events and logs of the\n                                pods, select View Details . To access the Spark History Server and view and monitor the\n                                applications, click Spark Web UI in the top\n                                right of the Application Detail screen. View YAML: To view the YAML file and see the configuration details, select View YAML . Edit YAML: To open an editor to change the application configuration using a\n                                YAML in the GUI, click Edit\n                                YAML .\n                                To apply the changes, click Update\n                                    Application . To cancel the changes, click Discard Changes . View Logs: To view the Spark driver pod logs, select View\n                                    Logs . Edit: To change application configurations and resubmit the application,\n                                select Edit . You can update all the application parameters except name, and type\n                                using Edit . Use Clone to update the parameters and create an application. You can update the schedule of the scheduled Spark application by\n                                using Edit . To open an editor to change the application configuration using\n                                YAML, click Edit YAML in the Review step. To apply the changes, click Save Changes . To cancel the changes,\n                                click Discard Changes . To schedule the Spark application, select Schedule or select Clone . NOTE Using Edit to resubmit an application\n                                    will remove pods and logs of the previous application\n                                    run. Clone: To create a new Spark application with the similar configuration as\n                                an existing Spark application, select Clone .\n                                You can update any application parameters and submit it as a new\n                                application. NOTE If you enter the same name as the current Spark application\n                                        and configure the scheduling details in the Schedule Application step, it\n                                        will create a new scheduled Spark application. Submitting an application with same name and application type\n                                        as an existing application will remove pods and logs of the\n                                        previous application run. Schedule: To schedule the application, click Schedule .\n                                You can view this application in the Scheduled\n                                    Applications tab. To learn more about the Schedule Application step, see Creating Spark Applications . Suspend: To stop the application from running at its scheduled time, select Suspend from the Actions menu in the Scheduled\n                                    Applications tab. Resume: To restart the schedule of the suspended applications, select Resume from the Actions menu in Scheduled\n                                    Applications tab. Delete: To delete the Spark application, select Delete . Delete multiple Spark applications at once: To select multiple applications, click the check box besides Application Name in the table. Click Delete in the top right pane of the\n                            table. To display the Spark applications according to the status, click the Filter icon. To select the columns to display on your applications table, click the Columns icon. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/managing_spark_applications.html",
        "title": "Managing Spark Applications"
    },
    {
        "content": "\nConfiguring Memory for Spark Applications Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. You can configure the driver and executor memory options for the Spark applications by using HPE Ezmeral Unified Analytics Software . See Creating Spark Applications . You can configure the driver and executor memory options for the Spark applications by\n      manually setting the following properties in the Spark application YAML file. See Spark application YAML . spark.driver.memory : Amount of memory allocated for the driver. spark.executor.memory : Amount of memory allocated for each executor\n          that runs the task. However, there is an added memory overhead of 10% of the configured driver or executor\n      memory, which is at least 384 MB. The memory overhead is per executor and driver. Thus, the\n      total driver or executor memory includes the driver or executor memory and overhead. Memory Overhead = 0.1 * Driver or Executor Memory (minimum of 384 MB) Total Driver or Executor Memory = Driver or Executor Memory + Memory Overhead Configuring Memory Overhead You can configure the memory overhead for driver and executor in HPE Ezmeral Unified Analytics Software . Set the following configurations options in the Spark application YAML file by clicking Edit YAML in Review step or Edit\n          YAML from the Actions menu on Spark\n          Applications screen. See Managing Spark Applications . spark.driver.memoryOverhead spark.executor.memoryOverhead To learn more about driver or executor memory, memory overhead, and other properties, see Apache Spark 3.x.x application properties. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/configure_memory_for_spark_apps.html",
        "title": "Configuring Memory for Spark Applications"
    },
    {
        "content": "\nCreating Interactive Sessions Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Prerequisites Log in to HPE Ezmeral Unified Analytics Software . See Get Started . About this task Create an interactive session in HPE Ezmeral Unified Analytics Software . Procedure To start creating interactive sessions, you can choose one of the following\n                    options: Click the Analytics icon and click Spark Interactive Sessions on the left\n                            navigation bar of the HPE Ezmeral Unified Analytics Software screen. Click the Applications & Frameworks icon on\n                            the left navigation bar. Navigate to the Livy tile under the Analytics tab and click Open . Click Create Interactive Session in the Spark\n                    Interactive Sessions screen. Navigate through each step within the Create Interactive Session wizard: Session Configurations and Dependencies :\n                            Configure session details, Spark configurations, and dependencies. Set\n                            the following boxes: Name: Enter the session name. Spark Configurations : Set Spark configurations by providing\n                                key-value pairs See Spark Configurations for\n                                available configurations. To add additional Spark configurations required to run your session,\n                                click Add Configuration . Dependencies Type: Select one of the following dependency types: files jars pyfiles archives Value: Enter the file location for the dependency. For example,\n                                            if the type is files, jars, or pyfiles, you could enter\n                                            s3:// or local:// as the value. To add additional dependencies required to run your session, click Add Dependency . Driver and Executor Configuration: Configure the\n                            number of cores, memory, number of executors, number of cores per\n                            executor, and memory per executor. Review: Review the session details. Click the pencil icon in each section to navigate to\n                            the specific step to change the session configuration. To create the interactive session, click Create Interactive\n                        Session on the bottom right of the Review step. Results A new interactive session is created and you can view it in\n            the Spark Interactive Sessions screen. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/creating_interactive_sessions.html",
        "title": "Creating Interactive Sessions"
    },
    {
        "content": "\nSubmitting Statements Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Prerequisites Create an interactive session. See Creating Interactive Sessions . About this task Run statements in Python, R, or Scala. Procedure To submit statements, you can choose one of the following options: Click Session ID of your Spark interactive\n                            ession. Click the menu icon in the Actions column and click Open . Select either Python, R, or Scala as the statements' programming\n                    language. Enter statements in Python, R, or Scala. For example: Select Scala as programming language and calculate the value of\n                    Pi by running the following statement. val NUM_SAMPLES = 10000;\nval res = sc.parallelize(1 to NUM_SAMPLES).map { i => val x = Math.random();\nval y = Math.random();\nif (x*x + y*y < 1) 1 else 0 }.reduce(_ + _);\nprintln(\"Pi is roughly \" + 4.0 * res / NUM_SAMPLES); Click the Run icon on the top right of the Statements pane. For example: Running the previous statement returns the following statement\n                        result: NOTE Each Spark interactive session\n                        expires in 60 minutes. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/submitting_statements.html",
        "title": "Submitting Statements"
    },
    {
        "content": "\nManaging Interactive Sessions Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . About this task View and manage the status of all the Spark interactive sessions. Procedure To view and manage Spark interactive sessions, you can choose one of the\n                    following options: Click the Analytics icon and click Spark Interactive Sessions on the left\n                            navigation bar of the HPE Ezmeral Unified Analytics Software screen. Click the Applications & Frameworks icon on\n                            the left navigation bar. Navigate to the Livy tile under the Analytics tab and click Open . To view actions that you can perform on the Spark Interactive\n                        Sessions screen, click the menu icon in\n                    the Actions column. View Details: To view the details of an application, and events and logs of the\n                                pods, select View Details . Open: To submit statements, select Open . See Submitting Statements . View Logs: To view the session logs provided by Livy server, select View Logs . Delete: To delete the Spark interactive session, select Delete . Delete multiple sessions at once: To select multiple sessions, click the check box besides Session ID in the table. Click Delete on the top right pane of the\n                            table. To display the Spark interactive sessions according to the status, click the Filter icon. To select the columns to display on your applications table, click the Columns icon. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/managing_interactive_sessions.html",
        "title": "Managing Interactive Sessions"
    },
    {
        "content": "\nSpark History Server Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Spark History Server Provides an overview of Spark History Server. Spark History Server provides a web UI to monitor and view the status of submitted Spark\n      applications. It shows the status of Running, Completed, and Failed (completed but failed)\n      Spark applications. To access Spark History Server in HPE Ezmeral Unified Analytics Software , click the Applications & Frameworks icon on\n      the left navigation bar. Navigate to the Spark History Server tile\n      under the Analytics tab and click Open . Spark History Server gathers metrics and enables you to get information about your Spark\n      applications. By default, all the Spark applications are integrated with Spark History Server. You can\n      disable the integration of the Spark applications with Spark History Server by reconfiguring\n      the Spark applications. Spark History Server pulls the details of the Spark applications from the event logs\n      directory. Persistent volume is mounted to all the Spark applications. The event logs from the\n      Spark runtime are written to the event log directory on persistent volume. Spark History\n      Server reads the event logs and displays them on the UI. SSO is enabled for the Spark History Server. When you sign in to the Spark History Server,\n      you can see the list of all applications; however, you can only read the details of your own\n      applications. Only an administrator can read the details of other users\u2019 applications. You can\n      configure each Spark application with its own separate access control lists (ACLs), see Authentication and Authorization for details. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/spark-history-server.html",
        "title": "Spark History Server"
    },
    {
        "content": "\nUsing Spark SQL API Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . In HPE Ezmeral Unified Analytics Software , you can use the Spark SQL API in two different\n      ways: External Metastore NOTE There will be some limitations to integration with external metastore. To integrate Spark with external metastore, follow these steps: Set the metastore URI with the spark.hive.metastore.uris config option.\n          This URI should be public and accessible from your Spark applications. Set the value of spark.sql.warehouse.dir property to the same value as\n          that of external metastore. For example: if you want to query a managed table then the\n          path to that managed table must match in both metastore and Spark runtime. Verify that the metastore host can accept external connections so that Spark can connect\n          to the metastore. Configure the gateway rules for securing the metastore as the metastore\n          doesn\u2019t have authentication and authorization. Verify that your Spark applications are querying the data from locations accessible\n          within the Spark runtime. Temporary Views The temporary view is a feature in the Spark DataFrame API. You can read data and create a\n        temporary view for the data by using the temporary view feature. These views are not global\n        and cannot be shared between any two Spark applications. You can use a temporary view in the\n        following two scenarios: If the schema is available for your data, use DataFrame:create[OrReplace]TempView . Some file formats already include\n          schema, for example, parquet files or CSV files with the header. You can read the file,\n          create a DataFrame and then call the create[OrReplace]TempView function\n          and give it the view name and finally, you can query data using Spark SQL API. If the schema is not available for your data, you can set it while creating or\n          converting the DataFrame, then create the temporary view. By default, Spark sets aliases\n          for the column names like underscore 1, underscore 2, and so on, however, you can set your\n          own column names. On this page External Metastore Temporary Views Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/using-spark-sql-api.html",
        "title": "Using Spark SQL API"
    },
    {
        "content": "\nEnabling GPU Support for Spark Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Enabling GPU Support for Spark Operator Describes how to enable and allocate GPU resources on Spark Operator. Enabling GPU Support for Livy Sessions Describes how to enable and allocate GPU resources on Livy Server. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how\n    to enable and allocate the GPU resources on Spark. In HPE Ezmeral Unified Analytics Software , you can use RAPIDS Accelerator for Apache Spark by NVIDIA to accelerate the processing for Spark by using the\n      GPUs. The GPU image (spark-gpu-<spark-version>), for example, spark-gpu-3.5.0 , has a built-in open-source RAPIDS plugin\n      in HPE Ezmeral Unified Analytics Software . To see the list of Spark GPU images, see List of Spark Images . NOTE Do not allocate GPUs for a driver pod. GPUs are used by executor pods only. With MIG configuration, only one GPU can be assigned per application. For details, see GPU Support . Spark Configurations for GPU Spark Configurations Key Value GPU Images See List of Spark Images spark.kubernetes.container.image gcr.io/mapr-252711/spark-gpu-<spark-version>:<image-tag> Enable RAPIDS plugin spark.plugins com.nvidia.spark.SQLPlugin spark.rapids.sql.enabled true spark.rapids.force.caller.classloader false Allocate GPU resources spark.task.resource.gpu.amount 1 spark.executor.resource.gpu.amount 1 spark.executor.resource.gpu.vendor nvidia.com Set GPU discovery script path spark.executor.resource.gpu.discoveryScript /opt/mapr/spark/spark-<spark-version>/examples/src/main/scripts/getGpusResources.sh Set RAPIDS shim layer for the run 1 spark.rapids.shims-provider-override com.nvidia.spark.rapids.shims.<spark-identifier>.SparkShimServiceProvider 1 The Spark version distributed by HPE is compatible with its corresponding\n        open-source version. The RAPIDS jar includes the shim layer provider classes called com.nvidia.spark.rapids.shims.[spark-identifier].SparkShimServiceProvider .\n        You can replace the [spark-identifier] based on the Spark distributed by\n        HPE such as: For spark-3.5.0, the identifier is spark350. Enabling GPU Support for Spark Operator Describes how to enable and allocate GPU resources on Spark Operator. Enabling GPU Support for Livy Sessions Describes how to enable and allocate GPU resources on Livy Server. More information GPU Support Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/enabling-gpu-on-spark.html",
        "title": "Enabling GPU Support for Spark"
    },
    {
        "content": "\nEnabling GPU Support for Spark Operator Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Enabling GPU Support for Spark Operator Describes how to enable and allocate GPU resources on Spark Operator. Enabling GPU Support for Livy Sessions Describes how to enable and allocate GPU resources on Livy Server. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Enabling GPU Support for Spark Operator Describes how to enable and allocate GPU resources on Spark Operator. Enabling GPU Support for Spark Operator To enable GPU processing and allocate GPU resources on Spark Operator, follow these\n          steps: Set the image option within the spec property of the Spark\n            application yaml file to gcr.io/mapr-252711/spark-gpu-<spark-version>:<image-tag> . To\n            see the list of Spark GPU images, see List of Spark Images . Add the following configuration options to sparkConf section within\n            the spec property. To enable the RAPIDS plugin and allocate the GPU resources, add: # Enabling RAPIDs plugin\nspark.plugins: \"com.nvidia.spark.SQLPlugin\"\nspark.rapids.sql.enabled: \"true\"\nspark.rapids.force.caller.classloader: \"false\"\n \n# GPU allocation and discovery settings\nspark.task.resource.gpu.amount: \"1\"\nspark.executor.resource.gpu.amount: \"1\"\nspark.executor.resource.gpu.vendor: \"nvidia.com\" To set the path to the GPU discovery script,\n                add: spark.executor.resource.gpu.discoveryScript: \"/opt/mapr/spark/spark-<spark-version>/examples/src/main/scripts/getGpusResources.sh\" To set the RAPIDS shim layer used for the run,\n                add: spark.rapids.shims-provider-override: \"com.nvidia.spark.rapids.shims.<spark-identifier>.SparkShimServiceProvider\" The\n                Spark version distributed by Hewlett Packard Enterprise is\n                compatible with its corresponding open-source version. The RAPIDS jar includes the\n                shim layer provider classes called com.nvidia.spark.rapids.shims.[spark-identifier].SparkShimServiceProvider .\n                You can replace the [spark-identifier] based on the Spark\n                distributed by Hewlett Packard Enterprise such as: For spark-3.5.0, the identifier is spark350. For example, for spark-gpu-3.4.0, set the RAPIDS shim layer as\n                    follows: spark.rapids.shims-provider-override: \"com.nvidia.spark.rapids.shims.spark340.SparkShimServiceProvider\" Verifying Spark Applications are Running on GPU To verify the Spark applications are running on GPU, you can use the explain Spark\n        method. Run the following PySpark application: from pyspark.sql import SQLContext\nfrom pyspark import SparkConf\nfrom pyspark import SparkContext\n \nconf = SparkConf()\nsc = SparkContext.getOrCreate()\nsqlContext = SQLContext(sc)\n \ndf = sqlContext.createDataFrame([1,2,3], \"int\").toDF(\"value\")\ndf.createOrReplaceTempView(\"df\")\n \nsqlContext.sql(\"SELECT * FROM df WHERE value<>1\").explain()\nsqlContext.sql(\"SELECT * FROM df WHERE value<>1\").show()\n \nsc.stop() If you get the following output where the explain method prints the GPU-related stages, you\n        can verify that your Spark application is running on GPU. == Physical Plan ==\nGpuColumnarToRow false\n+- GpuFilter NOT (value#2 = 1), true\n   +- GpuRowToColumnar targetsize(2147483647)\n      +- *(1) SerializeFromObject [input[0, int, false] AS value#2]\n         +- Scan[obj#1] However, if you get the following output, your Spark application is not running on GPU but\n        instead on CPU. You must ensure that Spark applications are configured properly to work on\n        GPU. == Physical Plan ==\n*(1) Filter NOT (value#2 = 1)\n+- *(1) SerializeFromObject [input[0, int, false] AS value#2]\n   +- Scan[obj#1] Spark Operator YAML Example Using GPU for Spark 3.4.0 Example: apiVersion: \"sparkoperator.hpe.com/v1beta2\"\nkind: SparkApplication\nmetadata:\n  name:\nspark-eep-gpu-340\n  namespace: spark spec:\n  sparkConf:\n    # Enabling RAPIDs plugin\n    spark.plugins: \"com.nvidia.spark.SQLPlugin\"\n    spark.rapids.sql.enabled: \"true\"\n    spark.rapids.force.caller.classloader: \"false\"\n \n    # GPU allocation and discovery settings\n    spark.task.resource.gpu.amount: \"1\"\n    spark.executor.resource.gpu.amount: \"1\"\n    spark.executor.resource.gpu.vendor: \"nvidia.com\"\n    spark.executor.resource.gpu.discoveryScript: \"/opt/mapr/spark/spark-3.4.0/examples/src/main/scripts/getGpusResources.sh\"\n    spark.rapids.shims-provider-override: \"com.nvidia.spark.rapids.shims.spark340.SparkShimServiceProvider\" type: Python\n  sparkVersion:3.4.0\n  mode: cluster image: gcr.io/mapr-252711/spark-gpu-3.4.0:v3.4.0 imagePullPolicy: Always\n  mainApplicationFile: .../path/to/application.py\n  restartPolicy:\n    type: Never\n  imagePullSecrets:\n    - imagepull\n  driver:\n    cores: 1\n    coreLimit: \"1000m\"\n    memory: \"1024m\"\n    labels:\n      version: 3.4.0\n  executor:\n    cores: 1\n    coreLimit: \"1000m\"\n    instances: 1\n    memory: \"2G\"\n    labels:\n      version: 3.4.0 On this page Enabling GPU Support for Spark Operator Verifying Spark Applications are Running on GPU Spark Operator YAML Example Using GPU for Spark 3.4.0 Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/enabling-gpu-on-spark-operator.html",
        "title": "Enabling GPU Support for Spark Operator"
    },
    {
        "content": "\nEnabling GPU Support for Livy Sessions Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Enabling GPU Support for Spark Operator Describes how to enable and allocate GPU resources on Spark Operator. Enabling GPU Support for Livy Sessions Describes how to enable and allocate GPU resources on Livy Server. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Enabling GPU Support for Livy Sessions Describes how to enable and allocate GPU resources on Livy Server. Enabling GPU Support for Livy Sessions Created Using Spark Interactive Sessions To enable GPU processing and allocate GPU resources when using Spark interactive sessions,\n        follow these steps: Perform the creating interactive sessions instructions until you reach the Spark Configurations box in the Session\n              Configurations and Dependencies step. See Creating Interactive Sessions . Set the Spark Configurations for GPU by providing key-value pairs.\n            To add each Spark configurations required to run your session, click Add\n              Configuration . To specify the details for other boxes or options in the Session\n                Configurations and Dependencies step and to complete creating\n              interactive sessions, see Creating Interactive Sessions . Enabling GPU Support for Livy Sessions Created Using Notebooks To enable GPU processing and allocate GPU resources when using Spark magic\n          ( %manage_spark ) to create Livy sessions, follow these steps: Run %manage_spark to connect to the Livy server and start a new\n            session. See %manage_spark for details. Run %config_spark to add the Spark configurations. Click the +Add Spark Configuration Key-Value Pair button. Enter the key and value for Spark Configurations for GPU in their\n            respective boxes. After you have finished adding the key-value pairs, click Submit . This will save the new Spark configuration changes to\n            enable the GPU support for Livy sessions. To specify the details for the other boxes or options in the Create\n              Session step and to complete creating Livy session, see %manage_spark . Verifying Livy Sessions are Running on GPU To verify Livy sessions are running on GPU, you can use the explain Spark method. Run the following PySpark application for Livy Sessions Created Using Spark Interactive\n        Sessions: sqlContext = SQLContext(sc)\n \ndf = sqlContext.createDataFrame([1,2,3], \"int\").toDF(\"value\")\ndf.createOrReplaceTempView(\"df\")\n \nsqlContext.sql(\"SELECT * FROM df WHERE value<>1\").explain()\nsqlContext.sql(\"SELECT * FROM df WHERE value<>1\").show() Run the following PySpark application for Livy Sessions Created Using\n        Notebooks: from pyspark.sql import SQLContext\n\nfrom py4j.java_gateway import java_import\njvm = sc._jvm\njava_import(jvm, \"org.apache.spark.sql.api.python.*\")\n\nsqlContext = SQLContext(sc)\n\ndf = sqlContext.createDataFrame([1,2,3], \"int\").toDF(\"value\")\ndf.createOrReplaceTempView(\"df\")\n\nsqlContext.sql(\"SELECT * FROM df WHERE value<>1\").explain()\nsqlContext.sql(\"SELECT * FROM df WHERE value<>1\").show() If you get the following output where the explain method prints the GPU-related stages, you\n        can verify that your Livy session is running on GPU. == Physical Plan ==\nGpuColumnarToRow false\n+- GpuFilter NOT (value#2 = 1), true\n   +- GpuRowToColumnar targetsize(2147483647)\n      +- *(1) SerializeFromObject [input[0, int, false] AS value#2]\n         +- Scan[obj#1] However, if you get the following output, your Livy session is not running on GPU but\n        instead on CPU. You must ensure that Livy sessions are configured properly to work on\n        GPU. == Physical Plan ==\n*(1) Filter NOT (value#2 = 1)\n+- *(1) SerializeFromObject [input[0, int, false] AS value#2]\n   +- Scan[obj#1] On this page Enabling GPU Support for Livy Sessions Created Using Spark Interactive Sessions Enabling GPU Support for Livy Sessions Created Using Notebooks Verifying Livy Sessions are Running on GPU Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/enabling-gpu-on-livy-server.html",
        "title": "Enabling GPU Support for Livy Sessions"
    },
    {
        "content": "\nSecurely Passing Spark Configuration Values Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes\n    Secret. About this task You can pass the sensitive data which are part of the Spark configuration using the\n        Kubernetes secret. The secret has a Key-Value format where the key is spark-defaults.conf file and the value is sensitive data. You can use\n        notebook to create secrets. Procedure Create a Kubernetes Secret with the key as spark-defaults.conf and the\n          value as  sensitive data. See Creating a Secret . Add spark.mapr.extraconf.secret option with value as Secret name on\n          Spark application YAML. Example To securely pass the sensitive data, create a file with Spark configuration properties\n          : cat << EOF > spark-defaults.conf\nspark.hadoop.fs.s3a.access.key EXAMPLE_ACCESS_KEY\nspark.hadoop.fs.s3a.secret.key EXAMPLE_SECRET_KEY\nEOF Create a Secret from the\n          file: kubectl create secret generic <k8s-secret-name> --from-file=spark-defaults.conf Set the spark.mapr.extraconf.secret option with Secret name in Spark\n          application YAML. ...\nspec:\n  sparkConf:\n    spark.mapr.extraconf.secret: \"<k8s-secret-name>\"\n... Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/securely_passing_spark_configs.html",
        "title": "Securely Passing Spark Configuration Values"
    },
    {
        "content": "\nRunning Spark Applications in Namespaces Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Information in this topic relates to Spark applications that use the HPE-curated Spark images or Spark OSS images with the security context set\n        in the Spark application YAML, as described in Setting Security Context for Spark OSS Images . HPE Ezmeral Unified Analytics Software users (admins\n        and members) can submit Spark applications through the following clients and interfaces: HPE Ezmeral Unified Analytics Software UI APIs/CLI (kubectl) Notebooks Airflow DAGs By default, when a user submits a Spark application, the Spark application runs in the\n        user's designated namespace, isolating the user's work and resource use from other users in\n        the HPE Ezmeral Unified Analytics Software cluster.\n        For example, if user01 is signed into HPE Ezmeral Unified Analytics Software and submits a Spark application, the Spark\n        application automatically runs in the user01 namespace. Only user01 can access the Spark application and Spark application details in\n        the Spark History Server UI. Alternatively, a user can run their Spark applications in the spark namespace. When a user changes the namespace to spark in the Spark\n        application YAML, the Spark application runs in the spark namespace and all\n        users (admins and members) can access the Spark application through the HPE Ezmeral Unified Analytics Software UI. However, only the\n        user that submitted the Spark application can access the application details in the Spark History Server UI . NOTE Currently,\n          the HPE Ezmeral Unified Analytics Software UI does\n          not support running Spark applications in the spark namespace. You can\n          only run Spark applications in the spark namespace through kubectl,\n          notebooks, and Airflow DAGs. The following table describes how HPE Ezmeral Unified Analytics Software responds when you submit Spark applications through the supported\n        clients and interfaces: Client/Interface Description HPE Ezmeral Unified Analytics Software UI Spark applications run in the user's designated namespace. Does not support running Spark applications in the spark namespace. If a user changes the namespace in their Spark application, the system\n                      automatically reverts the namespace back to the namespace of the user\n                      submitting the Spark application. For example, if user01 submits the Spark application as user02, the system\n                      automatically reverts the namespace back to user01 and runs\n                      the application in the user01 namespace. API/CLI (kubectl) Spark applications run in the user's designated namespace. Users can change the namespace to spark ; Spark applications\n                      run in the spark namespace and become accessible to all\n                      users. If a user changes the namespace in their Spark application, for example user01 changes the namespace to user02, the system accepts the Spark application, but returns an access denied error. Notebook Spark applications run in the user's designated namespace. If a user changes the namespace in their Spark application, for example user01 changes the namespace to user02, the system returns an access denied error. Airflow DAG A Spark application launched through an Airflow DAG automatically runs in\n                      the namespace of the user that deployed the DAG. For example, if user01 deploys a DAG with a Spark application in the\n                      workflow, the Spark application runs in the user01 namespace. Manually triggered DAGs launch in the namespace of the trigger event owner. Scheduled DAGs launch in the namespace of the last user to un-pause the\n                      DAG. Spark History Server In an HPE Ezmeral Unified Analytics Software cluster, one Spark History Server runs in the spark namespace. Users can go\n        to the Spark History Server UI to view a list of all Spark applications that have run.\n        However, users can only view the details of Spark applications that they submit, regardless\n        of the namespace they use (their own namespace or the spark namespace). If a user submits a Spark application in the spark namespace, only that\n        user can view the application details in the Spark History Server UI. For example, if user01 submits a spark application in the spark namespace, user02 cannot access the Spark application details in the Spark\n        History Server UI. Only user01 can view the Spark application details. The system returns an unauthorized message when users try to view application details for\n        Spark applications that were submitted by other users. Setting Security Context for Spark OSS\n        Images The Spark OSS images do not contain the security context required to run\n        Spark applications against volumes in HPE Ezmeral Unified Analytics Software . HPE Ezmeral Unified Analytics Software denies user access to the volume if it cannot authenticate the user,\n        which results in Spark application failures. To add security context to your Spark\n      application, add the following configuration setting in the Spark application\n        YAML: sparkConf:\n    spark.hpe.webhook.security.context.autoconfigure: \"true\" This security context flag sets the pod security context and enables HPE Ezmeral Unified Analytics Software to recognize you as a\n        valid HPE Ezmeral Unified Analytics Software user\n        when you run your Spark applications. When you add the security context flag to the\n        Spark application YAML and run the Spark application, the application automatically runs in\n        your user-designated namespace. If you change the namespace to spark , the\n        Spark application runs in the spark namespace. WARNING Do not\n          set the security context in HPE-Curated Spark images. Setting the security context in\n          HPE-Curated Spark images causes Spark applications to fail. For additional\n        information, see User Isolation and Setting the User Context . On this page Spark History Server Setting Security Context for Spark OSS\n        Images Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/spark-namespaces.html",
        "title": "Running Spark Applications in Namespaces"
    },
    {
        "content": "\nUsing whylogs with Spark Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Spark Provides a brief overview of Apache Spark in HPE Ezmeral Unified Analytics Software . Using Spark Images Describes different types of Spark images supported by HPE Ezmeral Unified Analytics Software . List of Spark Images Lists the Spark images distributed by HPE Ezmeral Unified Analytics Software . These         images enables you to run the Spark applications in an air-gapped environment. Creating Spark Applications Describes how to create Spark applications using HPE Ezmeral Unified Analytics Software . Managing Spark Applications Describes how to view and manage Spark applications using HPE Ezmeral Unified Analytics Software . Configuring Memory for Spark Applications Describes how to set memory options for Spark applications. Creating Interactive Sessions Describes how to create interactive sessions in HPE Ezmeral Unified Analytics Software . Submitting Statements Describes how to submit statements in HPE Ezmeral Unified Analytics Software . Managing Interactive Sessions Describes how to view and manage Spark interactive sessions in HPE Ezmeral Unified Analytics Software . Spark History Server Provides an overview of Spark History Server. Using Spark SQL API Describes how to use Spark SQL API in HPE Ezmeral Unified Analytics Software . Enabling GPU Support for Spark Describes NVIDIA spark-rapids accelerator support for Spark, and how     to enable and allocate the GPU resources on Spark. Securely Passing Spark Configuration Values Describes how to pass the sensitive data to Spark configuration using the Kubernetes     Secret. Running Spark Applications in Namespaces Describes how namespaces work with regard to Spark applications in HPE Ezmeral Unified Analytics Software . Using whylogs with Spark Describes how to use whylogs with Spark. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using whylogs with Spark Describes how to use whylogs with Spark. Prerequisites Sign in to HPE Ezmeral Unified Analytics Software as a\n            member. About this task In HPE Ezmeral Unified Analytics Software , whylogs is integrated to work with Livy\n                sessions submitted through Kubeflow notebooks using the %manage_spark magic function. You can use whylogs with Spark to\n                profile, visualize, and monitor the data and detect. To use whylogs with Spark, refer to Data Validation example and WhyLogs Profiling example in GitHub. The basic steps are outlined as\n                    follows: Create a notebook or import your notebook into HPE Ezmeral Unified Analytics Software . See Creating and Managing Notebook Servers . Enter the %manage_spark command in your notebook and\n                        configure your Spark session through different tabs. You must select the\n                        authentication as Single Sign-On and the runtime language as Python. To\n                        learn about creating sessions by using %manage_spark , see %manage_spark . Enter the %config_spark magic in your notebook and update\n                        the value of spark.kubernetes.container.image property to gcr.io/mapr-252711/spark-3.5.0:202401221805R .\n                        Click Submit when done. To learn about using %config_spark , see %config_spark . Verify that your created session is in the Idle state. You can verify by clicking the Manage Sessions tab or by navigating to the Spark Interactive\n                            Sessions screen. See Managing Interactive Sessions . Once the session is in the Idle state, you can set\n                        the environment variables and import the required libraries and modules from\n                        whylogs. Create data frames to profile the data or validate the data with whylogs and\n                        run the notebook. Once you finish running your notebook, navigate back to the HPE Ezmeral Unified Analytics Software home screen. In the left navigation bar, go to Data Engineering > Data\n                            Sources . Click Browse . Go to the /shared/<spark-whylogs> folder which is a path\n                        set in your notebook to store the logs from whylogs. You can see that the\n                        data pro\ufb01les and the drift summary report are stored in the shared volume in\n                        the .html and .bin formats. To download a summary report, select Download from\n                        the Actions menu. Results You can analyze the summary report to detect drifts and monitor your data. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Spark/spark-whylogs-integration.html",
        "title": "Using whylogs with Spark"
    },
    {
        "content": "\nData Science Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Data scientists can use programming languages such as Python, R, Java, and SQL to build,\n      train, and deploy machine learning models in HPE Ezmeral Unified Analytics Software using open-source tools that optimize the performance of\n      predictive machine learning models. Data scientists can use the tools provided in HPE Ezmeral Unified Analytics Software to: Perform exploratory data analysis in Notebooks. Build features or labels from the data. Create and train models in Notebooks or Pipelines and training frameworks like\n          TensorFlow, Ray, or PyTorch. Create and run pipelines based on variable conditions for repetitive tasks. Run jobs across the distributed clusters or cloud burst (launch) the jobs into a\n          separate cloud environment using APIs from Kubeflow. Select your model and hyperparameters for your model to run AutoML jobs by using Katib\n          and MLflow. Compile the models into a container and enter the container into the registry to make it\n          available for model serving as a part of KServe. Query pipelines for data drift, bias, and robustness. Evaluate models and replace the previous models for optimization or retrain and deploy\n          the models for better performance. Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/DataScience/data-science.html",
        "title": "Data Science"
    },
    {
        "content": "\nFeast Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Feast is a feature store that configures data infrastructure for serving machine learning\n      features and operationalizing a machine learning model. Feast tracks and defines feature\n      metadata and enables the reusing and sharing of features across multiple teams. To learn more,\n      see Feast . You can interact with Feast by using the Kubeflow notebooks. To access Feast in HPE Ezmeral Unified Analytics Software , click the Tools & Frameworks icon on\n      the left navigation bar. Navigate to the Feast tile under the Data Science tab and click Open . The mount path for Feast is /mnt/shared/feast-store . To see the files in feast-store folder, click Data Engineering \u2192\n        Data Sources on the left navigation bar. Click Browse and\n      then go to shared/feast-store folder. More information Feast Ride Sharing Use Case Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Feast/feast.html",
        "title": "Feast"
    },
    {
        "content": "\nKubeflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . Kubeflow Sizing Describes the resource allocation for different Kubeflow components. Enabling GPU Support on Kubeflow Kserve Model Serving Describes how to enable GPU support on Kubeflow Kserve model serving         instance. HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . Kubeflow is the platform to develop and deploy machine learning (ML) workflows using Kubeflow\n                        components. You can create Kubeflow pipelines, manage Katib experiments, and\n                        serve ML model using Kubeflow in a fully managed and secured unified\n                        environment provided by HPE Ezmeral Unified Analytics Software . Features and Functionality Kubeflow in HPE Ezmeral Unified Analytics Software supports the following features and\n                                functionality: Provides a seamless SSO login experience for authorization and\n                                        authentication. A default notebook is created with tensorflow image by using\n                                        Kubeflow Notebooks. See Creating and Managing Notebook Servers . A default user volume is created in Kubeflow notebooks where\n                                        only the current user has access to the data stored in the user folder. Kubeflow notebooks contains shared directory\n                                        with all the notebook examples that can be accessed by all\n                                        the authorized users. Kubeflow Components The following are Kubeflow components: Central\n                                                  Dashboard Kubeflow\n                                                  Notebooks Kubeflow\n                                                  Pipelines Katib Training\n                                                  Operators To learn more, see Kubeflow\n                                documentation . Kubeflow Sizing Describes the resource allocation for different Kubeflow components. Enabling GPU Support on Kubeflow Kserve Model Serving Describes how to enable GPU support on Kubeflow Kserve model serving         instance. More information Financial Time Series Workflow MNIST Digits Recognition Workflow On this page Features and Functionality Kubeflow Components Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Kubeflow/kubeflow.html",
        "title": "Kubeflow"
    },
    {
        "content": "\nKubeflow Sizing Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . Kubeflow Sizing Describes the resource allocation for different Kubeflow components. Enabling GPU Support on Kubeflow Kserve Model Serving Describes how to enable GPU support on Kubeflow Kserve model serving         instance. HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Kubeflow Sizing Describes the resource allocation for different Kubeflow components. Kubeflow sets default resource usage for each workload and component. You can customize the\n      values for resource consumption for Katib experiments, model serving, and Kubeflow pipelines\n      using the YAML file before applying the YAML file to a cluster. You can customize the resource\n      consumption values for the Notebook while creating a Notebook in the Kubeflow UI. Katib Experiments Katib experiments create a pod for each trial, and allocates the following\n                resources: vCPU: 50m Memory: 10Mi Model Serving Model serving creates a serving pod for each model, and allocates the following\n                resources: vCPU: 100m Memory: 128Mi Kubeflow Pipeline Kubeflow Pipeline creates a workload pod for each step, and allocates the following\n                resources: vCPU: 1 Memory: 1Gi Notebook The default notebook is allocated with the following resources: vCPU: 1 Memory: 2Gi When you create a new notebook, the following resources will be allocated by\n                default: vCPU: 0.5 Memory: 1Gi However, you can change the value of these resources during the notebook creation\n              step in the Kubeflow UI. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Kubeflow/kubeflow-sizing.html",
        "title": "Kubeflow Sizing"
    },
    {
        "content": "\nEnabling GPU Support on Kubeflow Kserve Model Serving Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . Kubeflow Sizing Describes the resource allocation for different Kubeflow components. Enabling GPU Support on Kubeflow Kserve Model Serving Describes how to enable GPU support on Kubeflow Kserve model serving         instance. HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Enabling GPU Support on Kubeflow Kserve Model Serving Describes how to enable GPU support on Kubeflow Kserve model serving\n        instance. Prerequisites Sign in to HPE Ezmeral Unified Analytics Software . Train and save a model using the PyTorch CUDA or Tensorflow CUDA libraries. About this task To enable GPU support for Kubeflow Kserve model serving instance in HPE Ezmeral Unified Analytics Software , follow these steps: Procedure Click the Applications & Frameworks icon on the left\n                    navigation bar. Navigate to the Kubeflow tile under the Data Science tab and click Open . Click Endpoints on the left side menubar of the Kubeflow Central Dashboard . Click the + New Endpoint button or click on your saved\n                    model. Create or update the InferenceService yaml manifest and set storageURI and the corresponding type of predictor (tensorflow or pytorch). To enable GPU, set the resources.limits section of the yaml as\n                    follows: For example: apiVersion: \"serving.kserve.io/v1beta1\"\nkind: \"InferenceService\"\nmetadata:\n  name: \"tensorflow-gpu\"\n  namespace: \"<user-name>\"\nspec:\n  predictor:\n    serviceAccountName: <service-account-name>\n    tensorflow:\n      storageUri: \"s3://mlflow/4/4d60878e34a947b080a6015ae297aaca/artifacts\"\n      resources:\n        limits:\n          nvidia.com/gpu: 1 NOTE With MIG configuration, only one GPU can be assigned per application.\n                            For details, see GPU Support . Results The GPU is now enabled on Kubeflow Kserve model serving instance. More information GPU Support Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Kubeflow/enable-gpu-on-kserve-model-serving-instance.html",
        "title": "Enabling GPU Support on Kubeflow Kserve Model Serving"
    },
    {
        "content": "\nHPE Machine Learning Development Environment Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . HPE MLDE User Authentication Describes the methods of user authentication in HPE Machine Learning Development Environment . Enabling HPE MLDE in an Air-Gapped Environment Describes how to enable HPE MLDE in an air-gapped     (disconnected) environment. Configuring HPE MLDE for Added GPU Nodes Describes how to configure HPE MLDE for added GPU nodes     in a cluster. MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment is a machine learning platform that offers features\n      such as automated hyperparameter tuning, distributed training and scaling of computations\n      across multiple GPUs, ensuring faster model training times. HPE MLDE supports various deep learning frameworks, enabling\n      you to work with tools such as TensorFlow and PyTorch. It enables efficient model training and\n      deployment, optimizing machine learning workflow. To learn more, see HPE\n        MLDE . To access HPE MLDE in HPE Ezmeral Unified Analytics Software , click the Tools &\n        Frameworks icon on the left navigation bar. Navigate to the HPE MLDE tile under the Data Science tab\n      and click Open . HPE MLDE User Authentication Describes the methods of user authentication in HPE Machine Learning Development Environment . Enabling HPE MLDE in an Air-Gapped Environment Describes how to enable HPE MLDE in an air-gapped     (disconnected) environment. Configuring HPE MLDE for Added GPU Nodes Describes how to configure HPE MLDE for added GPU nodes     in a cluster. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/MLDE/mlde.html",
        "title": "HPE Machine Learning Development Environment"
    },
    {
        "content": "\nHPE MLDE User Authentication Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . HPE MLDE User Authentication Describes the methods of user authentication in HPE Machine Learning Development Environment . Enabling HPE MLDE in an Air-Gapped Environment Describes how to enable HPE MLDE in an air-gapped     (disconnected) environment. Configuring HPE MLDE for Added GPU Nodes Describes how to configure HPE MLDE for added GPU nodes     in a cluster. MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. HPE MLDE User Authentication Describes the methods of user authentication in HPE Machine Learning Development Environment . In HPE MLDE , there are two methods of authentication: Authentication with SSO via Keycloak Authentication with Built-in User Profiles Authentication with SSO via Keycloak HPE recommends signing in to HPE MLDE with SSO by using the Keycloak button.You can sign in by\n        using your Unified Analytics account via SSO. If you sign in with your Unified Analytics Administrator account, you\n        will have the ClusterAdmin role in HPE MLDE . If you sign in with your Unified Analytics Member account, you will\n        have the WorkspaceCreator role in HPE MLDE . NOTE If your username is admin or determined, you cannot sign in to HPE MLDE with SSO by using the Keycloak button. In this scenario,\n          you must sign in with built-in user profiles by manually entering your username and\n          password. Authentication with Built-in User Profiles You can sign in to HPE MLDE by using one of the two built-in\n        user profiles called admin and determined . To locate the password for built-in profiles, follow these steps: Sign in to HPE Ezmeral Unified Analytics Software as an Administrator. Click the Tools & Frameworks icon on the left navigation\n            bar. Navigate to the HPE MLDE tile under the Data Science tab. On the HPE MLDE tile, click the three-dots button. Select Configure to open the editor. The password is available as a value for defaultPassword . On this page Authentication with SSO via Keycloak Authentication with Built-in User Profiles Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/MLDE/mlde-user-auth.html",
        "title": "HPE MLDE User Authentication"
    },
    {
        "content": "\nEnabling HPE MLDE in an Air-Gapped Environment Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . HPE MLDE User Authentication Describes the methods of user authentication in HPE Machine Learning Development Environment . Enabling HPE MLDE in an Air-Gapped Environment Describes how to enable HPE MLDE in an air-gapped     (disconnected) environment. Configuring HPE MLDE for Added GPU Nodes Describes how to configure HPE MLDE for added GPU nodes     in a cluster. MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Enabling HPE MLDE in an Air-Gapped Environment Describes how to enable HPE MLDE in an air-gapped\n    (disconnected) environment. In HPE Ezmeral Unified Analytics Software , HPE MLDE is\n      disabled (deployment is scaled to zero) by default in an air-gapped environment. To enable HPE MLDE in an air-gapped environment, follow these\n        steps: Sign in to HPE Ezmeral Unified Analytics Software as an Administrator. Contact HPE support to get the HPE MLDE master enterprise\n          image. Upload the HPE MLDE master enterprise image to the airgap\n          registry. See Using the Air Gap Utility . Click the Tools & Frameworks icon on the left navigation\n          bar. Navigate to the HPE MLDE tile under the Data Science tab. On the HPE MLDE tile, click the three-dots button. Select Configure to open the editor. Add prefix for the imageRegistry option. Set replicas to 1 under the ezua.masterDeployment.replicas option. If your airgap registry differs from the one configured for Unified Analytics and needs authentication, you can provide credentials in\n          the base64 encoded format. Set dockerconfigjson_b64enc option under the ezua.masterDeployment.imagePullSecret property. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/MLDE/enable-mlde-in-air-gap-env.html",
        "title": "Enabling HPE MLDE in an Air-Gapped Environment"
    },
    {
        "content": "\nConfiguring HPE MLDE for Added GPU Nodes Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . HPE MLDE User Authentication Describes the methods of user authentication in HPE Machine Learning Development Environment . Enabling HPE MLDE in an Air-Gapped Environment Describes how to enable HPE MLDE in an air-gapped     (disconnected) environment. Configuring HPE MLDE for Added GPU Nodes Describes how to configure HPE MLDE for added GPU nodes     in a cluster. MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Configuring HPE MLDE for Added GPU Nodes Describes how to configure HPE MLDE for added GPU nodes\n    in a cluster. If you add GPU nodes to the cluster after installing HPE MLDE ,\n      you must perform the following steps to ensure HPE MLDE works\n      on these nodes. Sign in to HPE Ezmeral Unified Analytics Software as an Administrator. To determine the maximum number of GPUs per node in the cluster, run the following\n          command in the shell with a configured\n          kubeconfig. kubectl get nodes -l nvidia.com/gpu.count -o json | jq '.items |\n            map(select(.status.capacity.\"nvidia.com/gpu\") | .status.capacity.\"nvidia.com/gpu\" | tonumber) | max // 0' Click the Tools & Frameworks icon on the left navigation\n          bar. Navigate to the HPE MLDE tile under the Data Science tab. On the HPE MLDE tile, click the three-dots button. Select Configure to open the editor. Set maxSlotsPerPod to the maximum number of GPUs per node in the\n          cluster. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/MLDE/configure-mlde-for-added-gpu-nodes.html",
        "title": "Configuring HPE MLDE for Added GPU Nodes"
    },
    {
        "content": "\nMLflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Defining RBACs on MLflow Experiments Describes role-based access controls (RBACs) with respect to MLflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to experiments in MLflow. Using whylogs with MLflow Describes how to use whylogs with MLflow. Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . MLflow is an open-source platform that manages the end-to-end machine learning lifecycle,\n      including experimentation, reproducibility, deployment, and a central model registry. You can\n      train your ML model and run ML experiments in a fully managed and secured unified environment\n      provided by HPE Ezmeral Unified Analytics Software . To\n      learn more, see open-source MLflow documentation . The model management framework with MLflow integration in HPE Ezmeral Unified Analytics Software is offered with the\n      following capabilities. Notebook Integration Build and Train ML models using MLFlow APIs with an underlying tracking server. Experiment Tracking Track experiments and compare the output parameters for various runs. MLflow Models Enables users to log all parameters, save artifacts, load models, and deploy\n            models. Model Artifacts Log params and save model artifacts to HPE Ezmeral Data Fabric Object Store . MLflow Registry A centralized model store, set of APIs, and UI, to collaboratively manage the full\n              lifecycle of an MLflow Model. Exploring MLflow in HPE Ezmeral Unified Analytics Software HPE Ezmeral Unified Analytics Software includes\n        sample files and data that you can access through the notebook server instance. To access the sample files in your notebook server instance: Sign in to HPE Ezmeral Unified Analytics Software . In the left navigation pane, click Notebooks . Connect to your notebook server instance. To access the sample files, navigate to the mlflow folder in the /<username> directory. TIP If the /user directory does not contain\n              the sample files, copy the sample files from the /shared/mlflow folder to the /username directory. The /shared directory is accessible to\n              all users. Editing or running examples from the /shared directory is\n              not advised. The /username directory is specific to you and cannot be accessed by other\n              users. Defining RBACs on MLflow Experiments Describes role-based access controls (RBACs) with respect to MLflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to experiments in MLflow. Using whylogs with MLflow Describes how to use whylogs with MLflow. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/MLflow/mlflow.html",
        "title": "MLflow"
    },
    {
        "content": "\nDefining RBACs on MLflow Experiments Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Defining RBACs on MLflow Experiments Describes role-based access controls (RBACs) with respect to MLflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to experiments in MLflow. Using whylogs with MLflow Describes how to use whylogs with MLflow. Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Defining RBACs on MLflow Experiments Describes role-based access controls (RBACs) with respect to MLflow in HPE Ezmeral Unified Analytics Software and how to define RBACs\n    to permit access to experiments in MLflow. Role-based access controls (RBACs) are an authorization system based on policies, user roles,\n      and bindings between the roles and policies that protect resources. With the introduction of\n      RBACs, HPE Ezmeral Unified Analytics Software users\n      (admins and members) can define access controls on their experiments through the MLflow API or\n      SDK. User access to MLflow is granted when a user makes a request to the MLflow server. A user is\n      automatically authenticated and granted access to MLflow based on their user role in HPE Ezmeral Unified Analytics Software , as either an admin or\n      a member. Admins can add users through the HPE Ezmeral Unified Analytics Software UI, as described in Adding and Removing Users and User Roles . Admin Role The following list describes admin access and the admin-related tasks that\n      impact users in MLflow: Admins can view and edit all experiments in MLflow regardless of the access controls\n          set. For example, if the NO_PERMISSIONS access control is defined in an\n          experiment, admins can still access the experiment. Admins can change a user's role in HPE Ezmeral Unified Analytics Software to admin . When a user has the admin role in HPE Ezmeral Unified Analytics Software , that user\n          can access all existing experiments in MLflow. If the admin role is removed from\n          the user (reverted back to member ), the user cannot see any experiments created by\n          other users. NOTE By default, the MLflow default admin user is disabled to prevent any\n            security issues, such as the plain text password being stored in open-source\n            code. Member Role The following list describes MLflow access for members : By default, members have full control over the experiments they create. When a member\n          creates an experiment, the experiment has the MANAGE permission set. The MANAGE permission enables the experiment owner to grant other users\n          access to their experiment through access controls. Members cannot access experiments created by other users unless explicitly permitted to\n          do so by the experiment owner through access controls set in the expermiment. If an HPE Ezmeral Unified Analytics Software admin changes a member's role to admin in the HPE Ezmeral Unified Analytics Software UI, the user is granted full access to all\n          experiments in MLflow. CAUTION HPE only supports user role changes made through the HPE Ezmeral Unified Analytics Software UI. Role changes made\n        in HPE Ezmeral Unified Analytics Software are\n        automatically propagated to MLflow. HPE does not support role changes made directly in\n        MLflow because the changes do not propagate back to HPE Ezmeral Unified Analytics Software , which can cause unexpected system behaviors. Supported Access Controls HPE Ezmeral Unified Analytics Software supports the\n        following access controls on experiments: Access Control Type Access Control Value Description None NO_PERMISSIONS Only the experiment creator and admins can access the experiment. Returns an\n                  \"access denied\" message when unauthorized users try to access the\n                  experiment. Manage MANAGE Default permission set on an experiment at the time of creation. Only the\n                  experiment creator and admins can access the experiment. You cannot set this\n                  access control on any existing experiments. Read READ The experiment creator has full access to the experiment. Specified users can\n                  only view the experiment in MLflow. Modify EDIT Experiment creator has full access to the experiment. Specified users modify\n                  the experiment in MLflow. Delete DELETE Only admin users can use DELETE to remove permissions on an\n                  experiment. Defining Access Controls on Users To permit access to experiments, use the MLflow API or SDK in your MLflow experiments to\n        define access controls on users. MLflow provides an AuthServiceClient that implements CRUD functionality\n        for experiment_permission and model_permission objects. Use the following code examples as a guide to define access controls on users. Required code to set access controls on an experiment from mlflow.server.auth.client import AuthServiceClient\nuser = \"<username>\"\npermission = \"<access_control>\"\nexp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\nclient = AuthServiceClient(\"http://mlflow.mlflow.svc.cluster.local:5000\") Create permission permission = \"READ\"\nexp_permission = client.create_experiment_permission(exp_id, user, permission) Modify permission permission = \"EDIT\"\nexp_permission = client.update_experiment_permission(exp_id, user, permission)\n\npermission = \"NO_PERMISSIONS\"\nexp_permission = client.update_experiment_permission(exp_id, user, permission) Delete permission exp_permission = client.delete_experiment_permission(exp_id, user, permission)\nclient.get_user( 'admin' ) On this page Supported Access Controls Defining Access Controls on Users Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/MLflow/rbac-mlflow.html",
        "title": "Defining RBACs on MLflow Experiments"
    },
    {
        "content": "\nUsing whylogs with MLflow Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Defining RBACs on MLflow Experiments Describes role-based access controls (RBACs) with respect to MLflow in HPE Ezmeral Unified Analytics Software and how to define RBACs     to permit access to experiments in MLflow. Using whylogs with MLflow Describes how to use whylogs with MLflow. Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using whylogs with MLflow Describes how to use whylogs with MLflow. Prerequisites Sign in to HPE Ezmeral Unified Analytics Software as a\n      member. About this task In HPE Ezmeral Unified Analytics Software , whylogs is integrated with MLflow to log and\n        analyze the data quality. You can use whylogs to analyze the data quality throughout the\n        machine learning lifecycle. To use whylogs with MLflow, refer to MLflow logging example in the GitHub. The basic steps are outlined as\n          follows: Create a notebook or import the notebook into HPE Ezmeral Unified Analytics Software .\n            See Creating and Managing Notebook Servers . Import the required libraries and modules from whylogs. Train a model and create data frames to profile the data, and then run the\n            notebook. Once you finish running your notebook, navigate back to the HPE Ezmeral Unified Analytics Software home screen. Click the Tools & Frameworks icon on the left navigation\n            bar. Navigate to the MLflow tile under the Data\n              Science tab and click Open . View the whylogs output in the whylogs directory within that run\u2019s\n            artifacts in the MLflow UI. Results You can analyze the data quality metrics and ensure the data quality by using whylogs\n        ouput. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/MLflow/mlflow-whylogs-integration.html",
        "title": "Using whylogs with MLflow"
    },
    {
        "content": "\nRay Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Ray is a unified framework for scaling AI/ML and Python applications, handling distributed\n      workloads, and parallelizing serial applications. As a distributed computing framework, Ray\n      simplifies scalability and fault tolerance. Ray offers flexible programming for parallel tasks\n      and actors, making it suitable for data processing, reinforcement learning, and\n      simulation. To learn about API changes for Ray 2.0, see Ray\n        2.0 Migration Guide . Ray Core Ray Core provides core primitives to build and scale distributed applications. The\n              core primitives are: Tasks Actors Objects Purpose Simplify development by providing high-level abstractions and automatic\n                  management of complex distributed systems. Accelerate the development process by reducing the complexity of building\n                  distributed systems. Use Cases Data Processing: Efficiently handle large-scale data processing tasks. Reinforcement Learning: Scale RL experiments across multiple machines for faster\n                  learning. High-Performance Computing: Parallelize complex computations for faster\n                  execution in HPC scenarios. Event-driven and Real-time Systems: Process events or data streams in parallel\n                  for timely processing. Features and Functionality Ray in HPE Ezmeral Unified Analytics Software supports the following features and functionality: Ray Cluster Reconciliation HPE Ezmeral Unified Analytics Software provides an automatic Ray cluster reconciliation feature using Helm hooks. When you upgrade Ray in HPE Ezmeral Unified Analytics Software , all Ray workloads, including head nodes, workgroup nodes,\n                small group nodes, and computational resources such as CRDs, config maps, services,\n                and others are managed autonomously. The Ray cluster reconciliation feature improves the user experience for AI\n                application development. Notebook Integration A pre-existing image is created in Kubeflow notebooks with Ray library. See Creating and Managing Notebook Servers . To submit jobs using Ray, you can connect to Ray cluster. See Connecting to Ray Cluster . Ray Dashboard Ray dashboard in HPE Ezmeral Unified Analytics Software allows you to: Understand Ray memory utilization and debug memory errors. See per-actor resource usage, executed tasks, logs, and more. View cluster metrics. Kill actors and profile your Ray jobs. See errors and exceptions at a glance. View logs across many machines in a single pane. See Ray Tune jobs and trial information. To access Ray dashboard, click the Applications &\n                  Frameworks icon on the left navigation bar. Navigate to the Ray tile under the Data Science tab\n                and click Open . To enable Metrics view in Ray dashboard, see Enabling Metrics in Ray Dashboard . Security To configure Ray to use TLS authentication for client-server communication, see TLS Authentication . To learn more about Ray, see Ray documentation . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. On this page Features and Functionality Security Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/ray.html",
        "title": "Ray"
    },
    {
        "content": "\nConnecting to Ray Cluster Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. NOTE The Ray Client has multithreading and connection issues which impact its reliability and\n        submitting Ray job using Ray Client is an outdated method. Hewlett Packard Enterprise recommends using JobSubmissionClient to submit Ray jobs. For details, see Using JobSubmissionClient to Submit Ray Jobs . To submit jobs using Ray, you can connect to Ray cluster in two different ways: Connecting to Ray in HPE Ezmeral Unified Analytics Software To connect to Ray in HPE Ezmeral Unified Analytics Software ,\n              run: ray.init(address=\"ray://kuberay-head-svc.kuberay:10001\") Connecting to Ray from outside of HPE Ezmeral Unified Analytics Software To connect to Ray cluster from outside of HPE Ezmeral Unified Analytics Software , perform the following steps: Change service type to\n                  NodePort. > kubectl -n kuberay edit service kuberay-head-svc\nspec:\n...\n  type: NodePort\n... Get cluster master IP. > kubectl cluster-info Get client\n                  port. > kubectl -n kuberay describe service kuberay-head-svc\n... \nPort:                     client  10001/TCP\nTargetPort:               10001/TCP\nNodePort:                 client  31536/TCP\nEndpoints:                10.244.1.85:10001 Connect through <K8 Master IP>:<Client\n                  Port> . ray.init(address=\"ray://<K8 Master IP>:31536\") Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/connecting-to-ray-cluster.html",
        "title": "Connecting to Ray Cluster"
    },
    {
        "content": "\nUsing JobSubmissionClient to Submit Ray Jobs Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . The Ray Client has multithreading and connection issues which impact its reliability and\n      submitting Ray job using Ray Client is an outdated method. Hewlett Packard Enterprise recommends using JobSubmissionClient to\n      submit Ray jobs. To submit Ray jobs using JobSubmissionClient , you must specify entry point\n      resources as follows: For CPU, set entrypoint_num_cpus to 1 or <M> For GPU, set entrypoint_num_gpus to 1 or <M> NOTE The failure to specify entry point resources before submitting any jobs in the Ray\n        cluster results in an unexpected behavior. To learn how to submit Ray jobs using JobSubmissionClient , see News Recommendation System . Example: The following code block shows the sample code for connecting to the Ray cluster and\n      submitting Ray Jobs using JobSubmissionClient : import ray\nfrom ray.job_submission import JobSubmissionClient\nimport time\n\n# Ray cluster information\nray_head_ip = \"kuberay-head-svc.kuberay.svc.cluster.local\"\nray_head_port = 8265\nray_address = f\"http://{ray_head_ip}:{ray_head_port}\"\n\n# Submit Ray job using JobSubmissionClient\nclient = JobSubmissionClient(ray_address)\njob_id = client.submit_job(\n    entrypoint=\"python demo.py\",\n    runtime_env={\n        \"working_dir\": \"./\",\n        # \"excludes\": ['']\n    },\n    entrypoint_num_cpus = 3\n)\n\nprint(client.__dict__)\nprint(f\"Ray job submitted with job_id: {job_id}\") Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/using-ray-JobSubmissionClient.html",
        "title": "Using JobSubmissionClient to Submit Ray Jobs"
    },
    {
        "content": "\nEnabling Metrics in Ray Dashboard Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Prerequisites Ensure that Ray's head pod has enough resources to run the\n            Grafana server. About this task To enable Metrics view in dashboard, you must install Grafana, configure the data\n                source as centralized Prometheus, and start the Grafana server with the specific\n                configuration file in Ray's head pod. Procedure By default Ray\u2019s metrics are scraped by centralized Prometheus, so specify\n                    Prometheus\u2019 service URL as the data source in /tmp/ray/session_latest/metrics/grafana/provisioning/datasources/default.yml file. For example: apiVersion: 1\n\ndatasources:\n  - name: Prometheus\n    url: http://af-prometheus-kube-prometh-prometheus.prometheus.svc.cluster.local:9090\n    type: prometheus\n    isDefault: true\n    access: proxy Install Grafana in Ray's head pod and navigate to Grafana's home\n                    directory. To install Grafana in Ray\u2019s head pod, follow these steps: Access the shell on the head node. kubectl -n kuberay exec -it <head_pod_name> -- bash Download Grafana. wget https://dl.grafana.com/oss/release/grafana-9.3.6.linux-amd64.tar.gz Go to the Grafana home directory. tar -zxvf grafana-9.3.6.linux-amd64.tar.gz \ncd grafana-9.3.6 Start the Grafana server with the Ray configuration file. ./bin/grafana-server --config /tmp/ray/session_latest/metrics/grafana/grafana.ini web Forward Grafana's default port. kubectl -n kuberay port-forward --address 0.0.0.0 <head_pod_name> 3000:3000 Click the Applications & Frameworks icon on the left\n                    navigation bar. Navigate to the Ray tile under the Data Science tab and click Open . Results Metrics view is enabled in the Ray dashboard. To learn more, see Ray Metrics . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/enabling-metrics-in-ray-dashboard.html",
        "title": "Enabling Metrics in Ray Dashboard"
    },
    {
        "content": "\nResource Configuration and Management Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Resource Configuration and Management Describes resource configuration and management for Ray. Resource Configuration In HPE Ezmeral Unified Analytics Software , a Ray\n        cluster is deployed using KubeRay Operator. Currently, the Ray cluster consists of a single head node and a single worker node.\n        Auto-scaling is enabled by default for worker nodes, the Ray cluster automatically scales up\n        and down based on resource demand. When there is no workload, the Ray cluster has a head, and a worker node as\n        follows: > kubectl -n kuberay get pod\nNAME                                          READY   STATUS    RESTARTS   AGE\nkuberay-operator-6c75647d8b-7mpqp             1/1     Running   0          22h\nray-cluster-kuberay-head-gw8lc                2/2     Running   0          22h When a submitted job demands more resources than the cluster current resources, then the\n        auto scaler will create two more pods as follows: Auto-scaling is enabled by default configuration so that the Ray cluster creates two more\n        worker pods when needed. If a pod stays idle for 60 seconds, then the auto scaler destroys\n        it. Upper resource limits for pods type are as follows: Head pod: 2 CPU and 8 GB memory. Worker pod: 3 CPU and 8 GB memory. Resource Management While running a heavy workload, you might get an Out of Memory exception. To avoid the\n        out-of-memory exception, there are two best practices: Memory Aware Scheduling By default, Ray does not consider the potential memory usage of a task or an actor\n                when scheduling as it cannot estimate beforehand how much memory is required by the\n                task or actor. However, if you know how much memory a task or an actor might\n                require, you can specify it in the resource requirements of ray.remote decorator to enable memory-aware scheduling. For example: # reserve 500MiB of available memory to place this task \n@ray.remote(memory=500 * 1024 * 1024) \ndef some_function(x): \n  pass # reserve 2.5GiB of available memory to place this actor\n\n@ray.remote(memory=2500 * 1024 * 1024) \nclass SomeActor(object): \n   def __init__(self, a, b): \n    pass Scheduling Strategies There are two scheduling strategies in Ray: Default Ray uses DEFAULT as the default strategy. Currently, Ray\n                        assigns tasks or actors on nodes until the resource utilization is beyond a\n                        certain threshold and spreads them afterward. For example: @ray.remote \ndef func(): \n  return 1 Spread Ray uses SPREAD strategy to spread tasks or actors among\n                        available nodes. For example: @ray.remote(scheduling_strategy=\"SPREAD\") \ndef spread_func(): \n  return 2 To learn more see Scheduling Strategies . On this page Resource Configuration Resource Management Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/ray-resource-config-and-management.html",
        "title": "Resource Configuration and Management"
    },
    {
        "content": "\nGPU Support for Ray Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for\n    Ray. Sign in as Administrator to HPE Ezmeral Unified Analytics Software to enable GPU to submit\n      GPU-accelerated jobs with Ray. You can enable GPU support for Ray in two different ways: Enabling GPU support during HPE Ezmeral Unified Analytics Software installation. Enabling GPU support after HPE Ezmeral Unified Analytics Software installation. Enabling GPU Support During HPE Ezmeral Unified Analytics Software Installation To enable the GPU for Ray during the HPE Ezmeral Unified Analytics Software installation,\n        see GPU Support . If you enabled GPU during the platform installation, you do not need to separately enable\n        GPU for Ray. The platform installation automatically enables GPU for all applications and\n        frameworks including Ray. Enabling GPU Support and Configuring Resources After HPE Ezmeral Unified Analytics Software Installation Before enabling the GPU support, when Ray is in an idle state, there are the following\n        three pods running: > kubectl -n kuberay get pod\nNAME                                READY   STATUS    RESTARTS   AGE\nkuberay-head-5c2jj                  2/2     Running   0          10m\nkuberay-operator-7b976fdb86-x5k4c   1/1     Running   0          10m\nkuberay-worker-smallgroup-xhhbq     1/1     Running   0          10m The operator pod creates the head pod and monitors the cluster. The head pod is the cluster\n        master and generates additional small worker pods as required. To enable GPU support for Ray after HPE Ezmeral Unified Analytics Software installation,\n        follow these steps: Click the Applications & Frameworks icon on the left\n          navigation bar. Navigate to the Ray tile under the Data\n            Science tab. Click the three dots menu on the Ray tile and click Configure . Set the value of gpu.enabled to true . (Optional) Modify the available resources as required by updating the values within the resources_gpu section. NOTE With MIG configuration, only one GPU can be assigned per application. To learn\n              more on what happens when you assign more than one GPU to the Ray cluster, see GPU . For details regarding GPU, see GPU Support . Click Configure . Results: The GPU is now enabled on Ray. After enabling GPU, Ray creates more pods as\n        follows: > kubectl -n kuberay get pod\nNAME                                READY   STATUS    RESTARTS   AGE\nkuberay-head-5c2jj                  2/2     Running   0          10m\nkuberay-operator-7b976fdb86-x5k4c   1/1     Running   0          10m\nkuberay-worker-smallgroup-xhhbq     1/1     Running   0          10m kuberay-worker-workergroup-rdptj    1/1     Running   0          13s #New pod with GPU resources! You\n        can also see the new pod with GPU resources on Ray Dashboard. Unlike the worker-smallgroup pod, the worker-workergroup pod cannot be scaled using an autoscaler. When GPU-accelerated jobs are submitted, the worker-workergroup pod handles the workload. Simultaneously, Ray manages\n        regular jobs by using the worker-smallgroup pod. Submitting GPU-Accelerated Jobs to Ray Cluster To submit the GPU-accelerated jobs, specify the following resource\n        requirements: @ray.remote(num_gpus=1)\ndef use_gpu():\n    print(\"ray.get_gpu_ids(): {}\".format(ray.get_gpu_ids()))\n    print(\"CUDA_VISIBLE_DEVICES: {}\".format(os.environ[\"CUDA_VISIBLE_DEVICES\"])) The function use_gpu does not use any GPUs directly. Instead, Ray\n        schedules it on a node with at least one GPU and allocates one GPU specifically for its run.\n        However, it is up to the function to utilize the GPU, which is typically done through an\n        external library such as TensorFlow. Ray example using GPUs: For this example to work, ensure you have installed GPU version of\n        TensorFlow. @ray.remote(num_gpus=1)\ndef use_gpu():\n    import tensorflow as tf\n \n    # Create a TensorFlow session. TensorFlow will restrict itself to use the\n    # GPUs specified by the CUDA_VISIBLE_DEVICES environment variable.\n    tf.Session() NOTE As Ray does not have the GPU-specific API, you must properly configure Ray jobs to run\n          on GPU. Without proper configuration, Ray jobs will run on CPUs. To learn more, see Using Ray with GPUs . Disabling GPU Support for Ray To disable GPU support for Ray after HPE Ezmeral Unified Analytics Software installation,\n        follow these steps: Click the Applications & Frameworks icon on the left\n            navigation bar. Navigate to the Ray tile under the Data Science tab. Click the three dots menu on the Ray tile and click Configure . Set the value of gpu.enabled to false . Click Configure . More information GPU Support On this page Enabling GPU Support During HPE Ezmeral Unified Analytics Software Installation Enabling GPU Support and Configuring Resources After HPE Ezmeral Unified Analytics Software Installation Submitting GPU-Accelerated Jobs to Ray Cluster Disabling GPU Support for Ray Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/ray-gpu-support.html",
        "title": "GPU Support for Ray"
    },
    {
        "content": "\nUsing whylogs with Ray Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Using whylogs with Ray Describes how to use whylogs with Ray. Prerequisites Sign in to HPE Ezmeral Unified Analytics Software as a\n            member. About this task In HPE Ezmeral Unified Analytics Software , whylogs is integrated to work with Ray in\n                a distributed environment. You can use whylogs with Ray for logging and analyzing\n                the distributed data or monitoring the ML models in a distributed environment. To use whylogs with Ray, refer to Ray example in the GitHub. The basic steps are outlined as\n                    follows: Create a notebook or import the notebook into HPE Ezmeral Unified Analytics Software . See Creating and Managing Notebook Servers . Import the required libraries and modules from whylogs. Use Ray for distributed data processing tasks. Log the data with whylogs and store the results. Once you finish running your notebook, navigate back to the HPE Ezmeral Unified Analytics Software home screen. In the left navigation bar, go to Data Engineering > Data\n                        Sources . Click Browse . Go to the /shared/<ray-whylogs> folder which is a path\n                        set in your notebook to store the logs from whylogs. You can see that the\n                        data pro\ufb01les and the drift summary report are stored in the shared volume in\n                        the .html and .bin formats. To download a summary report, select Download from the Actions\n                        menu. Results You can analyze the summary report to detect drifts and monitor your data in a\n                distributed environment. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/ray-whylogs-integration.html",
        "title": "Using whylogs with Ray"
    },
    {
        "content": "\nRay Best Practices Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Feast Provides a brief overview of Feast in HPE Ezmeral Unified Analytics Software . Kubeflow Provides a brief overview of Kubeflow in HPE Ezmeral Unified Analytics Software . HPE Machine Learning Development Environment Provides a brief overview of HPE Machine Learning Development Environment ( HPE MLDE ) in HPE Ezmeral Unified Analytics Software . MLflow Provides a brief overview of MLflow in HPE Ezmeral Unified Analytics Software . Ray Provides a brief overview of Ray in HPE Ezmeral Unified Analytics Software . Connecting to Ray Cluster Describes how to connect to Ray clusters to submit jobs. Using JobSubmissionClient to Submit Ray Jobs Describes how to connect to Ray cluster and submit Ray jobs using JobSubmissionClient . Enabling Metrics in Ray Dashboard Describes how to enable metrics in Ray dashboard. Resource Configuration and Management Describes resource configuration and management for Ray. GPU Support for Ray Describes how to enable GPU, configure the GPU resources, and disable GPU for     Ray. Using whylogs with Ray Describes how to use whylogs with Ray. Ray Best Practices Lists the best practices for Ray. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Ray Best Practices Lists the best practices for Ray. Stabilize the Head Pod In the Ray cluster, a head pod has a key role and therefore it should be stable. Hewlett Packard Enterprise recommends not scheduling any workload\n              on the head pod. The worker nodes handle all workloads in the default deployment of HPE Ezmeral Unified Analytics Software . To make the head pod stable, when creating the Ray cluster, set {\"num-cpus\": \"0\"} in \"rayStartParams\" of \"headGroupSpec\" such that the Ray scheduler skips the head node\n              when scheduling workloads. NOTE This is set by default in HPE Ezmeral Unified Analytics Software . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Ray/ray-best-practices.html",
        "title": "Ray Best Practices"
    },
    {
        "content": "\nNotebooks Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebooks are an interactive computational environment to develop and run your data science\n      applications. You can use Notebooks to run code snippets, view the results, and then save the\n      data in HPE Ezmeral Unified Analytics Software .\n      Notebook files are saved with a .ipynb extension. You can edit notebook files, change parameters, display the results, and document the\n      methodology, results, summary, and findings within the same file. You can run your commands, visualize data, and get outputs and results using the following\n      Kubeflow Notebook interfaces: JupyterLab RStudio Visual Studio Code Features and Functionality Kubeflow in HPE Ezmeral Unified Analytics Software supports the following features and functionality: All the actions are done as your logged-in user and not as the Jovyan user. The notebooks are integrated with the SDK (Feast, MLlflow, Kubeflow Pipelines, Katib,\n            Ray, EzPresto). Special data science notebook that includes common machine learning and data science\n            libraries. Ability to install new packages to the notebook at runtime or create a custom notebook\n            image. To experience notebooks in HPE Ezmeral Unified Analytics Software , refer to the following tutorials: Financial Time Series Workflow MNIST Digits Recognition Workflow Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/notebooks.html",
        "title": "Notebooks"
    },
    {
        "content": "\nNotebook Images Overview Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their\n    uses. Notebook images contain all the necessary software dependencies and configurations needed to\n      run machine learning workflows. By using notebook images, you can collaborate, share, and\n      deploy models with minimal compatibility issues. Image Format The images follow the following\n        format: <base-repository>/<image-name>:<image-tag> For\n          example: gcr.io/mapr-252711/kubeflow/notebooks/jupyter-scipy:ezaf-fy23-q4-sp4-r9 Here, base-repository: gcr.io/mapr-252711/kubeflow/notebooks image-name: jupyter-scipy image-tag: ezaf-fy23-q4-sp4-r9 Supported Notebook Images The following table describes the notebook images available in HPE Ezmeral Unified Analytics Software and their uses. Notebook Images Descriptions Uses gcr.io/mapr-252711/kubeflow/notebooks/jupyter-scipy:<image-tag> This image is packaged with data science packages, including Pandas for data\n                  manipulation, Matplotlib and Bokeh for advanced plotting, and statistical tools\n                  such as SciPy and Statsmodels. Use this image to perform data analysis, manipulation, and visualization that\n                  doesn\u2019t require machine learning libraries such as TensorFlow or PyTorch. gcr.io/mapr-252711/kubeflow/notebooks/jupyter-pytorch-full:<image-tag> This image is packaged with data science packages and is integrated with\n                  PyTorch machine learning libraries for CPU-based tasks. This image does not have\n                  GPU acceleration capability. Use this image to perform data analysis, manipulation, and visualization for\n                  CPU-based machine learning tasks using PyTorch library. gcr.io/mapr-252711/kubeflow/notebooks/jupyter-pytorch-cuda-full:<image-tag> This image is packaged with data science packages and is integrated with\n                  PyTorch machine learning libraries for GPU-based tasks. Use this image to perform data analysis, manipulation, and visualization for\n                  GPU-based machine learning tasks using PyTorch library for faster model training\n                  and data processing. gcr.io/mapr-252711/kubeflow/notebooks/jupyter-tensorflow-full:<image-tag> This image is packaged with data science packages and is integrated with\n                  TensorFlow machine learning libraries for CPU-based tasks. This image does not\n                  have GPU acceleration capability. Use this image to perform data analysis, manipulation, and visualization for\n                  CPU-based machine learning tasks using TensorFlow library. gcr.io/mapr-252711/kubeflow/notebooks/jupyter-tensorflow-cuda-full:<image-tag> This image is packaged with data science packages and is integrated with\n                  TensorFlow machine learning libraries for GPU-based tasks. Use this image to perform data analysis, manipulation, and visualization for\n                  GPU-based machine learning tasks using TensorFlow library for faster model\n                  training and data processing. gcr.io/mapr-252711/kubeflow/notebooks/jupyter-data-science:<image-tag> This image is integrated with Tensorflow and PyTorch packages, including\n                  various other tools for data analysis, machine learning, and\n                  visualization. Use this image that is integrated with data science libraries to perform data\n                  science tasks requiring deep learning capabilities of TensorFlow and\n                  PyTorch. gcr.io/mapr-252711/kubeflow/notebooks/codeserver:<image-tag> This image enables you to run Visual Studio Code in the browser where you can\n                    edit and develop code in a remote server setup. This image features a VS Code environment, providing a code-server that runs\n                    Visual Studio Code in the browser, allowing for rich code editing and\n                    development experience in a remote server setup. In HPE Ezmeral Unified Analytics Software , the codeserver image includes VS\n                    Code and Python installation, and VS Code Python extension. Use this image to run Visual Studio Code in the browser where you can edit and\n                    develop code in a remote server setup. Image and Package Support For a list of supported notebook images and included packages in HPE Ezmeral Unified Analytics Software , see Notebook Images . On this page Image Format Supported Notebook Images Image and Package Support Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/notebook-images-overview.html",
        "title": "Notebook Images Overview"
    },
    {
        "content": "\nCreating and Managing Notebook Servers Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Prerequisites Sign in to HPE Ezmeral Unified Analytics Software . About this task Create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Procedure Click Notebooks icon on the left navigation bar of HPE Ezmeral Unified Analytics Software screen. You are now in the Notebook Servers screen. You can\n                        see a default Jupyter notebook has been created with your username. A default notebook is created with tensorflow image by using Kubeflow\n                        Notebooks. To connect to a default Jupyter notebook (for example, <user-name-notebook> ), click <user-name-notebook> or select Connect . To create notebook servers, click New Notebook\n                                Server . You can choose JupyterLab or Visual Studio Code as your\n                            notebook server within Kubeflow Notebooks. To learn more, see Kubeflow Notebooks . When any notebook is created, the following three volumes are added\n                            automatically: <username> : This directory is mounted to\n                                user-pvc volume. Only the current user has access to the data stored\n                                in the <username> folder. shared : This directory can be accessed by all\n                                authorized users. shared directory contains all the\n                                notebook examples. datafabrics : This directory is mounted to HPE Ezmeral Data Fabric . You can run your commands, visualize data, and get outputs and results by\n                        using notebook servers. To view actions that you can perform on Notebook\n                        Servers screen, click the menu icon in\n                    the Actions column. Connect: To connect to notebook servers, select Connect . Delete: To delete the notebook server, select Delete . Delete multiple notebook servers at once: To select multiple notebook servers, click the check box besides Name in the table. Click Delete on the top right pane of the\n                            table. To display notebook servers according to the status, click Filter icon. To select the columns to display on your applications table, click Columns icon. More information Creating GPU-Enabled Notebook Servers Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/creating_and_managing_notebook_servers.html",
        "title": "Creating and Managing Notebook Servers"
    },
    {
        "content": "\nCreating GPU-Enabled Notebook Servers Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Prerequisites Sign in to HPE Ezmeral Unified Analytics Software . About this task Create GPU-enabled notebook servers in HPE Ezmeral Unified Analytics Software . Procedure Click Notebooks icon on the left navigation bar of HPE Ezmeral Unified Analytics Software screen. Click New Notebook Server . You will be navigated to the\n                    Kubeflow Notebooks UI. You can choose JupyterLab as your notebook server within Kubeflow Notebooks. Configure the notebook server with the following options: Select one of the following docker images: (Tensorflow CUDA image) gcr.io/mapr-252711/kubeflow/notebooks/jupyter-tensorflow-cuda-full:<image-tag> (PyTorch CUDA image) gcr.io/mapr-252711/kubeflow/notebooks/jupyter-pytorch-cuda-full:<image-tag> Set Requested memory in Gi to atleast two to\n                            three Gi. Set GPUs as follows: Number of GPUs : 1 NOTE With MIG\n                                        configuration, only one GPU can be assigned per application.\n                                        To learn more on what happens when you assign more than one\n                                        GPU to the notebook server, see GPU . For\n                                        details regarding GPU, see GPU Support . GPU Vendor : Nvidia Click Launch . Results The new GPU-enabled notebook server is created. More information Creating and Managing Notebook Servers GPU Support Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/creating-gpu-enabled-notebook-servers.html",
        "title": "Creating GPU-Enabled Notebook Servers"
    },
    {
        "content": "\nBuilding Custom Kubeflow Jupyter Notebook Image Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. About this task Build a custom image with one of the default notebooks available in the Kubeflow\n                dashboard as a base image. The notebook will be created using the custom image. You can build the custom image for both air-gapped and non-air-gapped environments\n                for all three types of packages \u2013 OS level packages, conda packages and pip\n                packages. To build the custom Kubeflow Jupyter notebook image, perform: Procedure Create requirements.txt file. For example: The content of the file can be following: ###requirements.txt\n# pandas packages\npandas=1.5.0\nnumpy=1.24.2\n# Some other packages \n### Create Dockerfile . ARG BASE_IMG=gcr.io/mapr-252711/kubeflow/notebooks/jupyter-scipy: <image-tag>\nFROM $BASE_IMG\nCOPY requirements.txt /tmp/requirements.txt\nRUN python3 -m pip install -r /tmp/requirements.txt --quiet --no-cache-dir \\\n && rm -f /tmp/requirements.txt Build the image with docker build command. Replace the <image> with actual image name, <tag> with actual tag name, and <base_img> with actual base image. docker build -t  <image>:<example>  . (OR) If the default base image is not suitable, Choose one of the  default\n                                images as the base image. See Notebook Images . Run docker build -t <image>:<example> --build-arg\n                                    BASE_IMG=<base_img> . Push the image to the registry. docker push <image>:<example> Use the custom image option when creating the notebook server in the Kubeflow\n                    UI. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/building-custom-nb-image.html",
        "title": "Building Custom Kubeflow Jupyter Notebook Image"
    },
    {
        "content": "\nInstalling Custom Packages in Kubeflow Notebooks at Runtime Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist\n    between restarts. You can only install custom packages in a Kubeflow notebook in connected HPE Ezmeral Unified Analytics Software environments only for two types of packages \u2013 conda packages and pip packages. You cannot install custom packages in air-gapped environments. Packages installed to the base\n      environment do not persist; the packages are removed after the notebook restarts. By default, the base conda environment is activated for all notebook users. All notebook\n      users can perform the following tasks: Install packages to the base environment Create and install your own conda environment Use the conda environment of another notebook user, if permitted by the environment\n          owner You can install packages that persist (save between restarts). You can also install packages\n      that do not persist (do not save between restarts). If packages do not have to persist between restarts, install the packages to the\n          base conda environment. This applies to both single-user and multi-user modes. If packages must persist between restarts, create an individual conda\n          environment. This applies to both single-user and multi-user modes. The following sections describe how to create an individual conda environment where you can\n      install packages that persist between restarts in single and multi-user modes: NOTE Run\n        commands in the notebook terminal. Single-User Mode Complete the following steps in the notebook if you want to install custom packages that\n        persist between restarts in single-user mode: Create an individual conda\n            environment: conda create --prefix ~/.conda/envs/kf-users-env --clone base Activate the conda environment: conda activate kf-users-env Multi-User Mode Any user with access to the notebook, typically the owner, can create the conda\n        environment. The conda environment is shared with other users (between contributors). All\n        users get equivalent permissions. Users can use the existing packages, as well as install\n        and remove the packages. Complete the following steps in the notebook if you want to install custom packages that\n        persist between restarts in multi-user mode: Create the conda\n            environment: umask 0000 && conda create --prefix ~/.conda/envs/kf-users-env --clone base Activate the conda environment: conda activate kf-users-env Add users (contributors) to the conda\n            environment: conda config --append envs_dirs  /home/<notebook_owner_username>/.conda/envs Activate the conda environment for\n            users: conda activate kf-users-env Install the conda\n            package: conda install package-name=<version> Install the PIP\n            package: pip install package-name==<version> On this page Single-User Mode Multi-User Mode Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/kf-install-custom-package.html",
        "title": "Installing Custom Packages in Kubeflow Notebooks at Runtime"
    },
    {
        "content": "\nEnabling Kale Extension in Kubeflow Notebook Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU\n      resources using Kale extension in a Kubeflow notebook. Enabling Kale Extension To enable the Kale extension in Kubeflow notebook, follow these steps: Sign in to HPE Ezmeral Unified Analytics Software . Connect to the notebook server. See Creating and Managing Notebook Servers . Once the notebook is launced, you can enable the Kale extension. Click the Kale icon on the left navigaton bar. Toggle the Enable button. Once you enable the Kale extension, you can view the Kale extension layout as\n                next: Pipeline Metadata Define the name of the experiment and pipeline, description. Run Enable the Katib feature for this pipeline and setup appropriate\n                      hyper-parameters. Advanced Settings Click Advanced Settings to open this section. Here you\n                      can set a Docker image, which is used for all steps of the current pipeline.\n                      Currently, the Rok snapshot feature is not supported. However, you can\n                      manually create or use the existing volume for this pipeline. Click the pencil icon to edit the cell. Here, you can edit the information\n            about the cell for Kale. Specifying GPU Resources in the Kale Extension To specify the GPU resources in the Kale extension, follow these steps: Create GPU-enabled notebook server. See Creating GPU-Enabled Notebook Servers . Enable Kale extension. See Enabling Kale Extension . Click the pencil icon to edit the cell. Click GPU . Specify the GPU resources as: GPU Count : 1 NOTE With MIG configuration, only one GPU can\n                  be assigned per application. To learn more on what happens when you assign more\n                  than one GPU to the Kale extension, see GPU . For details\n                  regarding GPU, see GPU Support . GPU Vendor : Nvidia More information https://github.com/kubeflow-kale/kale Candy Sharing Tutorial (Kale) GPU Support On this page Enabling Kale Extension Specifying GPU Resources in the Kale Extension Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Kubeflow/enabling-kale-extension.html",
        "title": "Enabling Kale Extension in Kubeflow Notebook"
    },
    {
        "content": "\nNotebook Magic Functions Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that\n    provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Jupyter notebook Magic functions , also known as magic commands or magics , are commands that you can execute within a code cell. Magics are not Python\n      code. They are shortcuts that extends the capabilities of a notebook. Magic commands start\n      with the % character. HPE Ezmeral Unified Analytics Software supports built-in magic functions and the custom\n      magics that are described in this topic. HPE Ezmeral Unified Analytics Software supports line\n      magics and cell magics. Line magic commands do not require a cell body and start with a single % character. Cell magic commands start with %% and require additional lines of input (a\n      cell body). To use these magic functions, you must create a notebook. See Creating and Managing Notebook Servers . %commands The %commands command lists the magic commands and SDKs that are\n        customized by Hewlett Packard Enterprise and are available in this\n          notebook. %createKernel The %createKernel command creates a custom Python kernel in the notebook. The custom Python kernel can be selected as the kernel for a notebook session to work\n        within a specific virtual environment with its own set of dependencies and configurations.\n        By using the custom Python kernel, you can isolate your Python packages and dependencies\n        from other projects or applications such that each project has its own environment and is\n        not affected by changes made to other environments. To create a custom Python kernel from conda package installation, perform: Enter the %createKernel command in a notebook. NOTE You can also directly enter packages as arguments with %createKernel magic function. For example: %createKernel pigz pandas Enter the name for your Python kernel in the Name box. In this\n            example, we use MyPython as the custom Python kernel name. Enter the conda package name in the Package 1 box. To enter\n            additional packages, click the + button. Click the Create Custom Python Kernel button. Click the New Launcher button. You can now see your custom Python kernel - MyPython kernel\n            among the available kernels. %manage_spark The %manage_spark command enables you to connect to the Livy server and\n        start a new Spark session. You must use Spark-related kernels such as\n          PySpark, Spark, or SparkR to use sparkmagic . When\n        you run the %manage_spark command in a notebook cell, a new user interface\n        (UI) widget is displayed, which allows you to configure and manage a Spark cluster. You can\n        use different tabs in this UI widget to manage sessions, create sessions, add endpoints, and\n        manage endpoints. Add Endpoint: To add endpoints, set the following boxes and then\n        click Add endpoint . Auth type: The default authentication for the internal Livy endpoint is Single\n              Sign-On. To connect to other Livy clusters, select the authentication type of your\n              choice. Address: Enter endpoint address. Create Session: To create sessions, set the following boxes and then\n        click Create Session . Endpoint: Select endpoint for your session. Name: Enter session name. Language: Choose either Scala or Python as a runtime. Properties: Edit the Spark configurations. %config_spark You can use the %config_spark magic command to customize the Spark jobs\n        submitted from the PySpark kernel. You can add or delete the Spark configurations when\n        submitting a Livy session. To customize the Spark configurations, follow these steps: Run %config_spark . Click the +Add Spark Configuration Key-Value Pair button. Enter the key and value for Spark configurations in their respective boxes. After you have finished adding the key-value pairs, click Submit . Restart the PySpark kernel and run %manage_spark to see the changes\n            applied in the Properties section of the Create\n              Session tab. You can also edit the values for other Spark configurations or delete any configurations\n        using this magic command. For example: To learn more about customizing Spark configurations when enabling the GPU\n        support for Livy sessions, see Enabling GPU Support for Livy Sessions Created Using Notebooks . %git_clone The %git_clone magic enables you to clone your private GitHub repository\n        from the notebook. To clone the repository, enter your GitHub username and GitHub password. After you have finished cloning the repository, you can use the Git extension in the notebook for version control. %sql and %%sql You can use the %sql magic command in Jupyter Notebook to interactively\n        work with SQL databases. To learn more about how to connect to databases, see connecting to a database . You must use Python kernels to use %sql and %%sql magic\n        commands. You can directly write and execute SQL queries within a notebook cell. When you\n        run the notebook cell containing %sql and your SQL query, the magic command\n        sends the query to the database, runs it, and retrieves the result. In HPE Ezmeral Unified Analytics Software , you can connect to all SQL databases (if\n          you have public access to these databases) and submit queries\n        through EzPresto using the %sql magic as\n          follows: %sql SELECT * FROM cache.information_schema.columns NOTE If you have private access to SQL databases, you can not connect to those\n          databases through EzPresto using the %sql or %%sql magic. To learn how to establish a\n          connection to SQL databases and submit queries from a notebook when you have private\n          access to the database, see Submitting Presto Queries from Notebook . You can use the %%sql magic command to define and run an entire SQL script\n        or block. This means you can write and run a series of SQL statements in the same cell using %%sql magic. The results of the SQL query or queries are displayed in the notebook as a table that makes\n        it easy to analyze and visualize the data. Getting Help To display help about a magic command, enter the command followed by a ? (question mark). For example: %manage_spark? On this page %commands %createKernel %manage_spark %config_spark %git_clone %sql and %%sql Getting Help Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/notebook-magic-functions.html",
        "title": "Notebook Magic Functions"
    },
    {
        "content": "\nCreating the Conda Environment Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . You can use conda package management system to create a new virtual\n      environment. To create a virtual environment which includes the Python version and ipykernel package,\n      run: conda create -n <your-env-name> python=<python-version> ipykernel NOTE To create a conda environment, you must use a notebook with at least 3 CPU and 3 Gi of\n        memory. For example: The following command creates a new environment named py27 ,\n      which includes Python version 2.7 and the ipykernel package. conda create -n py27 python=2.7 ipykernel You can also create a custom Python kernel using the %createKernel magic\n      command. For details, see Notebook Magic Functions . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/create-conda-env.html",
        "title": "Creating the Conda Environment"
    },
    {
        "content": "\nAccessing MinIO S3 using Boto3 Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Notebook Images Overview Describes notebook images available HPE Ezmeral Unified Analytics Software and their     uses. Creating and Managing Notebook Servers Describes how to create and manage notebook servers in HPE Ezmeral Unified Analytics Software . Creating GPU-Enabled Notebook Servers Describes how to create and deploy the GPU-enabled notebook servers. Building Custom Kubeflow Jupyter Notebook Image Describes how to build the custom Kubeflow Jupyter notebook image. Installing Custom Packages in Kubeflow Notebooks at Runtime Describes how to install custom packages in existing Kubeflow notebooks that persist     between restarts. Enabling Kale Extension in Kubeflow Notebook Describes how to enable and use the Kale extension, and specify GPU       resources using Kale extension in a Kubeflow notebook. Notebook Magic Functions Jupyter notebook magic functions, also known as magics, are special commands that     provide notebook functions that might not be easy for you to program using Python. HPE Ezmeral Unified Analytics Software supports line magics and cell magics. Creating the Conda Environment Describes how to create a conda environment in HPE Ezmeral Unified Analytics Software . Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Accessing MinIO S3 using Boto3 Describes how to use Boto3 to interact wtih MinIO from a Jupyter Notebook. You can use Boto3 to interact with Minio S3 services. Boto3 is a Python library that enables\n      you to create, configure, and manage S3 services from a Jupyter Notebook. The following example shows you how to run Boto3 in a Jupyter Notebook to list the existing\n      Minio S3 buckets: import boto3\nimport os\n\naccess_key_id = os.environ[\"AUTH_TOKEN\"]\nsecret_access_key = \"xxx\"\n\nLOCAL_S3_PROXY_SERVICE_URL = 'http://local-s3-service.ezdata-system.svc.cluster.local:30000'\n\ns3 = boto3.client('s3',\naws_access_key_id=access_key_id,\naws_secret_access_key=secret_access_key,\nendpoint_url=LOCAL_S3_PROXY_SERVICE_URL\n)\n\ns3.list_buckets() Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/Notebooks/using-boto3.html",
        "title": "Accessing MinIO S3 using Boto3"
    },
    {
        "content": "\nNotices Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Notices The information contained herein is subject to change without notice. The only warranties\n        for Hewlett Packard Enterprise products and services are set forth in the express warranty\n        statements accompanying such products and services. Nothing herein should be construed as\n        constituting an additional warranty. Hewlett Packard Enterprise shall not be liable for\n        technical or editorial errors or omissions contained herein. Confidential computer software. Valid license from Hewlett Packard Enterprise required for\n        possession, use, or copying. Consistent with FAR 12.211 and 12.212, Commercial Computer\n        Software, Computer Software Documentation, and Technical Data for Commercial Items are\n        licensed to the U.S. Government under vendor's standard commercial license. Links to third-party websites take you outside the Hewlett Packard Enterprise website.\n        Hewlett Packard Enterprise has no control over and is not responsible for information\n        outside the Hewlett Packard Enterprise website. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/notices.html",
        "title": "Notices"
    },
    {
        "content": "\nAcknowlegements Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Acknowlegements Microsoft \u00ae and Windows \u00ae are either registered trademarks or trademarks of Microsoft Corporation in the United States and/or other countries. UNIX \u00ae is a registered trademark of The Open Group. All third-party marks are property of their respective owners. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/acknowlegements.html",
        "title": "Acknowlegements"
    },
    {
        "content": "\nGlossary Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Get Started Describes how to get started with HPE Ezmeral Unified Analytics Software . Administration Provides information about managing applications and clusters in HPE Ezmeral Unified Analytics Software . Observability Describes observability in HPE Ezmeral Unified Analytics Software . Data Engineering Data engineers can design and build pipelines that transform and transport data into     usable formats for data consumers. Data Analytics Provides a brief overview of data analytics in HPE Ezmeral Unified Analytics Software . Data Science Provides a brief overview of data science in HPE Ezmeral Unified Analytics Software . Notebooks Provides a brief overview of Notebooks in HPE Ezmeral Unified Analytics Software . Glossary Definitions for commonly used terms in HPE Ezmeral Unified Analytics\n        environments. Glossary List of terms (with description) used in HPE Ezmeral Unified Analytics Software documentation. Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/glossary/glossary.html",
        "title": "Glossary"
    },
    {
        "content": "\nLanding Page Nav Version 2 Jump to main content HPE Ezmeral Unified Analytics Software 1.3 Documentation Feedback Landing Page Nav Version 2 This file is a resource file used for creating a persona based overflow for common\n    tasks. HPE Ezmeral Unified Analytics Software is\n        usage-based Software-as-a-Service (SaaS) that fully manages, supports, and maintains hybrid\n        and multi-cloud modern analytical workloads through open-source tools. HPE Ezmeral Unified Analytics Software separates compute and\n        storage for flexible, cost-efficient scalability to securely access data stored in multiple\n        data platforms through a simple user interface, which is easily installed and deployed in\n        minutes on private, public, and on-premises infrastructure. Get Started Learn about the features and functionalities in HPE Ezmeral Unified Analytics Software and get started\n          with product installation and tutorials. Learn\n            more . Administration Manage clusters, applications, users, and data security.\n          Monitor users, clusters, application resource consumption, and billing. Learn more . Data Engineering Connect data sources and create Airflow pipelines, run\n          federated queries ( EzPresto ), and visualize data\n          (Superset). Learn more . Data Analytics Run analytical workloads through the Apache Spark\n          Operator, interactive Spark sessions, and schedule jobs using Apache Airflow. Learn more . Data Science Use programming languages such as Python, R, Java, and SQL\n          to build, train, and deploy machine learning models using open-source tools that optimize\n          the performance of predictive machine learning models. Learn more Release Notes Provides links to release notes for each HPE Ezmeral Unified Analytics Software release. Release notes include new features, product updates, fixed issues, known issues,\n          and limitations. Learn more . Partners Support Dev-Hub Community Training ALA Privacy Policy Glossary Search Search current doc version",
        "url": "https://docs.ezmeral.hpe.com/unified-analytics/13/landing_page_v2.html",
        "title": "Landing Page Nav Version 2"
    }
]