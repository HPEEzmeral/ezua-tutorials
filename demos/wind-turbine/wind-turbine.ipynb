{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98253c01-c048-43de-8c2a-ab8b033b60eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wind Turbines\n",
    "\n",
    "In this tutorial you delve into the world of wind turbines and harness the power of Machine Learning (ML) to predict\n",
    "their energy production. To this end, you use Spark to explore and augment a training dataset, train a Gradient-Boosted\n",
    "Tree (GBT) regressor, and predict the power output of a wind turbine.\n",
    "\n",
    "<div><img src=\"images/wind-farm.jpg\" width=\"100%\"/>\n",
    "    <p>(Image generated by Stable Diffusion)</p>\n",
    "</div>\n",
    "\n",
    "Wind turbines hold tremendous potential as a sustainable source of energy, capable of supplying a substantial portion of\n",
    "the world's power needs. However, the inherent unpredictability of power generation poses a challenge when it comes to\n",
    "optimizing this process.\n",
    "\n",
    "Fortunately, you have a powerful tool at your disposal: Machine Learning. By leveraging advanced algorithms and data\n",
    "analysis, you can develop models that accurately predict the power production of wind turbines. This enables you to\n",
    "optimize the power generation process and overcome the challenges associated with its ingrained variability.\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "* [Create a Spark Interactive Session](#create-a-spark-interactive-session)\n",
    "* [Load the Dataset](#load-the-dataset)\n",
    "* [Data Exploration](#data-exploration)\n",
    "* [Training a GBT Regression](#training-a-gbt-regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c1d18-b1d1-4755-b2a1-465656177c30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a Spark Interactive Session\n",
    "\n",
    "Let's begin! In this demo you use Livy to create and manage an interactive Spark session. Livy is an open-source REST\n",
    "service that enables remote and interactive analytics on Apache Spark clusters. It provides a way to interact with Spark\n",
    "clusters programmatically using a REST API, allowing you to submit Spark jobs, run interactive queries, and manage Spark\n",
    "sessions.\n",
    "\n",
    "First, you need to connect to the Livy endpoint and create a new Spark interactive session. The Spark interactive\n",
    "session is particularly useful for exploratory data analysis, prototyping, and iterative development. It allows you to\n",
    "interactively work with large datasets, perform transformations, apply analytical operations, and build machine learning\n",
    "models using Spark's distributed computing capabilities. This is exactly what you do in this Notebook!\n",
    "\n",
    "To communicate with Livy and manage your sessions you use Sparkmagic, an open-source tool that provides a Jupyter kernel\n",
    "extension. Sparkmagic integrates with Livy, to provide the underlying communication layer between the Jupyter kernel and\n",
    "the Spark cluster.\n",
    "\n",
    "Execute the cell below and:\n",
    "\n",
    "1. Select `Add Endpoint`.\n",
    "1. Select `Basic_Access`, paste your Livy endpoint, and authenticate with your credentials.\n",
    "1. Select `Create Session`.\n",
    "1. Provide a name, select the `python` language, and click `Create Session`.\n",
    "\n",
    "Give it a few minutes for your session to initialize. Once ready, the Manage Sessions pane will activate, displaying\n",
    "your session ID. When the session state turns to idle, you're all set. This process can take up to five minutes.\n",
    "\n",
    "> To further configure Sparkmagic, you can make use of a config.json file located at ~/.sparkmagic/config.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c97a7-e2d6-40e0-8977-9725706523cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext sparkmagic.magics\n",
    "%manage_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cfae83-2d9a-40b8-9df3-f7296162dfd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can also use the EzUA UI to view the logs and code executions:\n",
    "\n",
    "![spark-interactive-ui](images/spark-interactive-ui.png)\n",
    "\n",
    "You are now prepared to embark on your first interaction with Livy. Whenever you initiate a cell with the `%%spark`\n",
    "magic command, the code within that cell is not executed locally. Instead, it is executed within a Spark context managed\n",
    "by Livy. Livy handles everything seamlessly and provide you with a response containing the results.\n",
    "\n",
    "With Sparkmagic at your side, you can leave the networking part to it. Sparkmagic takes care of all the intricate\n",
    "details, effortlessly creating and sending requests to the Livy server. Finally, it seamlessly renders the response\n",
    "within the Jupyter user interface, ensuring a smooth and hassle-free experience.\n",
    "\n",
    "Before you begin, let's make sure that the dataset is copied in the right location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f2f94-4ad9-41c9-a7f6-cef590163e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# create the `auto-spark` folder if it does not exist\n",
    "os.makedirs(f\"{os.getenv('HOME')}/shared/auto-spark/\", exist_ok=True)\n",
    "\n",
    "# copy the file to the right location\n",
    "dataset_file = \"dataset/T1.csv\"\n",
    "destination = f\"{os.getenv('HOME')}/shared/auto-spark/T1.csv\"\n",
    "shutil.copyfile(dataset_file, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478d922-8640-43a6-8802-c6bc577f508d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, let's import the libraries you use inside the Spark session and get a handle on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1de280-d9ba-41bf-a864-96f8c06871a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.regression import GBTRegressionModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from py4j.java_gateway import java_import\n",
    "\n",
    "\n",
    "sns.set_style('white')\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f096b2-ef79-4e29-af2d-eda6e067811b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "spark = SparkSession.builder.appName(\"wind-turbine\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca547e-4945-46a0-a2d5-643ba75e480d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "java_import(spark._sc._jvm, \"org.apache.spark.sql.api.python.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f34db-40b1-4910-b1b6-187192163875",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "It's time to load the dataset, which comes in a convenient CSV format. You leverage the spark session you created to\n",
    "load it as a DataFrame. Once loaded, you can delve into its contents by examining the first five rows and its schema. \n",
    "Additionally, you get an idea of the dataset's size by printing the number of examples available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40616750-6907-48bf-bd6a-ef4b69168e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "spark_df = spark.read.csv(\n",
    "    'file:///mounts/shared-volume/shared/auto-spark/T1.csv',\n",
    "    header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d469f5-0387-4516-835f-dc270c1faac4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, you should cache the dataset in memory. The `cache()` method is used to persist or cache the contents of a\n",
    "DataFrame, Dataset, or RDD (Resilient Distributed Dataset) in memory. Caching data in memory can significantly improve\n",
    "the performance of iterative algorithms or repeated computations by avoiding the need to recompute or fetch the data\n",
    "from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382342b-20e1-4bb5-b2d6-7a40544b529b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Caching the dataset\n",
    "spark_df.cache()\n",
    "\n",
    "# Converting all the column names to lower case\n",
    "spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])\n",
    "\n",
    "print('Show the first 5 rows')\n",
    "spark_df.show(5)\n",
    "\n",
    "print('What are the variable data types?')\n",
    "spark_df.printSchema()\n",
    "\n",
    "print('How many observations do we have?')\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc06054-69d9-42db-81f2-4a099e632b2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this experiment, the objective is to predict the power production of a wind turbine (`lv activepower (kw)`) based on\n",
    "the other features. These features include the current date and hour, the wind speed, and the wind direction. By\n",
    "analyzing the relationships between these variables, you aim to uncover valuable insights and create a predictive model\n",
    "that can estimate the power output of the turbine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e152b-a548-4709-8bff-dea542415b13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "Let's start exploring and transforming the dataset. First step, separate the `date/time` column into two distinct\n",
    "columns, one for the month and one for the hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dba19a-5583-425a-8ce1-766713bae8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Extracting a substring from columns to create month and hour variables\n",
    "spark_df = spark_df.withColumn(\"month\", substring(\"date/time\", 4,2))\n",
    "spark_df = spark_df.withColumn(\"hour\", substring(\"date/time\", 12,2))\n",
    "\n",
    "# Converting string month and hour variables to integer\n",
    "spark_df = spark_df.withColumn('month', spark_df.month.cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn('hour', spark_df.hour.cast(IntegerType()))\n",
    "\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae329a-16a6-44fb-8472-7c0eabc85da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Moving forward, let's examine some essential statistical characteristics of the features, specifically the mean and\n",
    "standard deviation. However, it's important to note that these statistics are relevant only for the wind speed,\n",
    "theoretical power curve, and active power variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f99d33-4678-45f5-b8ce-c318c2d5b064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "spark_df.select('wind speed (m/s)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)').toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78378126-c34d-4ffc-9726-f46018664565",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's extract a random sample from the dataset and start creating a visual model. By visualizing the data, you can gain\n",
    "a deeper understanding of its patterns, trends, and relationships. Through this visual exploration, you uncover valuable\n",
    "insights that can guide you through your analysis and decision-making processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b67bf-dacf-4aab-bf64-361ecd79f549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Taking a random sample from the big data\n",
    "sample_df = spark_df.sample(withReplacement=False, fraction=0.1, seed=42).toPandas()\n",
    "\n",
    "# Visualizing the distributions with the sample data\n",
    "columns = ['wind speed (m/s)', 'wind direction (deg)', 'month', 'hour', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']\n",
    "i=1\n",
    "plt.figure(figsize=(10, 12))\n",
    "for each in columns:\n",
    "    plt.subplot(3, 2, i)\n",
    "    sample_df[each].plot.hist(bins=12)\n",
    "    plt.title(each)\n",
    "    i += 1\n",
    "    \n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911566e3-6abb-48df-9706-7eac54b62ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "\n",
    "# Compute the average power production by month\n",
    "monthly = spark_df.groupby('month').mean('lv activepower (kw)').sort('avg(lv activepower (kw))').toPandas()\n",
    "sns.barplot(x='month', y='avg(lv activepower (kw))', data=monthly)\n",
    "plt.title('Months and Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d3314-c3b7-4c2a-a81a-d4c00efd4575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "\n",
    "# Compute the average power production by hour\n",
    "hourly = spark_df.groupby('hour').mean('lv activepower (kw)').sort('avg(lv activepower (kw))').toPandas()\n",
    "sns.barplot(x='hour', y='avg(lv activepower (kw))', data=hourly)\n",
    "plt.title('Hours and Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa67c59-a101-4409-9300-c2d810c02c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Compute the correlation between the features of the dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "sample_df[columns].corr()\n",
    "plt.clf()\n",
    "sns.pairplot(sample_df[columns], markers='*');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d0527-3ff8-4197-9f51-ded9e2a7284c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Finding the average power production for 5 m/s wind speed increments\n",
    "avg_power = []\n",
    "wind_speed = []\n",
    "\n",
    "for i in [0, 5, 10, 15, 20]:\n",
    "    avg_value = spark_df.filter((spark_df['wind speed (m/s)'] > i) \n",
    "                                & (spark_df['wind speed (m/s)'] <= i+5))\\\n",
    "                                .agg({'lv activepower (kw)':'mean'}).collect()[0][0] \n",
    "    avg_power.append(avg_value)\n",
    "    wind_speed.append(str(i) + '-' + str(i+5))\n",
    "\n",
    "plt.clf()\n",
    "sns.barplot(x=wind_speed, y=avg_power, color='orange')\n",
    "plt.title('Avg Power Production for 5 m/s Wind Speed Increments')\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5880755-5a80-4aaa-b53f-7830f1023db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Creating the polar diagram\n",
    "from math import radians\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "# The circle position indicates wind direction\n",
    "# The further from the circle center the higher the wind speed\n",
    "# The circle size indicates active power\n",
    "sns.scatterplot(x=[radians(x) for x in sample_df['wind direction (deg)']], \n",
    "                y=sample_df['wind speed (m/s)'],\n",
    "                size=sample_df['lv activepower (kw)'],\n",
    "                hue=sample_df['lv activepower (kw)'],\n",
    "                alpha=0.7, legend=None)\n",
    "\n",
    "# Setting the polar diagram's top to represent North \n",
    "ax.set_theta_zero_location('N')\n",
    "# Setting -1 to start the wind direction clockwise\n",
    "ax.set_theta_direction(-1)\n",
    "# Setting wind speed labels in a better position to see\n",
    "ax.set_rlabel_position(110)\n",
    "\n",
    "plt.title('Wind Speed - Wind Direction - Power Production Diagram')\n",
    "plt.ylabel(None);\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7626d0-b8c9-4718-8a9a-89031e0a2c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Plot the real power production over the theoritical\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='wind speed (m/s)', y='lv activepower (kw)', color='orange', label='Real Production', alpha=0.5, data=sample_df)\n",
    "sns.lineplot(x='wind speed (m/s)', y='theoretical_power_curve (kwh)', color='blue', label='Theoritical Production', data=sample_df)\n",
    "plt.title('Wind Speed and Power Production Chart')\n",
    "plt.ylabel('Power Production (kw)');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f72f3c-c667-4725-a047-0ca8735607ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Filter the big data where the real and theoritical power productions are equal to 0\n",
    "zero_theo_power = spark_df.filter((spark_df['lv activepower (kw)'] == 0)\n",
    "                                  & (spark_df['theoretical_power_curve (kwh)'] == 0)).toPandas()\n",
    "\n",
    "print(zero_theo_power[['wind speed (m/s)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac3b95-4aaa-4277-bb21-b17875ccd752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "# Examine the wind speed distribution for 0 power production\n",
    "zero_theo_power['wind speed (m/s)'].hist()\n",
    "plt.title('Wind Speed Distribution for 0 Power Production')\n",
    "plt.xlabel('Wind speed (m/s)')\n",
    "plt.ylabel('Counts for 0 Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eeccb6-4ff5-4e45-acda-0fa76fb067d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Observations for the wind speed > 3m/s and power production = 0, \n",
    "# while theoritically there should be power production\n",
    "zero_power = spark_df.filter((spark_df['lv activepower (kw)'] == 0)\n",
    "                            & (spark_df['theoretical_power_curve (kwh)'] != 0)\n",
    "                            & (spark_df['wind speed (m/s)'] > 3)).toPandas()\n",
    "print(zero_power.head())\n",
    "print('No of Observations (while Wind Speed > 3 m/s and Power Production = 0): ', len(zero_power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673591c3-0777-46a4-9329-a0bd7c7033b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "zero_power['wind speed (m/s)'].plot.hist(bins=8)\n",
    "plt.xlabel('Wind Speed (m/s)')\n",
    "plt.ylabel('Counts for Zero Production')\n",
    "plt.title('Wind Speed Counts for Zero Power Production')\n",
    "plt.xticks(ticks=np.arange(4,18,2));\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74434df-c123-4c04-9c4c-882bd7a790c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# The number of the examples that show a 0 power production\n",
    "# while theoritically there should be power production\n",
    "print(\"The number of the examples that show a 0 power production\"\n",
    "      \" while theoritically there should be power production:\", zero_power['month'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a596bd6-aac0-4e5d-adb7-a2d586e1db40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Excluding the observations meeting the filter criterias \n",
    "spark_df = spark_df.filter(~((spark_df['lv activepower (kw)'] == 0)\n",
    "                            & (spark_df['theoretical_power_curve (kwh)'] != 0)\n",
    "                            & (spark_df['wind speed (m/s)'] > 3)))\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2d2af-94d7-4c7d-ba84-7188cf94e42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "columns = ['wind speed (m/s)', 'wind direction (deg)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']\n",
    "i=1\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20, 5))\n",
    "for each in columns:\n",
    "    df = spark_df.select(each).toPandas()\n",
    "    plt.subplot(1, 4, i)\n",
    "    #plt.boxplot(df)\n",
    "    sns.boxplot(x=df[each])\n",
    "    # plt.title(each)\n",
    "    i += 1\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd46aa-9e6c-4b4d-b917-84cf81428b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Let's find and exclude possible outliers.\n",
    "# Create a pandas df for visualization\n",
    "wind_speed = spark_df.select('wind speed (m/s)').toPandas()\n",
    "\n",
    "# Defining the quantiles and interquantile range\n",
    "Q1 = wind_speed['wind speed (m/s)'].quantile(0.25)\n",
    "Q3 = wind_speed['wind speed (m/s)'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "# Defining the lower and upper threshold values\n",
    "lower = Q1 - 1.5*IQR\n",
    "upper = Q3 + 1.5*IQR\n",
    "\n",
    "print('Quantile (0.25): ', Q1, '  Quantile (0.75): ', Q3)\n",
    "print('Lower threshold: ', lower, ' Upper threshold: ', upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc873f-cb57-43a5-9f4b-97cfb1fe37d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# Fancy indexing for outliers\n",
    "outlier_tf = (wind_speed['wind speed (m/s)'] < lower) | (wind_speed['wind speed (m/s)'] > upper)\n",
    "\n",
    "print('Total Number of Outliers: ', len(wind_speed['wind speed (m/s)'][outlier_tf]))\n",
    "print('--'*15)\n",
    "print('Some Examples of Outliers:')\n",
    "print(wind_speed['wind speed (m/s)'][outlier_tf].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59088229-0fa5-4cd6-92b8-28fd9e570754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "(spark_df.select('wind speed (m/s)', 'lv activepower (kw)')\n",
    "         .filter(spark_df['wind speed (m/s)'] >= 19)\n",
    "         .agg({'lv activepower (kw)':'mean'}).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad694feb-9bd4-4d14-b8eb-6445801afd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "from pyspark.sql import functions as F\n",
    "spark_df = spark_df.withColumn('wind speed (m/s)', \n",
    "                               F.when(F.col('wind speed (m/s)') > 19.447, 19)\n",
    "                               .otherwise(F.col('wind speed (m/s)')))\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286a981-17f6-44d7-a0eb-a4ccf3c51cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# High level power production\n",
    "spark_df.filter(((spark_df['month'] == 3) | (spark_df['month'] == 8) | (spark_df['month'] == 11)) \n",
    "                & ((spark_df['hour'] >= 16) | (spark_df['hour'] <= 24)) \n",
    "                & ((spark_df['wind direction (deg)'] > 0) | (spark_df['wind direction (deg)'] < 90))\n",
    "                & ((spark_df['wind direction (deg)'] > 180) | (spark_df['wind direction (deg)'] < 225))\n",
    "               ).agg({'lv activepower (kw)':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995200ac-6701-4fef-ad1c-2029d4c2d67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Low level power production\n",
    "spark_df.filter((spark_df['month'] == 7) \n",
    "                & ((spark_df['hour'] >= 9) | (spark_df['hour'] <= 11)) \n",
    "                & ((spark_df['wind direction (deg)'] > 90) | (spark_df['wind direction (deg)'] < 160))\n",
    "               ).agg({'lv activepower (kw)':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a81598-293f-44c0-92f1-544efa52b1bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training a GBT Regressor\n",
    "\n",
    "You are now ready to train the GBT regresson. To begin, you carefully specify the features and the label for the model.\n",
    "Then, you split the dataset into training and test subsets to ensure robust evaluation of the model's performance.\n",
    "Finally, you initiate the training process, allowing the GBT regressor to learn from the training data, and generate\n",
    "accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487057c-6032-41ec-b2e4-fe28dd297bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Converting lv activepower (kw) variable as label\n",
    "spark_df = spark_df.withColumn('label', spark_df['lv activepower (kw)'])\n",
    "\n",
    "# Preparing the independent variables (Features) and fefining the variables to be used\n",
    "variables = ['month', 'hour', 'wind speed (m/s)', 'wind direction (deg)']\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "va_df = vectorAssembler.transform(spark_df)\n",
    "\n",
    "# Combining features and label column\n",
    "final_df = va_df.select('features', 'label')\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02140c44-46ce-4ad0-9481-33c6b1b6230b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Split the dataset:\n",
    "# 80% for training\n",
    "# 20% for testing\n",
    "splits = final_df.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "print('Train dataset: ', train_df.count())\n",
    "print('Test dataset : ', test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330b4e2-f27c-4cce-9027-65c7ed80f4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Creating the gbm regressor object\n",
    "gbm = GBTRegressor(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Training the model with train data\n",
    "gbm_model = gbm.fit(train_df)\n",
    "\n",
    "# Predicting using the test data\n",
    "y_pred = gbm_model.transform(test_df)\n",
    "\n",
    "# Initial look at the target and predicted values\n",
    "y_pred.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0b106-149e-43a3-95a2-f868b4fde8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "gbm_model.write().overwrite().save(\"file:///mounts/shared-volume/shared/auto-spark/GBM.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac402d0-e52c-4cda-8a6a-32a218154316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "gbm_model_dtap = GBTRegressionModel.load(\"file:///mounts/shared-volume/shared/auto-spark/GBM.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bd4cd-74b0-40f7-a239-759e766cc925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Initial model success\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "print('R2:\\t', evaluator.evaluate(y_pred, {evaluator.metricName: 'r2'}))\n",
    "print('MAE:\\t', evaluator.evaluate(y_pred, {evaluator.metricName: 'mae'}))\n",
    "print('RMSE:\\t', evaluator.evaluate(y_pred, {evaluator.metricName: 'rmse'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4aa810-6839-4240-937e-c353a3719a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Converting sample_df back to Spark dataframe\n",
    "eva_df = spark.createDataFrame(sample_df)\n",
    "\n",
    "# Converting lv activepower (kw) variable as label\n",
    "eva_df = eva_df.withColumn('label', eva_df['lv activepower (kw)'])\n",
    "\n",
    "# Defining the variables to be used\n",
    "variables = ['month', 'hour', 'wind speed (m/s)', 'wind direction (deg)']\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "vec_df = vectorAssembler.transform(eva_df)\n",
    "\n",
    "# Combining features and label column\n",
    "vec_df = vec_df.select('features', 'label')\n",
    "\n",
    "# Using ML model to predict\n",
    "preds = gbm_model.transform(vec_df)\n",
    "preds_df = preds.select('label','prediction').toPandas()\n",
    "\n",
    "# Compining dataframes to compare\n",
    "frames = [sample_df[['wind speed (m/s)', 'theoretical_power_curve (kwh)']], preds_df]\n",
    "sample_data = pd.concat(frames, axis=1)\n",
    "\n",
    "plt.clf()\n",
    "# Visualizing real, theoritical and predicted power production\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x='wind speed (m/s)', y='label',alpha=0.5, label= 'Real Power', data=sample_data)\n",
    "sns.scatterplot(x='wind speed (m/s)', y='prediction', alpha=0.7, label='Predicted Power', marker='o', data=sample_data)\n",
    "sns.lineplot(x='wind speed (m/s)', y='theoretical_power_curve (kwh)', label='Theoritical Power',color='purple', data=sample_data)\n",
    "plt.title('Wind Turbine Power Production Prediction')\n",
    "plt.ylabel('Power Production (kw)')\n",
    "plt.legend();\n",
    "\n",
    "%matplot plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wind-turbine",
   "language": "python",
   "name": "wind-turbine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
