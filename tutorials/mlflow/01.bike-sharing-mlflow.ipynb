{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7wSVnqQ7xZB"
   },
   "source": [
    "# Bike Sharing (MLFlow - KServe)\n",
    "\n",
    "This notebook provides a detailed walkthrough of a comprehensive data science workflow, encompassing data preprocessing,\n",
    "model training and evaluation, hyperparameter tuning, experiment tracking via MLFlow, and model deployment using Seldon\n",
    "and KServe. The use case under consideration is the well-known bike sharing dataset, sourced from the UCI Machine\n",
    "Learning Repository.\n",
    "\n",
    "![bike-sharing](images/bike-sharing.jpg)\n",
    "(Photo by <a href=\"https://unsplash.com/@zaccastravels?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">ZACHARY STAINES</a> on <a href=\"https://unsplash.com/photos/KEhNcoCldbk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>)\n",
    "\n",
    "The dataset records the hourly and daily count of rental bikes between 2011 and 2012 in the Capital Bikeshare system,\n",
    "supplemented with corresponding weather and seasonal data. The primary objective of this dataset is to foster research\n",
    "into bike sharing systems, which are gaining significant attention due to their implications on traffic management,\n",
    "environmental sustainability, and public health.\n",
    "\n",
    "The task associated with this dataset is regression, with 17,389 instances. The overarching goal is to construct a\n",
    "predictive model capable of forecasting bike rental demand. The primary target variable for prediction is the `cnt`\n",
    "attribute, representing the total count of rental bikes, inclusive of both casual and registered users.\n",
    "\n",
    "By leveraging other features in the dataset (such as date, season, year, month, hour, holiday, weekday, working day,\n",
    "weather conditions, temperature, perceived temperature, humidity, and wind speed), you can train a model to predict this\n",
    "count with high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "The subsequent code cells are dedicated to importing the requisite dependencies. Additionally, it's recommended to\n",
    "establish a local directory for preserving the training artifacts generated during your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import itertools\n",
    "import warnings\n",
    "import subprocess\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"model_artifacts\"):\n",
    "    os.system(\"rm -rf model_artifacts\")\n",
    "os.mkdir(\"model_artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set an MLflow Experiment\n",
    "\n",
    "To set an experiment as active in MLflow, you can specify it either by its name using the `experiment_name` parameter or\n",
    "by its ID using the `experiment_id` parameter. It's important to note that you can't specify both the experiment name\n",
    "and ID simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_experiment(exp_name):\n",
    "    \"\"\"Register an experiment in MLFlow.\n",
    "    \n",
    "    args:\n",
    "      exp_name (str): The name of the experiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mlflow.set_experiment(exp_name)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to set the experiment: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up an experiment with set_exp from ezmllib.mlflow\n",
    "experiment_name = \"bike-sharing-exp\"\n",
    "set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwKZC40S-e0R"
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "With the preliminary setup complete, you can now proceed to load the dataset. The data is provided in a CSV format,\n",
    "which can be conveniently loaded using the Pandas library in Python. To get a glimpse of the dataset, you'll display the\n",
    "first five rows using the `head()` method of the DataFrame. This initial exploration will provide a snapshot of the data\n",
    "we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "mFGzYdKCCNiK",
    "outputId": "8783bf81-d46a-4958-d2dc-59a324868a64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load input data into pandas dataframe\n",
    "bike_sharing = pd.read_csv(\"dataset/bike-sharing.csv\")\n",
    "bike_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQk3RQt2FB8x"
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "In this phase, you will prepare the data for the subsequent stages of the analysis. This involves cleaning,\n",
    "transforming, and structuring the data to ensure it is in the optimal format for your machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "vyS5Ru5aE5Y7",
    "outputId": "5d0b2528-9664-437d-8e3f-61119fdaad5e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove unused columns\n",
    "bike_sharing.drop(columns=[\"instant\", \"dteday\", \"registered\", \"casual\"],\n",
    "                  inplace=True)\n",
    "\n",
    "# Use better names\n",
    "bike_sharing.rename(\n",
    "    columns={\n",
    "        \"yr\": \"year\",\n",
    "        \"mnth\": \"month\",\n",
    "        \"hr\": \"hour_of_day\",\n",
    "        \"holiday\": \"is_holiday\",\n",
    "        \"workingday\": \"is_workingday\",\n",
    "        \"weathersit\": \"weather_situation\",\n",
    "        \"temp\": \"temperature\",\n",
    "        \"atemp\": \"feels_like_temperature\",\n",
    "        \"hum\": \"humidity\",\n",
    "        \"cnt\": \"rented_bikes\",\n",
    "    }, inplace=True)\n",
    "\n",
    "# Convert every data point to `float64`\n",
    "cols = bike_sharing.select_dtypes(exclude=['float64']).columns\n",
    "for i in ['season', 'year', 'month', 'hour_of_day', 'is_holiday',\n",
    "          'weekday', 'is_workingday', 'weather_situation', 'rented_bikes']:\n",
    "    bike_sharing[i] = bike_sharing[i].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40MGTHbNFKTP"
   },
   "source": [
    "## Data Visualization\n",
    "\n",
    "In this section, you will employ various visualization techniques to better understand the data. By creating graphical\n",
    "representations of the data, you can identify patterns, trends, and correlations that might not be evident from the raw\n",
    "data alone. This step is crucial in guiding the subsequent analysis and model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "bNZOegwGHzUR",
    "outputId": "45a00d75-c019-4c39-96c4-08e3995fb381",
    "tags": []
   },
   "outputs": [],
   "source": [
    "hour_of_day_agg = bike_sharing.groupby([\"hour_of_day\"])[\"rented_bikes\"].sum()\n",
    "\n",
    "hour_of_day_agg.plot(\n",
    "    kind=\"line\", \n",
    "    title=\"Total rented bikes by hour of day\",\n",
    "    xticks=hour_of_day_agg.index,\n",
    "    figsize=(10, 5),\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMg_JKoUKq9j"
   },
   "source": [
    "## Prepare training and test data sets\n",
    "\n",
    "In this section, you will partition the data into training and test datasets. This is a crucial step in the machine\n",
    "learning workflow, allowing you to train the model on a subset of the data (the training set), and then evaluate its\n",
    "performance on unseen data (the test set). This process helps ensure that your model generalizes well to new data and is\n",
    "not simply memorizing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ZwtDgaZ9Ktie",
    "outputId": "4971f3d6-5e99-4583-acb6-4ef73892a633",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset randomly into 70% for training and 30% for testing.\n",
    "X = bike_sharing.drop(\"rented_bikes\", axis=1)\n",
    "y = bike_sharing.rented_bikes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.size}\")\n",
    "print(f\"Test samples: {X_test.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN0w6zFJSb87"
   },
   "source": [
    "## Establishing Evaluation Metrics\n",
    "\n",
    "Before proceeding to the training stage, you will define the evaluation metrics that will be used to assess the\n",
    "performance of your model. These metrics will provide quantitative measures of the model's accuracy, helping you\n",
    "understand how well the model is performing and where improvements can be made. This step is crucial in ensuring that\n",
    "your model meets the desired performance standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC1wzz_T_tSA"
   },
   "source": [
    "### Root Mean Square Error (RMSE)\n",
    "\n",
    "One of the evaluation metrics you will use is the Root Mean Square Error (RMSE). This metric provides a measure of the\n",
    "differences between the values predicted by the model and the actual values. By taking the square root of the average of\n",
    "these squared differences, RMSE can give you a sense of the magnitude of the prediction errors. Lower RMSE values\n",
    "indicate a better fit of the model to the data.\n",
    "\n",
    "References: \n",
    "- https://medium.com/@xaviergeerinck/artificial-intelligence-how-to-measure-performance-accuracy-precision-recall-f1-roc-rmse-611d10e4caac\n",
    "- https://www.kaggle.com/residentmario/model-fit-metrics#Root-mean-squared-error-(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhPcLCteQy6j",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def rmse_score(y, y_pred):\n",
    "    score = rmse(y, y_pred)\n",
    "    message = \"RMSE score: {:.4f}\".format(score)\n",
    "    return score, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ3nr3D_AE85"
   },
   "source": [
    "### Cross-Validation RMSLE score\n",
    "\n",
    "Another evaluation metric you will employ is the Root Mean Squared Logarithmic Error (RMSLE) score, calculated through\n",
    "cross-validation. Cross-validation is a robust technique that averages measures of prediction accuracy to derive a more\n",
    "precise estimate of model performance.\n",
    "\n",
    "The RMSLE score is especially valuable in your situation as it penalizes underestimates more than overestimates.\n",
    "Therefore, it is an essential metric for a bike sharing demand prediction model, ensuring that you avoid scenarios\n",
    "where the available number of bikes falls short of the demand.\n",
    "\n",
    "References: \n",
    "- https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "- https://www.kaggle.com/carlolepelaars/understanding-the-metric-rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H9CZAP2ASe6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmsle_clip(estimator, x, y):\n",
    "    \"\"\"Clip negative prediction numbers before calculating RMSLE.\"\"\"\n",
    "    y_pred = estimator.predict(x)\n",
    "    y_pred_clipped = np.clip(y_pred, a_min=0, a_max=None)\n",
    "    return sklearn.metrics.mean_squared_log_error(y, y_pred_clipped, squared=False)\n",
    "\n",
    "def rmsle_cv(model, X_train, y_train):\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    # Evaluate RMSLE score by cross-validation\n",
    "    rmsle = cross_val_score(model, X_train.values, y_train, scoring=rmsle_clip, cv=kf, error_score=\"raise\")\n",
    "    return rmsle\n",
    "\n",
    "def rmsle_cv_score(model, X_train, y_train):\n",
    "    score = rmsle_cv(model, X_train, y_train)\n",
    "    message = \"Cross-Validation RMSLE score: {:.4f} (std = {:.4f})\".format(score.mean(), score.std())\n",
    "    return score, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad0mABWEarsA"
   },
   "source": [
    "## Feature Importance\n",
    "\n",
    "In this section, you will analyze the importance of each feature in the dataset. Feature importance refers to techniques\n",
    "that assign a score to input features based on how useful they are at predicting a target variable.\n",
    "\n",
    "Understanding which features are most influential in predicting the target variable can provide valuable insights into\n",
    "the dataset and the underlying model. This can help you interpret the model's predictions, and can guide further data\n",
    "collection and feature engineering efforts.\n",
    "\n",
    "References:\n",
    "- https://medium.com/bigdatarepublic/feature-importance-whats-in-a-name-79532e59eea3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZ7kzjbOWae8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_feature_importance(model):\n",
    "    feature_importance = pd.DataFrame(\n",
    "        model.feature_importances_,\n",
    "        index=X_train.columns,\n",
    "        columns=[\"Importance\"])\n",
    "\n",
    "    # sort by importance\n",
    "    feature_importance.sort_values(by=\"Importance\", ascending=False, inplace=True)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(\n",
    "        data=feature_importance.reset_index(),\n",
    "        y=\"index\",\n",
    "        x=\"Importance\",\n",
    "    ).set_title(\"Feature Importance\")\n",
    "\n",
    "    # save image\n",
    "    plt.savefig(\"model_artifacts/feature_importance.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYfCxPo8w-Gn"
   },
   "source": [
    "## Permutation Importance\n",
    "\n",
    "Permutation Importance is a technique used to measure feature importance. It works by randomly shuffling a single\n",
    "feature in the validation data and measuring the decrease in the model's performance. The features that cause the most\n",
    "significant drop in performance are considered the most important.\n",
    "\n",
    "This method provides a straightforward way to interpret the influence of each feature on the model's predictions. It can\n",
    "help you understand which features are driving the model's decisions and where you might focus your attention for\n",
    "further data analysis or feature engineering.\n",
    "\n",
    "References:\n",
    "- https://www.kaggle.com/dansbecker/permutation-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_vzVVbGcS6M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_permutation_importance(model):\n",
    "    p_importance = permutation_importance(model, X_test, y_test, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # sort by importance\n",
    "    sorted_idx = p_importance.importances_mean.argsort()[::-1]\n",
    "    p_importance = pd.DataFrame(\n",
    "        data=p_importance.importances[sorted_idx].T,\n",
    "        columns=X_train.columns[sorted_idx]\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(\n",
    "        data=p_importance,\n",
    "        orient=\"h\"\n",
    "    ).set_title(\"Permutation Importance\")\n",
    "\n",
    "    # save image\n",
    "    plt.savefig(\"model_artifacts/permutation_importance.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "warpAv8RFSOI"
   },
   "source": [
    "## MLflow Tracking\n",
    "\n",
    "In this phase, you will use MLflow Tracking, a component of MLflow that logs and tracks experiment data. This includes\n",
    "parameters, metrics, and artifacts of machine learning models during the training process.\n",
    "\n",
    "MLflow Tracking provides a centralized repository for metadata associated with your experiments, making it easier to\n",
    "compare different runs, reproduce results, and share findings with your team. This is a crucial step in maintaining an\n",
    "organized and efficient machine learning workflow.\n",
    "\n",
    "First, let's setup the logger.\n",
    "\n",
    "References:\n",
    "- https://www.mlflow.org/docs/latest/cli.html#mlflow-ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyQRcKslAwv-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Track params and metrics\n",
    "def log_mlflow_run(model, signature):\n",
    "    # Auto-logging for scikit-learn estimators\n",
    "    # mlflow.sklearn.autolog()\n",
    "\n",
    "    # log estimator_name name\n",
    "    name = model.__class__.__name__\n",
    "    mlflow.set_tag(\"estimator_name\", name)\n",
    "\n",
    "    # log input features\n",
    "    mlflow.set_tag(\"features\", str(X_train.columns.values.tolist()))\n",
    "\n",
    "    # Log tracked parameters only\n",
    "    mlflow.log_params({key: model.get_params()[key] for key in parameters})\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        'RMSLE_CV': score_cv.mean(),\n",
    "        'RMSE': score})\n",
    "\n",
    "    # log training loss\n",
    "    for s in model.train_score_:\n",
    "        mlflow.log_metric(\"Train Loss\", s)\n",
    "\n",
    "    # Save model to artifacts\n",
    "    mlflow.sklearn.log_model(model, \"model\")#, signature=signature)\n",
    "\n",
    "    # log charts\n",
    "    mlflow.log_artifacts(\"model_artifacts\")\n",
    "\n",
    "    # misc\n",
    "    # Log all model parameters\n",
    "    # mlflow.log_params(model.get_params())\n",
    "    mlflow.log_param(\"Training size\", X_test.size) \n",
    "    mlflow.log_param(\"Test size\", y_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDAdPTeDTjr1"
   },
   "source": [
    "## Model Training and Hyperparameter Tuning\n",
    "\n",
    "In this section, you will focus on training the model and tuning its hyperparameters. For this particular use case, you\n",
    "will employ the following approach:\n",
    "\n",
    "- Approach: You will use a Supervised Learning method, specifically a Decision Tree model. Decision Trees are intuitive\n",
    "  and easy-to-interpret models that make decisions based on a set of rules inferred from the features.\n",
    "- Tree Type: Given that the task is to predict a continuous target variable (the count of total rental bikes), you will\n",
    "  use a Regression Tree.\n",
    "- Technique/Ensemble Method: To improve the performance of your Decision Tree model, you will use an ensemble method\n",
    "  known as Gradient Boosting. Gradient Boosting combines several weak learners (in this case, Decision Trees) to create\n",
    "  a robust predictive model. It trains models in a gradual, additive, and sequential manner, with each new model\n",
    "  correcting the errors made by the previous ones.\n",
    "\n",
    "By carefully tuning the hyperparameters of your Gradient Boosting model, you can optimize its performance and ensure it\n",
    "generalizes well to new data.\n",
    "\n",
    "References:\n",
    "- GBRT (Gradient Boosted Regression Tree): https://orbi.uliege.be/bitstream/2268/163521/1/slides.pdf\n",
    "- Choosing a model: https://scikit-learn.org/stable/tutorial/machine_learning_map\n",
    "- Machine Learning Models Explained\n",
    ": https://docs.paperspace.com/machine-learning/wiki/machine-learning-models-explained\n",
    "- Gradient Boosted Regression Trees: https://orbi.uliege.be/bitstream/2268/163521/1/slides.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSbcPvkBThXV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GBRT (Gradient Boosted Regression Tree) scikit-learn implementation \n",
    "model_class = GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7BYFTSRzLk2"
   },
   "source": [
    "Set the training's process hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Mu88JOkMiJF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    # \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnUDX2p2j9p_",
    "tags": []
   },
   "source": [
    "To optimize the performance of your model, you will tune its hyperparameters using a method known as Grid Search.\n",
    "\n",
    "Grid Search is a traditional method for hyperparameter tuning. It works by defining a grid of hyperparameters and then\n",
    "evaluating the model performance for each point on the grid. You can think of this as an exhaustive search through a\n",
    "manually specified subset of the hyperparameter space of the chosen algorithm.\n",
    "\n",
    "By using Grid Search, you can systematically work through multiple combinations of hyperparameters to determine the\n",
    "optimal values that improve the performance of the model. This process can significantly enhance the predictive accuracy\n",
    "of your model.\n",
    "\n",
    "References:\n",
    "- More advanced tuning techniques: https://research.fb.com/efficient-tuning-of-online-systems-using-bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CybsVlgCw6n9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate parameters combinations\n",
    "params_keys = parameters.keys()\n",
    "params_values = [\n",
    "    parameters[key] if isinstance(parameters[key], list) else [parameters[key]]\n",
    "    for key in params_keys]\n",
    "\n",
    "runs_parameters = [\n",
    "    dict(zip(params_keys, combination))\n",
    "         for combination in itertools.product(*params_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u23-Tpn_0X7d"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Now that you have prepared the data and set up the model, the next step is to train the model. During this process, the\n",
    "model will learn from the features of the training data to predict the target variable.\n",
    "\n",
    "Model training involves adjusting the model to minimize the difference between the predicted and actual values, a\n",
    "process guided by a specific learning algorithm. In your case, you are using a Gradient Boosting model, which will learn\n",
    "to correct its errors in a gradual, additive, and sequential manner.\n",
    "\n",
    "This is a crucial step in the machine learning workflow, as the quality of the model's predictions heavily depends on\n",
    "the effectiveness of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "Le6sa7jjg37v",
    "outputId": "7e8c3e45-e75a-45ce-8157-38b097d623cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training loop\n",
    "for i, run_parameters in enumerate(runs_parameters):\n",
    "    # mlflow: stop active runs if any\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "    # mlflow:track run\n",
    "    mlflow.start_run(run_name=f\"Run {i}\")\n",
    "\n",
    "    # create model instance\n",
    "    model = model_class(**run_parameters)\n",
    "\n",
    "    # train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # get evaluations scores\n",
    "    ypred = model.predict(X_test)\n",
    "    score, message = rmse_score(y_test, model.predict(X_test))\n",
    "    score_cv, message_cv = rmsle_cv_score(model, X_train, y_train)\n",
    "\n",
    "    # get model signature\n",
    "    signature = infer_signature(model_input=X_train,\n",
    "                                model_output=model.predict(X_train))\n",
    "\n",
    "    # mlflow: log metrics\n",
    "    log_mlflow_run(model, signature)\n",
    "\n",
    "    # mlflow: end tracking\n",
    "    mlflow.end_run()\n",
    "\n",
    "    print(f\"Learning Rate: {run_parameters['learning_rate']}\\n\"\n",
    "          f\"Max Depth: {run_parameters['max_depth']}\\n\"\n",
    "          f\"{message}\\n\"\n",
    "          f\"{message_cv}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOHX6U3ABTSE"
   },
   "source": [
    "## Best Model Results\n",
    "\n",
    "After training several models and tuning their hyperparameters, you will identify the model that performs the best\n",
    "according to the chosen evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5jKy850zKtS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_run_df = mlflow.search_runs(order_by=['metrics.RMSLE_CV ASC'],\n",
    "                                 max_results=1)\n",
    "if len(best_run_df.index) == 0:\n",
    "    raise Exception(f\"Found no runs for experiment '{experiment_name}'\")\n",
    "\n",
    "best_run = mlflow.get_run(best_run_df.at[0, 'run_id'])\n",
    "best_model_uri = f\"{best_run.info.artifact_uri}/model\"\n",
    "best_model = mlflow.sklearn.load_model(best_model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "wHVM74A--4-C",
    "outputId": "b28470ff-aa99-4f19-c124-d4b9c3a88233",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print best run info\n",
    "print(\"Best run info:\")\n",
    "print(f\"Run id: {best_run.info.run_id}\")\n",
    "print(f\"Run parameters: {best_run.data.params}\")\n",
    "print(f\"Run score: RMSLE_CV = {best_run.data.metrics['RMSLE_CV']:.4f}\")\n",
    "print(f\"Run model URI: {best_model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "WmjSO3vhCP7u",
    "outputId": "52e2c4ac-4aeb-44b8-d65d-7d2de8122fb8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_feature_importance(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "LQRJKFuJCSBZ",
    "outputId": "3a60cd14-f402-4304-ee8c-7f3647be4721",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_permutation_importance(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDhu91aa8vuw"
   },
   "source": [
    "## Model Testing\n",
    "\n",
    "Once you have identified the best model, the next step is to test its predictive performance on unseen data. This is\n",
    "done using the test dataset, which has been set aside specifically for this purpose.\n",
    "\n",
    "Testing the model's predictions allows you to evaluate how well the model generalizes to new data. This is a crucial\n",
    "step in the machine learning process, as it provides a realistic estimate of the model's performance in a real-world\n",
    "setting.\n",
    "\n",
    "You will compare the model's predictions with the actual values in the test dataset and calculate your chosen evaluation\n",
    "metrics. These results will give you a clear indication of the model's predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "EiQwrb7TK40n",
    "outputId": "709d749f-bc0d-4b68-c2c4-8c1a0197eca6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = X_test.copy()\n",
    "# real output (rented_bikes) from test dataset\n",
    "test_predictions[\"rented_bikes\"] = y_test\n",
    "\n",
    "# add \"predicted_rented_bikes\" from test dataset\n",
    "test_predictions[\"predicted_rented_bikes\"] = best_model.predict(X_test).astype(int)\n",
    "\n",
    "# show results\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "id": "SwfQEr_NGlDa",
    "outputId": "e153d67b-b13f-4b13-bbe9-542eed7442a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot truth vs prediction values\n",
    "test_predictions.plot(\n",
    "    kind=\"scatter\",\n",
    "    x=\"rented_bikes\",\n",
    "    y=\"predicted_rented_bikes\",\n",
    "    title=\"Rented bikes vs predicted rented bikes\",\n",
    "    figsize=(10, 10)\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "In this section of the notebook, you will focus on deploying the trained model and bridge the gap between insightful\n",
    "data analysis and tangible real-world impact. For this, you will be using KServe, an open-source platform that\n",
    "facilitates the deployment and management of machine learning models at scale. It provides a robust and scalable\n",
    "infrastructure to serve predictions from trained models in production environments. The backend that you'll be using for\n",
    "KServe is Seldon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = f\"\"\"\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: kserve-minio-sa\n",
    "secrets:\n",
    "- name: {os.getenv('USER')}-objectstore-secret\n",
    "\n",
    "---\n",
    "apiVersion: \"serving.kserve.io/v1beta1\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"bike-sharing\"\n",
    "spec:\n",
    "  predictor:\n",
    "    serviceAccountName: kserve-minio-sa\n",
    "    sklearn:\n",
    "      protocolVersion: \"v2\"\n",
    "      storageUri: \"{best_model_uri}\"\n",
    "\"\"\"\n",
    "\n",
    "os.makedirs(\"manifests\", exist_ok=True)\n",
    "\n",
    "with open(os.path.join(\"manifests\", \"isvc.yaml\"), \"w\") as f:\n",
    "    f.write(manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = subprocess.run([\"kubectl\", \"apply\", \"-f\", \"manifests/isvc.yaml\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUyEIXKPIvKiU5I2T//pwx",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MLflow-example-notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bike-sharing",
   "language": "python",
   "name": "bike-sharing"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gcr.io/mapr-252711/kubeflow/notebooks/jupyter-data-science:ezaf-fy23-q3",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:add-external-df-volume:true",
    "label:add-ldapcert-secret:true",
    "label:add-sssd-secret:true",
    "label:add-user-s3-secret:true"
   ],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
