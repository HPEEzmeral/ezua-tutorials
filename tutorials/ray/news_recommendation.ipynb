{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Good Hyperparameter For News Recommendation System With Tune\n",
    "\n",
    "The goal of this example is to train a very simple news recommendation system, We will:\n",
    "- Prepare the training data in parallel with Ray\n",
    "- Train a simple model that classifies article titles as \"popular\" or \"less popular\" using scikit learn and\n",
    "- Find good hyperparameter settings for the model with Tune, Ray's parallel hyperparameter optimization library.\n",
    "\n",
    "### Downloading And Preparing The Training Data\n",
    "\n",
    "First we will download and uncompress 400,000 hackernews submissions. This is a small subset of the articles that have been submitted to https://news.ycombinator.com. The data includes the title of each submission and its score, which roughly corresponds to the number of upvotes. There are 4 batches of JSON files that contain the information, named `submission-1.json` through `submission-4.json`. The first couple lines of the first file will be printed below by the `head` command. Delete zip file as we have already extracted the required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-24 15:54:00--  https://s3-us-west-2.amazonaws.com/ray-tutorials/hackernews.zip\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.213.128, 52.218.246.136, 52.218.219.32, ...\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.213.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 56402193 (54M) [application/zip]\n",
      "Saving to: ‘hackernews.zip’\n",
      "\n",
      "hackernews.zip      100%[===================>]  53.79M  18.6MB/s    in 2.9s    \n",
      "\n",
      "2023-01-24 15:54:03 (18.6 MB/s) - ‘hackernews.zip’ saved [56402193/56402193]\n",
      "\n",
      "Archive:  hackernews.zip\n",
      "  inflating: submission-1.json       \n",
      "  inflating: submission-2.json       \n",
      "  inflating: submission-3.json       \n",
      "  inflating: submission-4.json       \n",
      "{\"body\": {\"descendants\": 0, \"url\": \"http://markpincus.blogspot.com/2005/03/peopleweb-i-believe-we-are-close-to.html\", \"text\": \"\", \"title\": \"The PeopleWeb | Mark Pincus Blog (March 2005)\", \"by\": \"sayemm\", \"score\": 3, \"time\": 1286515576, \"type\": \"story\", \"id\": 1770734}, \"source\": \"firebase\", \"id\": 1770734, \"retrieved_at_ts\": 1436469924}\n",
      "{\"body\": {\"descendants\": 0, \"url\": \"http://omergertel.com/2010/11/16/honing-my-craft/\", \"text\": \"\", \"title\": \"Computer science and programming are two separate things\", \"by\": \"omergertel\", \"score\": 1, \"time\": 1289946709, \"type\": \"story\", \"id\": 1911996}, \"source\": \"firebase\", \"id\": 1911996, \"retrieved_at_ts\": 1436484897}\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://s3-us-west-2.amazonaws.com/ray-tutorials/hackernews.zip\n",
    "!unzip -o hackernews.zip\n",
    "!head -n 2 submission-1.json\n",
    "!rm -rf \"hackernews.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==1.3.2 in /home/jovyan/.local/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.2) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.2) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.2) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/jovyan/.local/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/jovyan/.local/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jovyan/.local/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/jovyan/.local/lib/python3.8/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 15:54:37,080\tINFO packaging.py:546 -- Creating a file package for local directory './'.\n",
      "2023-01-24 15:54:37,121\tWARNING packaging.py:420 -- File /home/jovyan/user/sercan/submission-1.json is very large (39.13MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/jovyan/user/sercan/submission-1.json']})`\n",
      "2023-01-24 15:54:37,172\tWARNING packaging.py:420 -- File /home/jovyan/user/sercan/submission-4.json is very large (35.09MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/jovyan/user/sercan/submission-4.json']})`\n",
      "2023-01-24 15:54:37,263\tWARNING packaging.py:420 -- File /home/jovyan/user/sercan/submission-2.json is very large (38.47MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/jovyan/user/sercan/submission-2.json']})`\n",
      "2023-01-24 15:54:37,354\tWARNING packaging.py:420 -- File /home/jovyan/user/sercan/submission-3.json is very large (36.67MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/jovyan/user/sercan/submission-3.json']})`\n",
      "2023-01-24 15:54:37,573\tINFO packaging.py:373 -- Pushing file package 'gcs://_ray_pkg_3fd8ce61f6676437.zip' (149.47MiB) to Ray cluster...\n",
      "2023-01-24 15:54:39,089\tINFO packaging.py:386 -- Successfully pushed file package 'gcs://_ray_pkg_3fd8ce61f6676437.zip'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.244.3.8:8265\" target=\"_blank\">http://10.244.3.8:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='10.244.3.8:8265', python_version='3.8.13', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', protocol_version='2022-10-05', _num_clients=2, _context_to_restore=<ray.util.client._ClientContext object at 0x7fa14532b910>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ray.init(address=\"ray://kuberay-head-svc.kuberay:10001\", runtime_env={\"working_dir\": \"./\"})\n",
    "\n",
    "# Run this line, all required packages exist in Ray cluster\n",
    "ray.init(address=\"ray://kuberay-head-svc.kuberay:10001\", runtime_env={\"working_dir\": \"./\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below parses a chunk of the data and produces a pandas DataFrame with the titles and scores of the submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hn_submissions(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        records = []\n",
    "        for line in f.readlines():\n",
    "            body = json.loads(line)[\"body\"]\n",
    "            records.append({\"data\": body[\"title\"], \"score\": body[\"score\"]})\n",
    "        return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now process all the data chunks and concatenate them into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 3.5356011390686035 seconds to parse the hackernews submissions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The PeopleWeb | Mark Pincus Blog (March 2005)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer science and programming are two separ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't Go It Alone: Create an Advisory Board</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wikileaks Secret Dreams</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MakeMyTrip.com: Is eCommerce in India Finall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  score\n",
       "0      The PeopleWeb | Mark Pincus Blog (March 2005)      3\n",
       "1  Computer science and programming are two separ...      1\n",
       "2        Don't Go It Alone: Create an Advisory Board      1\n",
       "3                            Wikileaks Secret Dreams      1\n",
       "4    MakeMyTrip.com: Is eCommerce in India Finall...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "files = [\"submission-\" + str(i) + \".json\" for i in range(1, 5)]\n",
    "records = [parse_hn_submissions(file) for file in files]\n",
    "df = pd.concat(records)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(\"Took {} seconds to parse the hackernews submissions\".format(duration))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following lines to determine a cutoff of what we consider a \"good\" article. The median score for articles is 1, so we want to label articles with score higher than that as class \"1\" and everything else as \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"score\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[\"score\"] > 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note: If above line gives error, try lowering down the version of pandas to 1.3.2 by uncommenting and running below line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas==1.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now done preparing the data and can start training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training A Model\n",
    "\n",
    "\n",
    "First we split the data into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following defines a pipeline that first converts the title of the submission to a bag of words and then applies an SVM for the actual classification. Note that we are fitting a very simple SVM here due to the computational restrictions of Binder. With more resources, a state-of-the-art model like [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) would be a better choice, in this case the code would be structured similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpedemouser01/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set is 0.585496875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"clf\", SGDClassifier(loss=\"hinge\", penalty=\"l2\",\n",
    "                          alpha=0.001,\n",
    "                          max_iter=5, tol=1e-3,\n",
    "                          warm_start=True))])\n",
    "result = pipeline.fit(train.data, train.target)\n",
    "\n",
    "predicted = result.predict(train.data)\n",
    "print(\"Accuracy on the training set is {}\".format(np.mean(predicted == train.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set is 0.5814625\n"
     ]
    }
   ],
   "source": [
    "predicted = pipeline.predict(test.data)\n",
    "print(\"Accuracy on the test set is {}\".format(np.mean(predicted == test.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also classify new titles as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"Iconic consoles of the IBM System/360 mainframes, 55 years old today\", \"Are Banned Drugs in Your Meat?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to improve these results by doing some hyperparameter tuning. Hyperparameter tuning is the process of finding the best parameters for the learning algorithm. These parameters are typically few numbers like learning rate schedule (i.e. how large steps to take in each iteration), regularization parameters or size of the model. By tuning these knobs, we can typically make the model perform better. Tune supports a number of different algorithms to perform hyperparameter tuning. The simplest is a grid search where we just exhaustively try out different values for the parameters. More sophisticated algorithms include hyperband and population based training. If you want to learn more about these, check out the [tune documentation](https://ray.readthedocs.io/en/latest/tune.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to put the training data into the object store (to make sure it will be re-used between training runs), and define the objective function. The objective function `train_func` takes two arguments: The `config` argument which contains the hyperparameters for that hyperparameter run. The `reporter` object can be used to report the performance of these hyperparameters back to tune so it can select the next trial based on the performance of the past ones.\n",
    "\n",
    "The following function instantiates a model corresponding to the hyperparameters in `config`, runs 5 iterations of training and saves the model parameters to a checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = ray.put(train)\n",
    "test_id = ray.put(test)\n",
    "\n",
    "def train_func(config, reporter):\n",
    "    pipeline = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"clf\", SGDClassifier(loss=\"hinge\", penalty=\"l2\",\n",
    "                          alpha=config[\"alpha\"],\n",
    "                          max_iter=5, tol=1e-3,\n",
    "                          warm_start=True))])\n",
    "    train = ray.get(train_id)\n",
    "    test = ray.get(test_id)\n",
    "    for i in range(5):\n",
    "        # Perform one epoch of SGD\n",
    "        X = pipeline.named_steps[\"vect\"].fit_transform(train.data)\n",
    "        pipeline.named_steps[\"clf\"].partial_fit(X, train.target, classes=[0, 1])\n",
    "        reporter(mean_accuracy=np.mean(pipeline.predict(test.data) == test.target))  # report metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get the best setting for the regularization parameter $\\alpha$ as follows. **You should expect the training to take about 4-5 minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_trials = tune.run(\n",
    "    train_func,\n",
    "    name=\"news_recommendation\",\n",
    "    # With the \"stop\" parameter, you could also specify a stopping criterion.\n",
    "    config={\"alpha\": tune.grid_search([1e-3, 1e-4, 1e-5, 1e-6])}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "From Trial Status table, considering metrics accuracy we can get optimized value for it.\n",
    "Get the best trial from all trials as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_func_ac062_00001\n"
     ]
    }
   ],
   "source": [
    "best_trial = all_trials.get_best_trial(metric=\"mean_accuracy\", mode=\"max\", scope=\"all\")\n",
    "print(best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "With this example, we ran trials for alpha parameter tuning using Ray Tune.\n",
    "Shut down the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
