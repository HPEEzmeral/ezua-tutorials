apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: nvidia-nim-nv-embedqa-e5-v5-1.0.1
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8000"
    serving.kserve.io/enable-metric-aggregation: "true"
    serving.kserve.io/enable-prometheus-scraping: "true"
  containers:
  - env:
    - name: NIM_MODEL_PROFILE
      value: "onnx"
    - name: NIM_CACHE_PATH
      value: /mnt/models
    image: {{ .Values.clusterServingRuntime.image.repository }}:{{ .Values.clusterServingRuntime.image.tag }}
    name: kserve-container
    ports:
    - containerPort: 8000
      protocol: TCP
    resources:
      limits:
        cpu: "16000m"
        memory: 32Gi
      requests:
        cpu: "4000m"
        memory: 16Gi
    volumeMounts:
    - mountPath: /dev/shm
      name: dshm
  protocolVersions:
  - v2
  - grpc-v2
  supportedModelFormats:
  - autoSelect: true
    name:  nvidia-nim-nv-embedqa-e5-v5
    priority: 1
    version: "1.0.1"
  volumes:
  - emptyDir:
      medium: Memory
      sizeLimit: 16Gi
    name: dshm