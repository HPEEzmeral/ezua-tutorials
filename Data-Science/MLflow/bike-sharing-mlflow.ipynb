{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7wSVnqQ7xZB"
   },
   "source": [
    "# Bike Sharing (MLFlow - KServe)\n",
    "\n",
    "This notebook provides a detailed walkthrough of a comprehensive data science workflow, encompassing data preprocessing, model training and evaluation, hyperparameter tuning, experiment tracking via MLFlow, and model deployment using Seldon and KServe. The use case under consideration is the well-known bike sharing dataset, sourced from the UCI Machine Learning Repository.\n",
    "\n",
    "![bike-sharing](images/bike-sharing.jpg)\n",
    "(Photo by <a href=\"https://unsplash.com/@zaccastravels?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">ZACHARY STAINES</a> on <a href=\"https://unsplash.com/photos/KEhNcoCldbk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>\n",
    "  )\n",
    "\n",
    "The dataset records the hourly and daily count of rental bikes between 2011 and 2012 in the Capital Bikeshare system, supplemented with corresponding weather and seasonal data. The primary objective of this dataset is to foster research into bike sharing systems, which are gaining significant attention due to their implications on traffic management, environmental sustainability, and public health.\n",
    "\n",
    "The task associated with this dataset is regression, with 17,389 instances. The overarching goal is to construct a predictive model capable of forecasting bike rental demand. The primary target variable for prediction is the `cnt` attribute, representing the total count of rental bikes, inclusive of both casual and registered users.\n",
    "\n",
    "By leveraging the other features in the dataset (such as date, season, year, month, hour, holiday, weekday, working day, weather conditions, temperature, perceived temperature, humidity, and wind speed), you can train a model to predict this count with high accuracy.\n",
    "\n",
    "**References:**\n",
    "- https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\n",
    "- https://docs.databricks.com/_static/notebooks/gbt-regression.html\n",
    "- https://www.kaggle.com/pratsiuk/mlflow-experiment-automation-top-9\n",
    "- https://mlflow.org/docs/latest/tracking.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "The subsequent code cells are dedicated to importing the requisite dependencies and adjusting the logging level to `ERROR`. Additionally, it's recommended to establish a local directory for preserving the training artifacts generated during your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from functools import partial\n",
    "\n",
    "import git\n",
    "import boto3\n",
    "import kserve\n",
    "import sklearn\n",
    "import ipywidgets as widgets\n",
    "import s3transfer\n",
    "import requests\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from pydotplus import graph_from_dot_data\n",
    "from IPython.display import Image, display\n",
    "from kubernetes import client, config\n",
    "from kubernetes.client import V1ObjectMeta, V1Secret, V1ServiceAccount, V1ObjectReference, V1Container, V1EnvVar\n",
    "from kserve import (V1beta1InferenceService, V1beta1InferenceServiceSpec, V1beta1SKLearnSpec,\n",
    "                    V1beta1PredictorSpec, V1beta1ModelSpec, V1beta1ModelFormat)\n",
    "\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Get all loggers\n",
    "loggers = logging.Logger.manager.loggerDict.values()\n",
    "\n",
    "# Iterate over all loggers and set their level to ERROR\n",
    "# as we don't want to polute the output of the code cells\n",
    "# with debugging messages.\n",
    "for logger in loggers:\n",
    "    if isinstance(logger, logging.Logger):\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"model_artifacts\"):\n",
    "    os.system(\"rm -rf model_artifacts\")\n",
    "os.mkdir(\"model_artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Authentication Process\n",
    "\n",
    "The subsequent step involves authenticating yourself with MLFlow. This is crucial for tracking your experiments and storing the training artifacts. Utilize your user credentials to establish a connection with the MLFlow service. Additionally, connect to the data fabric object store to preserve the metadata associated with your experiments. This ensures a comprehensive record of your work, facilitating future analysis and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add heading\n",
    "heading = widgets.HTML(\"<h2>MLflow Credentials</h2>\")\n",
    "display(heading)\n",
    "\n",
    "ezaf_env_input = widgets.Text(description='EZAF Env:')\n",
    "username_input = widgets.Text(description='Username:')\n",
    "password_input = widgets.Password(description='Password:')\n",
    "submit_button = widgets.Button(description='Submit')\n",
    "success_message = widgets.Output()\n",
    "\n",
    "ezaf_env = None\n",
    "mlflow_username = None\n",
    "mlflow_password = None\n",
    "\n",
    "def submit_button_clicked(b):\n",
    "    global ezaf_env, mlflow_username, mlflow_password\n",
    "    ezaf_env = ezaf_env_input.value\n",
    "    mlflow_username = username_input.value\n",
    "    mlflow_password = password_input.value\n",
    "    with success_message:\n",
    "        success_message.clear_output()\n",
    "        print(\"Credentials submitted successfully!\")\n",
    "    submit_button.disabled = True\n",
    "\n",
    "submit_button.on_click(submit_button_clicked)\n",
    "\n",
    "# Set margin on the submit button\n",
    "submit_button.layout.margin = '20px 0 20px 0'\n",
    "\n",
    "# Display inputs and button\n",
    "display(ezaf_env_input, username_input, password_input, submit_button, success_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EZAF_ENV = ezaf_env\n",
    "token_url = f\"https://keycloak.{EZAF_ENV}.com/realms/UA/protocol/openid-connect/token\"\n",
    "\n",
    "data = {\n",
    "    \"username\" : mlflow_username,\n",
    "    \"password\" : mlflow_password,\n",
    "    \"grant_type\" : \"password\",\n",
    "    \"client_id\" : \"ua-grant\",\n",
    "}\n",
    "\n",
    "token_responce = requests.post(token_url, data=data, allow_redirects=True, verify=False)\n",
    "\n",
    "token = token_responce.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add heading\n",
    "heading = widgets.HTML(\"<h2>Object Store Credentials</h2>\")\n",
    "display(heading)\n",
    "\n",
    "# Access Key and Secret Key inputs\n",
    "access_key_input = widgets.Text(description='Access Key:')\n",
    "secret_key_input = widgets.Password(description='Secret Key:')\n",
    "submit_button = widgets.Button(description='Submit')\n",
    "success_message = widgets.Output()\n",
    "\n",
    "minio_access_key = None\n",
    "minio_secret_key = None\n",
    "\n",
    "def submit_button_clicked(b):\n",
    "    global minio_access_key, minio_secret_key\n",
    "    minio_access_key = access_key_input.value\n",
    "    minio_secret_key = secret_key_input.value\n",
    "    with success_message:\n",
    "        success_message.clear_output()\n",
    "        print(\"Credentials submitted successfully!\")\n",
    "    submit_button.disabled = True\n",
    "\n",
    "submit_button.on_click(submit_button_clicked)\n",
    "\n",
    "# Set margin on the submit button\n",
    "submit_button.layout.margin = '20px 0 20px 0'\n",
    "\n",
    "# Display inputs and button\n",
    "display(access_key_input, secret_key_input, submit_button, success_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_experiment(exp_name):\n",
    "    \"\"\"Register an experiment in MLFlow.\n",
    "    \n",
    "    args:\n",
    "      exp_name (str): The name of the experiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        usr = \"hpedemo-user01\"\n",
    "        os.environ['MLFLOW_TRACKING_INSECURE_TLS'] = \"true\"\n",
    "        os.environ[\"AWS_ACCESS_KEY_ID\"] = minio_access_key\n",
    "        os.environ[\"AWS_SECRET_ACCESS_KEY\"] = minio_secret_key\n",
    "        os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"https://home.{EZAF_ENV}.com:31900\"\n",
    "        os.environ['MLFLOW_S3_IGNORE_TLS'] = \"true\"\n",
    "        os.environ['MLFLOW_TRACKING_TOKEN'] = token\n",
    "        mlflow.set_tracking_uri(f\"https://mlflow.{EZAF_ENV}.com\")\n",
    "        mlflow.set_experiment(exp_name)\n",
    "        mlflow.set_tag('mlflow.user', usr)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to set the experiment: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up an experiment with set_exp from ezmllib.mlflow\n",
    "experiment_name = 'bike-sharing-exp-07'\n",
    "set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwKZC40S-e0R"
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "With the preliminary setup complete, we can now proceed to load the dataset. The data is provided in a CSV format, which can be conveniently loaded using the Pandas library in Python. To get a glimpse of the dataset, we'll display the first five rows using the `head()` method of the DataFrame. This initial exploration will provide a snapshot of the data we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "1SZF_ZgD-gez",
    "outputId": "2dad51e5-5194-44af-c06c-5481c81d7639",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset is already available in github repository if not you can download and extract csv files as well.\n",
    "#!wget -e use_proxy=yes -e http_proxy=http://web-proxy.corp.hpecorp.net:8080 -nc \"http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\"\n",
    "#!unzip -o \"Bike-Sharing-Dataset.zip\"\n",
    "#!rm -rf \"Bike-Sharing-Dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "mFGzYdKCCNiK",
    "outputId": "8783bf81-d46a-4958-d2dc-59a324868a64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load input data into pandas dataframe\n",
    "bike_sharing = pd.read_csv(\"bike-sharing.csv\")\n",
    "bike_sharing.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQk3RQt2FB8x"
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "In this phase, we will prepare our data for the subsequent stages of our analysis. This involves cleaning, transforming, and structuring the data to ensure it is in the optimal format for our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "vyS5Ru5aE5Y7",
    "outputId": "5d0b2528-9664-437d-8e3f-61119fdaad5e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove unused columns\n",
    "bike_sharing.drop(columns=[\"instant\", \"dteday\", \"registered\", \"casual\"], inplace=True)\n",
    "\n",
    "# Use better names\n",
    "bike_sharing.rename(\n",
    "    columns={\n",
    "        \"yr\": \"year\",\n",
    "        \"mnth\": \"month\",\n",
    "        \"hr\": \"hour_of_day\",\n",
    "        \"holiday\": \"is_holiday\",\n",
    "        \"workingday\": \"is_workingday\",\n",
    "        \"weathersit\": \"weather_situation\",\n",
    "        \"temp\": \"temperature\",\n",
    "        \"atemp\": \"feels_like_temperature\",\n",
    "        \"hum\": \"humidity\",\n",
    "        \"cnt\": \"rented_bikes\",\n",
    "    }, inplace=True)\n",
    "\n",
    "# Convert every data point to `float64`\n",
    "cols = bike_sharing.select_dtypes(exclude=['float64']).columns\n",
    "for i in ['season', 'year', 'month', 'hour_of_day', 'is_holiday',\n",
    "          'weekday', 'is_workingday', 'weather_situation', 'rented_bikes']:\n",
    "    bike_sharing[i] = bike_sharing[i].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40MGTHbNFKTP"
   },
   "source": [
    "## Data Visualization\n",
    "\n",
    "In this section, we will employ various visualization techniques to better understand our data. By creating graphical representations of the data, we can identify patterns, trends, and correlations that might not be evident from the raw data alone. This step is crucial in guiding our subsequent analysis and model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "bNZOegwGHzUR",
    "outputId": "45a00d75-c019-4c39-96c4-08e3995fb381",
    "tags": []
   },
   "outputs": [],
   "source": [
    "hour_of_day_agg = bike_sharing.groupby([\"hour_of_day\"])[\"rented_bikes\"].sum()\n",
    "\n",
    "hour_of_day_agg.plot(\n",
    "    kind=\"line\", \n",
    "    title=\"Total rented bikes by hour of day\",\n",
    "    xticks=hour_of_day_agg.index,\n",
    "    figsize=(10, 5),\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMg_JKoUKq9j"
   },
   "source": [
    "## Prepare training and test data sets\n",
    "\n",
    "In this section, we will partition our data into training and test datasets. This is a crucial step in the machine learning workflow, allowing us to train our model on a subset of the data (the training set), and then evaluate its performance on unseen data (the test set). This process helps ensure that our model generalizes well to new data and is not simply memorizing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ZwtDgaZ9Ktie",
    "outputId": "4971f3d6-5e99-4583-acb6-4ef73892a633",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset randomly into 70% for training and 30% for testing.\n",
    "X = bike_sharing.drop(\"rented_bikes\", axis=1)\n",
    "y = bike_sharing.rented_bikes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.size}\")\n",
    "print(f\"Test samples: {X_test.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN0w6zFJSb87"
   },
   "source": [
    "## Establishing Evaluation Metrics\n",
    "\n",
    "Before proceeding to the training stage, we will define the evaluation metrics that will be used to assess the performance of our model. These metrics will provide quantitative measures of the model's accuracy, helping us understand how well our model is performing and where improvements can be made. This step is crucial in ensuring that our model meets the desired performance standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC1wzz_T_tSA"
   },
   "source": [
    "### Root Mean Square Error (RMSE)\n",
    "\n",
    "One of the evaluation metrics we will use is the Root Mean Square Error (RMSE). This metric provides a measure of the differences between the values predicted by our model and the actual values. By taking the square root of the average of these squared differences, RMSE gives us a sense of the magnitude of the prediction errors. Lower RMSE values indicate a better fit of the model to the data.\n",
    "\n",
    "References: \n",
    "- https://medium.com/@xaviergeerinck/artificial-intelligence-how-to-measure-performance-accuracy-precision-recall-f1-roc-rmse-611d10e4caac\n",
    "- https://www.kaggle.com/residentmario/model-fit-metrics#Root-mean-squared-error-(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhPcLCteQy6j",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def rmse_score(y, y_pred):\n",
    "    score = rmse(y, y_pred)\n",
    "    message = \"RMSE score: {:.4f}\".format(score)\n",
    "    return score, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ3nr3D_AE85"
   },
   "source": [
    "### Cross-Validation RMSLE score\n",
    "\n",
    "Another evaluation metric we will employ is the Root Mean Squared Logarithmic Error (RMSLE) score, calculated through cross-validation. Cross-validation is a robust technique that averages measures of prediction accuracy to derive a more precise estimate of model performance.\n",
    "\n",
    "The RMSLE score is especially valuable in your situation as it penalizes underestimates more than overestimates. Therefore, it is an essential metric for our bike sharing demand prediction model, ensuring that we avoid scenarios where the available number of bikes falls short of the demand.\n",
    "\n",
    "References: \n",
    "- https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "- https://www.kaggle.com/carlolepelaars/understanding-the-metric-rmsle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H9CZAP2ASe6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmsle_clip(estimator, x, y):\n",
    "    \"\"\"Clip negative prediction numbers before calculating RMSLE.\"\"\"\n",
    "    y_pred = estimator.predict(x)\n",
    "    y_pred_clipped = np.clip(y_pred, a_min=0, a_max=None)\n",
    "    return sklearn.metrics.mean_squared_log_error(y, y_pred_clipped, squared=False)\n",
    "\n",
    "def rmsle_cv(model, X_train, y_train):\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    # Evaluate RMSLE score by cross-validation\n",
    "    rmsle = cross_val_score(model, X_train.values, y_train, scoring=rmsle_clip, cv=kf, error_score=\"raise\")\n",
    "    return rmsle\n",
    "\n",
    "def rmsle_cv_score(model, X_train, y_train):\n",
    "    score = rmsle_cv(model, X_train, y_train)\n",
    "    message = \"Cross-Validation RMSLE score: {:.4f} (std = {:.4f})\".format(score.mean(), score.std())\n",
    "    return score, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad0mABWEarsA"
   },
   "source": [
    "## Feature Importance\n",
    "\n",
    "In this section, we will analyze the importance of each feature in our dataset. Feature importance refers to techniques that assign a score to input features based on how useful they are at predicting a target variable.\n",
    "\n",
    "Understanding which features are most influential in predicting the target variable can provide valuable insights into our dataset and the underlying model. This can help us interpret the model's predictions, and can guide further data collection and feature engineering efforts.\n",
    "\n",
    "References:\n",
    "- https://medium.com/bigdatarepublic/feature-importance-whats-in-a-name-79532e59eea3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZ7kzjbOWae8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_feature_importance(model):\n",
    "    feature_importance = pd.DataFrame(\n",
    "        model.feature_importances_,\n",
    "        index=X_train.columns,\n",
    "        columns=[\"Importance\"])\n",
    "\n",
    "    # sort by importance\n",
    "    feature_importance.sort_values(by=\"Importance\", ascending=False, inplace=True)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(\n",
    "        data=feature_importance.reset_index(),\n",
    "        y=\"index\",\n",
    "        x=\"Importance\",\n",
    "    ).set_title(\"Feature Importance\")\n",
    "\n",
    "    # save image\n",
    "    plt.savefig(\"model_artifacts/feature_importance.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYfCxPo8w-Gn"
   },
   "source": [
    "## Permutation Importance\n",
    "\n",
    "Permutation Importance is a technique used to measure feature importance. It works by randomly shuffling a single feature in the validation data and measuring the decrease in the model's performance. The features that cause the most significant drop in performance are considered the most important.\n",
    "\n",
    "This method provides a straightforward way to interpret the influence of each feature on the model's predictions. It can help us understand which features are driving the model's decisions and where we might focus our attention for further data analysis or feature engineering.\n",
    "\n",
    "References:\n",
    "- https://www.kaggle.com/dansbecker/permutation-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_vzVVbGcS6M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_permutation_importance(model):\n",
    "    p_importance = permutation_importance(model, X_test, y_test, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # sort by importance\n",
    "    sorted_idx = p_importance.importances_mean.argsort()[::-1]\n",
    "    p_importance = pd.DataFrame(\n",
    "        data=p_importance.importances[sorted_idx].T,\n",
    "        columns=X_train.columns[sorted_idx]\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(\n",
    "        data=p_importance,\n",
    "        orient=\"h\"\n",
    "    ).set_title(\"Permutation Importance\")\n",
    "\n",
    "    # save image\n",
    "    plt.savefig(\"model_artifacts/permutation_importance.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtQGsSNU8hWc"
   },
   "source": [
    "## Decision Tree Visualization\n",
    "\n",
    "In this section, we will visualize the decision tree model. A decision tree is a flowchart-like structure where each internal node represents a feature (or attribute), each branch represents a decision rule, and each leaf node represents an outcome.\n",
    "\n",
    "Visualizing the decision tree provides a clear understanding of how the model makes predictions. It allows us to see the decision paths and rules the model uses, making it one of the most interpretable machine learning models. This can be particularly useful when explaining the model's decisions to stakeholders.\n",
    "\n",
    "References:\n",
    "- https://towardsdatascience.com/visualizing-decision-trees-with-python-scikit-learn-graphviz-matplotlib-1c50b4aa68dc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxKIpaE-g-b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_tree_visualization(model):\n",
    "    # generate visualization\n",
    "    tree_dot_data = tree.export_graphviz(\n",
    "        # Get the first tree\n",
    "        # TODO: Visualize every tree\n",
    "        decision_tree=model.estimators_[0, 0],\n",
    "        label=\"all\",\n",
    "        feature_names=X_train.columns,\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        proportion=True,\n",
    "        impurity=False,\n",
    "        precision=1,\n",
    "    )\n",
    "\n",
    "    # save image\n",
    "    graph_from_dot_data(tree_dot_data).write_png(\"model_artifacts/Decision_Tree_Visualization.png\")\n",
    "\n",
    "    # show tree\n",
    "    return graphviz.Source(tree_dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "warpAv8RFSOI"
   },
   "source": [
    "## MLflow Tracking\n",
    "\n",
    "In this phase, we will utilize MLflow Tracking, a component of MLflow that logs and tracks experiment data. This includes parameters, metrics, and artifacts of machine learning models during the training process.\n",
    "\n",
    "MLflow Tracking provides a centralized repository for metadata associated with your experiments, making it easier to compare different runs, reproduce results, and share findings with your team. This is a crucial step in maintaining an organized and efficient machine learning workflow.\n",
    "\n",
    "First, let's setup the logger.\n",
    "\n",
    "References:\n",
    "- https://www.mlflow.org/docs/latest/cli.html#mlflow-ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyQRcKslAwv-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Track params and metrics\n",
    "def log_mlflow_run(model, signature):\n",
    "    # Auto-logging for scikit-learn estimators\n",
    "    # mlflow.sklearn.autolog()\n",
    "\n",
    "    # log estimator_name name\n",
    "    name = model.__class__.__name__\n",
    "    mlflow.set_tag(\"estimator_name\", name)\n",
    "\n",
    "    # log input features\n",
    "    mlflow.set_tag(\"features\", str(X_train.columns.values.tolist()))\n",
    "\n",
    "    # Log tracked parameters only\n",
    "    mlflow.log_params({key: model.get_params()[key] for key in parameters})\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        'RMSLE_CV': score_cv.mean(),\n",
    "        'RMSE': score})\n",
    "\n",
    "    # log training loss\n",
    "    for s in model.train_score_:\n",
    "        mlflow.log_metric(\"Train Loss\", s)\n",
    "\n",
    "    # Save model to artifacts\n",
    "    mlflow.sklearn.log_model(model, \"model\")#, signature=signature)\n",
    "\n",
    "    # log charts\n",
    "    mlflow.log_artifacts(\"model_artifacts\")\n",
    "\n",
    "    # misc\n",
    "    # Log all model parameters\n",
    "    # mlflow.log_params(model.get_params())\n",
    "    mlflow.log_param(\"Training size\", X_test.size) \n",
    "    mlflow.log_param(\"Test size\", y_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDAdPTeDTjr1"
   },
   "source": [
    "## Model Training and Hyperparameter Tuning\n",
    "\n",
    "In this section, we will focus on training our model and tuning its hyperparameters. For this particular use case, we will employ the following approach:\n",
    "\n",
    "- Approach: We will use a Supervised Learning method, specifically a Decision Tree model. Decision Trees are intuitive and easy-to-interpret models that make decisions based on a set of rules inferred from the features.\n",
    "- Tree Type: Given that our task is to predict a continuous target variable (the count of total rental bikes), we will use a Regression Tree. Regression Trees predict outcomes by learning simple decision rules inferred from the features.\n",
    "- Technique/Ensemble Method: To improve the performance of our Decision Tree model, we will use an ensemble method known as Gradient Boosting. Gradient Boosting combines several weak learners (in this case, Decision Trees) to create a robust predictive model. It trains models in a gradual, additive, and sequential manner, with each new model correcting the errors made by the previous ones.\n",
    "\n",
    "By carefully tuning the hyperparameters of our Gradient Boosting model, we can optimize its performance and ensure it generalizes well to new data.\n",
    "\n",
    "References:\n",
    "- GBRT (Gradient Boosted Regression Tree): https://orbi.uliege.be/bitstream/2268/163521/1/slides.pdf\n",
    "- Choosing a model: https://scikit-learn.org/stable/tutorial/machine_learning_map\n",
    "- Machine Learning Models Explained\n",
    ": https://docs.paperspace.com/machine-learning/wiki/machine-learning-models-explained\n",
    "- Gradient Boosted Regression Trees: https://orbi.uliege.be/bitstream/2268/163521/1/slides.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSbcPvkBThXV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GBRT (Gradient Boosted Regression Tree) scikit-learn implementation \n",
    "model_class = GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7BYFTSRzLk2"
   },
   "source": [
    "Set the training's process hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Mu88JOkMiJF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    # \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnUDX2p2j9p_",
    "tags": []
   },
   "source": [
    "To optimize the performance of our model, we will tune its hyperparameters using a method known as Grid Search.\n",
    "\n",
    "Grid Search is a traditional method for hyperparameter tuning. It works by defining a grid of hyperparameters and then evaluating the model performance for each point on the grid. You can think of this as an exhaustive search through a manually specified subset of the hyperparameter space of the chosen algorithm.\n",
    "\n",
    "By using Grid Search, we can systematically work through multiple combinations of hyperparameters to determine the optimal values that improve the performance of our model. This process can significantly enhance the predictive accuracy of our model.\n",
    "\n",
    "References:\n",
    "- More advanced tuning techniques: https://research.fb.com/efficient-tuning-of-online-systems-using-bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CybsVlgCw6n9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate parameters combinations\n",
    "params_keys = parameters.keys()\n",
    "params_values = [\n",
    "    parameters[key] if isinstance(parameters[key], list) else [parameters[key]]\n",
    "    for key in params_keys]\n",
    "\n",
    "runs_parameters = [\n",
    "    dict(zip(params_keys, combination)) for combination in itertools.product(*params_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u23-Tpn_0X7d"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Now that we have prepared our data and set up our model, the next step is to train the model. During this process, the model will learn from the features of our training data to predict the target variable.\n",
    "\n",
    "Model training involves adjusting the model to minimize the difference between the predicted and actual values, a process guided by a specific learning algorithm. In our case, we are using a Gradient Boosting model, which will learn to correct its errors in a gradual, additive, and sequential manner.\n",
    "\n",
    "This is a crucial step in our machine learning workflow, as the quality of the model's predictions heavily depends on the effectiveness of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "Le6sa7jjg37v",
    "outputId": "7e8c3e45-e75a-45ce-8157-38b097d623cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(runs_parameters),\n",
    "    # description='Training progress',\n",
    "    bar_style='info',\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "progress_text = widgets.Output()\n",
    "\n",
    "display(progress_bar, progress_text)\n",
    "\n",
    "# training loop\n",
    "for i, run_parameters in enumerate(runs_parameters):\n",
    "    progress_bar.description = f\"Run {i+1}/{len(runs_parameters)}\"\n",
    "    # mlflow: stop active runs if any\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "    # mlflow:track run\n",
    "    mlflow.start_run(run_name=f\"Run {i}\")\n",
    "\n",
    "    # create model instance\n",
    "    model = model_class(**run_parameters)\n",
    "\n",
    "    # train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # get evaluations scores\n",
    "    ypred = model.predict(X_test)\n",
    "    score, message = rmse_score(y_test, model.predict(X_test))\n",
    "    score_cv, message_cv = rmsle_cv_score(model, X_train, y_train)\n",
    "    \n",
    "    # generate charts\n",
    "    model_feature_importance(model)\n",
    "    plt.close()\n",
    "    model_permutation_importance(model)\n",
    "    plt.close()\n",
    "    # model_tree_visualization(model)\n",
    "\n",
    "    # get model signature\n",
    "    signature = infer_signature(model_input=X_train, model_output=model.predict(X_train))\n",
    "\n",
    "    # mlflow: log metrics\n",
    "    log_mlflow_run(model, signature)\n",
    "\n",
    "    # mlflow: end tracking\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    progress_bar.value = i + 1\n",
    "    \n",
    "    # Update progress text\n",
    "    with progress_text:\n",
    "        print(f\"Learning rate: {run_parameters['learning_rate']}\"\n",
    "              f\"\\tMax depth: {run_parameters['max_depth']}\")\n",
    "        print(message)\n",
    "        print(message_cv)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOHX6U3ABTSE"
   },
   "source": [
    "## Best Model Results\n",
    "\n",
    "After training several models and tuning their hyperparameters, we will identify the model that performs the best according to our chosen evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5jKy850zKtS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_run_df = mlflow.search_runs(order_by=['metrics.RMSLE_CV ASC'], max_results=1)\n",
    "if len(best_run_df.index) == 0:\n",
    "    raise Exception(f\"Found no runs for experiment '{experiment_name}'\")\n",
    "\n",
    "best_run = mlflow.get_run(best_run_df.at[0, 'run_id'])\n",
    "best_model_uri = f\"{best_run.info.artifact_uri}/model\"\n",
    "best_model = mlflow.sklearn.load_model(best_model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "wHVM74A--4-C",
    "outputId": "b28470ff-aa99-4f19-c124-d4b9c3a88233",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print best run info\n",
    "print(\"Best run info:\")\n",
    "print(f\"Run id: {best_run.info.run_id}\")\n",
    "print(f\"Run parameters: {best_run.data.params}\")\n",
    "print(f\"Run score: RMSLE_CV = {best_run.data.metrics['RMSLE_CV']:.4f}\")\n",
    "print(f\"Run model URI: {best_model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "WmjSO3vhCP7u",
    "outputId": "52e2c4ac-4aeb-44b8-d65d-7d2de8122fb8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_feature_importance(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "LQRJKFuJCSBZ",
    "outputId": "3a60cd14-f402-4304-ee8c-7f3647be4721",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_permutation_importance(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "fR2F0ex7CS4I",
    "outputId": "ff25041b-c91e-4372-ab49-514e350bc709",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_tree_visualization(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDhu91aa8vuw"
   },
   "source": [
    "## Model Testing\n",
    "\n",
    "Once we have identified our best model, the next step is to test its predictive performance on unseen data. This is done using the test dataset, which has been set aside specifically for this purpose.\n",
    "\n",
    "Testing the model's predictions allows us to evaluate how well our model generalizes to new data. This is a crucial step in the machine learning process, as it provides a realistic estimate of the model's performance in a real-world setting.\n",
    "\n",
    "We will compare the model's predictions with the actual values in the test dataset and calculate our chosen evaluation metrics. These results will give us a clear indication of the model's predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "EiQwrb7TK40n",
    "outputId": "709d749f-bc0d-4b68-c2c4-8c1a0197eca6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = X_test.copy()\n",
    "# real output (rented_bikes) from test dataset\n",
    "test_predictions[\"rented_bikes\"] = y_test\n",
    "\n",
    "# add \"predicted_rented_bikes\" from test dataset\n",
    "test_predictions[\"predicted_rented_bikes\"] = best_model.predict(X_test).astype(int)\n",
    "\n",
    "# show results\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "id": "SwfQEr_NGlDa",
    "outputId": "e153d67b-b13f-4b13-bbe9-542eed7442a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot truth vs prediction values\n",
    "test_predictions.plot(\n",
    "    kind=\"scatter\",\n",
    "    x=\"rented_bikes\",\n",
    "    y=\"predicted_rented_bikes\",\n",
    "    title=\"Rented bikes vs predicted rented bikes\",\n",
    "    figsize=(10, 10)\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "In this section of the notebook, you will focus on deploying the trained model\n",
    "and bridge the gap between insightful data analysis and tangible real-world impact.\n",
    "For this, you will be using KServe, an open-source platform that facilitates the deployment\n",
    "and management of machine learning models at scale. It provides a robust and scalable\n",
    "infrastructure to serve predictions from trained models in production environments. The\n",
    "backend that you'll be using for KServe is Seldon.\n",
    "\n",
    "Before diving into deployment, you should start by creating a secure environment for accessing the S3 endpoint. First, you define a Secret object, which securely holds the necessary credentials. Additionally, we create a ServiceAccount object, associating it with the secret to establish an identity for the deployment process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access Key and Secret Key inputs\n",
    "namespace_input = widgets.Text(description='Namespace:')\n",
    "submit_button = widgets.Button(description='Submit')\n",
    "success_message = widgets.Output()\n",
    "\n",
    "namespace = None\n",
    "\n",
    "def submit_button_clicked(b):\n",
    "    global namespace\n",
    "    namespace = namespace_input.value\n",
    "    with success_message:\n",
    "        success_message.clear_output()\n",
    "        print(\"Namespace submitted successfully!\")\n",
    "    submit_button.disabled = True\n",
    "\n",
    "submit_button.on_click(submit_button_clicked)\n",
    "\n",
    "# Set margin on the submit button\n",
    "submit_button.layout.margin = '20px 0 20px 0'\n",
    "\n",
    "# Display inputs and button\n",
    "display(namespace_input, submit_button, success_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k8s_client = client.CoreV1Api()\n",
    "\n",
    "minio_secret = V1Secret(\n",
    "    api_version=\"v1\",\n",
    "    kind=\"Secret\",\n",
    "    metadata=V1ObjectMeta(\n",
    "        name=\"kserve-minio-secret\",\n",
    "        namespace=namespace,\n",
    "        annotations={\n",
    "            \"serving.kserve.io/s3-endpoint\": f\"home.{EZAF_ENV}.com:31900\",\n",
    "            \"serving.kserve.io/s3-usehttps\": \"1\",\n",
    "            \"serving.kserve.io/s3-verifyssl\": \"0\",\n",
    "            \"serving.kserve.io/s3-useanoncredential\": \"false\",\n",
    "            \"serving.kserve.io/s3-cabundle\": \"\"}),\n",
    "    type=\"Opaque\",\n",
    "    string_data={\n",
    "        \"AWS_ACCESS_KEY_ID\": minio_access_key,\n",
    "        \"AWS_SECRET_ACCESS_KEY\": minio_secret_key})\n",
    "\n",
    "k8s_client.create_namespaced_secret(namespace, minio_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = V1ServiceAccount(\n",
    "    api_version=\"v1\",\n",
    "    kind=\"ServiceAccount\",\n",
    "    metadata=V1ObjectMeta(name=\"kserve-minio-sa\"),\n",
    "    secrets=[V1ObjectReference(\n",
    "        api_version=\"v1\",\n",
    "        kind=\"Secret\",\n",
    "        name=\"kserve-minio-secret\",\n",
    "        namespace=namespace)])\n",
    "\n",
    "k8s_client.create_namespaced_service_account(namespace, sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, you can configure your InferenceService (ISVC) object to create your deployment. Once the ISVC is ready, launch the `bike-sharing-prediction.ipynb` notebook to send your first request to your model's endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isvc = V1beta1InferenceService(\n",
    "    api_version=\"serving.kserve.io/v1beta1\",\n",
    "    kind=\"InferenceService\",\n",
    "    metadata=V1ObjectMeta(name=\"bike-sharing\"),\n",
    "    spec=V1beta1InferenceServiceSpec(\n",
    "        predictor=V1beta1PredictorSpec(\n",
    "            service_account_name=\"kserve-minio-sa\",\n",
    "            sklearn=V1beta1SKLearnSpec(\n",
    "                storage_uri=best_model_uri,\n",
    "                protocol_version=\"v2\"))))\n",
    "\n",
    "kserve_client = kserve.KServeClient()\n",
    "kserve_client.create(isvc, namespace=namespace)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUyEIXKPIvKiU5I2T//pwx",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MLflow-example-notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bike-sharing]",
   "language": "python",
   "name": "conda-env-.conda-bike-sharing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
