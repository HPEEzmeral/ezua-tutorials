{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98253c01-c048-43de-8c2a-ab8b033b60eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wind Turbine (Spark Demo)\n",
    "\n",
    "Welcome! In this experiment we delve into the world of wind turbines\n",
    "and harness the power of machine learning to predict their energy production!\n",
    "In this demonstration, we will be using Spark to explore and augment the training\n",
    "dataset and train a Gradient-Boosted Tree (GBT) regressor that will utilize various\n",
    "features, such as wind speed and direction, to estimate the power output of a\n",
    "wind turbine.\n",
    "\n",
    "<div><img src=\"images/wind-farm.jpg\" width=\"100%\"/>\n",
    "    <p>(Image generated by Stable Diffusion)</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "Wind turbines hold tremendous potential as a sustainable source of energy,\n",
    "capable of supplying a substantial portion of the world's power needs. However,\n",
    "the inherent unpredictability of power generation poses a challenge when it\n",
    "comes to optimizing this process.\n",
    "\n",
    "Fortunately, we have a powerful tool at our disposal: machine learning. By\n",
    "leveraging advanced algorithms and data analysis, we can develop models that\n",
    "accurately predict the power production of wind turbines. This enables us to\n",
    "optimize the power generation process and overcome the challenges associated\n",
    "with its ingrained variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c1d18-b1d1-4755-b2a1-465656177c30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a Spark Interactive Session\n",
    "\n",
    "Let's begin! In this demo you'll be using Livy to create and manage an interactive\n",
    "Spark session. Livy is an open-source REST service that enables remote and interactive\n",
    "analytics on Apache Spark clusters. It provides a way to interact with Spark clusters\n",
    "programmatically using a REST API, allowing you to submit Spark jobs, run interactive\n",
    "queries, and manage Spark sessions.\n",
    "\n",
    "First you need to connect to the Livy endpoint and create a new Spark interactive session.\n",
    "This session will allow you to interact with Spark using your familiar notebook\n",
    "environment, and execute Spark code to perform data processing tasks in an interactive manner.\n",
    "\n",
    "The Spark interactive session is particularly useful for exploratory data analysis,\n",
    "prototyping, and iterative development. It allows you to interactively work with large datasets,\n",
    "perform transformations, apply analytical operations, and build machine learning models using\n",
    "Spark's distributed computing capabilities. This is exactly what you'll do in this Notebook!\n",
    "\n",
    "To communicate with Livy and manage your sessions you'll be using sparkmagic, an open-source\n",
    "tool that provides a Jupyter kernel extension. Sparkmagic integrates with Livy, to provide\n",
    "the underlying communication layer between the Jupyter kernel and the Spark cluster.\n",
    "\n",
    "Execute the cell below and:\n",
    "\n",
    "1. Select `Add Endpoint`\n",
    "1. Select `Basic_Access`, paste your Livy endpoint and authenticate with your credentials\n",
    "1. Select `Create Session`\n",
    "1. Provide a name select `python` and click `Create Session`\n",
    "\n",
    "When your session is ready the `Manage Sessions` pane will become active, providing you the session ID.\n",
    "The session state will become `idle` which means that you are good to go!\n",
    "\n",
    "> To configure Sparkmagic, you can make use of a config.json file located at ~/.sparkmagic/config.json.\n",
    "> If you're running this notebook in a server that was created using the jupyter-data-science image,\n",
    "> the default settings should suffice, and no additional configuration is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c97a7-e2d6-40e0-8977-9725706523cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext sparkmagic.magics\n",
    "%manage_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cfae83-2d9a-40b8-9df3-f7296162dfd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "You are now prepared to embark on your first interaction with Livy.\n",
    "Whenever you initiate a cell with the `%%spark` magic command, the code within\n",
    "that cell will not be executed by your IPython kernel. Instead, it will be executed\n",
    "within a Spark context managed by Livy. Rest assured, Livy will handle everything\n",
    "seamlessly and provide you with a response containing the desired results.\n",
    "\n",
    "Moreover, with Sparkmagic at your side, you can leave the networking part to it. Sparkmagic\n",
    "takes care of all the intricate details, effortlessly creating and sending requests to\n",
    "the Livy server. Finally, it seamlessly renders the response within the Jupyter user interface,\n",
    "ensuring a smooth and hassle-free experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1de280-d9ba-41bf-a864-96f8c06871a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.regression import GBTRegressionModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from py4j.java_gateway import java_import\n",
    "\n",
    "\n",
    "sns.set_style('white')\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f096b2-ef79-4e29-af2d-eda6e067811b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "spark = SparkSession.builder.appName(\"wind-turbine\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca547e-4945-46a0-a2d5-643ba75e480d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "java_import(spark._sc._jvm, \"org.apache.spark.sql.api.python.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f34db-40b1-4910-b1b6-187192163875",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "It's time to load the dataset, which comes in a convenient CSV format.\n",
    "You'll leverage the spark session you created to load it as a DataFrame. Once loaded,\n",
    "you can delve into its contents by examining the first five rows and its schema.\n",
    "Additionally, you'll get an idea of the dataset's size by printing the number of\n",
    "examples available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40616750-6907-48bf-bd6a-ef4b69168e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "spark_df = spark.read.csv('file:///mounts/shared-volume/shared/spark/T1.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d469f5-0387-4516-835f-dc270c1faac4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, you should cache the dataset in memory. The `cache()` method is used to persist\n",
    "or cache the contents of a DataFrame, Dataset, or RDD (Resilient Distributed Dataset)\n",
    "in memory. Caching data in memory can significantly improve the performance of iterative\n",
    "algorithms or repeated computations by avoiding the need to recompute or fetch the data\n",
    "from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382342b-20e1-4bb5-b2d6-7a40544b529b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Caching the dataset\n",
    "spark_df.cache()\n",
    "\n",
    "# Converting all the column names to lower case\n",
    "spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])\n",
    "\n",
    "print('Show the first 5 rows')\n",
    "spark_df.show(5)\n",
    "\n",
    "print('What are the variable data types?')\n",
    "spark_df.printSchema()\n",
    "\n",
    "print('How many observations do we have?')\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc06054-69d9-42db-81f2-4a099e632b2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this experiment, the objective is to predict the power production of a wind turbine\n",
    "(`lv activepower (kw)`) based on the dataset's other features. These features include\n",
    "the current date and hour, the wind speed, and the wind direction. By analyzing the\n",
    "relationships between these variables, you aim to uncover valuable insights and create\n",
    "a predictive model that can estimate the power output of the turbine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e152b-a548-4709-8bff-dea542415b13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "Let's start exploring and transforming the dataset. First step, separate the `date/time`\n",
    "column into two separate columns, one for the month and one for the hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dba19a-5583-425a-8ce1-766713bae8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Extracting a substring from columns to create month and hour variables\n",
    "spark_df = spark_df.withColumn(\"month\", substring(\"date/time\", 4,2))\n",
    "spark_df = spark_df.withColumn(\"hour\", substring(\"date/time\", 12,2))\n",
    "\n",
    "# Converting string month and hour variables to integer\n",
    "spark_df = spark_df.withColumn('month', spark_df.month.cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn('hour', spark_df.hour.cast(IntegerType()))\n",
    "\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae329a-16a6-44fb-8472-7c0eabc85da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Moving forward, let's examine some essential statistical characteristics of our features,\n",
    "specifically the mean and standard deviation. However, it's important to note that these statistics\n",
    "are relevant only for the wind speed, theoretical power curve, and active power variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f99d33-4678-45f5-b8ce-c318c2d5b064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "spark_df.select('wind speed (m/s)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)').toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78378126-c34d-4ffc-9726-f46018664565",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's extract a random sample from the dataset and start creating a visual model.\n",
    "By visualizing the data, we can gain a deeper understanding of its patterns, trends, and relationships.\n",
    "Through this visual exploration, we'll uncover valuable insights that can guide us in our analysis\n",
    "and decision-making processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b67bf-dacf-4aab-bf64-361ecd79f549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Taking a random sample from the big data\n",
    "sample_df = spark_df.sample(withReplacement=False, fraction=0.1, seed=42).toPandas()\n",
    "\n",
    "# Visualizing the distributions with the sample data\n",
    "columns = ['wind speed (m/s)', 'wind direction (deg)', 'month', 'hour', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']\n",
    "i=1\n",
    "plt.figure(figsize=(10, 12))\n",
    "for each in columns:\n",
    "    plt.subplot(3, 2, i)\n",
    "    sample_df[each].plot.hist(bins=12)\n",
    "    plt.title(each)\n",
    "    i += 1\n",
    "    \n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911566e3-6abb-48df-9706-7eac54b62ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "\n",
    "# Compute the average power production by month\n",
    "monthly = spark_df.groupby('month').mean('lv activepower (kw)').sort('avg(lv activepower (kw))').toPandas()\n",
    "sns.barplot(x='month', y='avg(lv activepower (kw))', data=monthly)\n",
    "plt.title('Months and Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d3314-c3b7-4c2a-a81a-d4c00efd4575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "\n",
    "# Compute the average power production by hour\n",
    "hourly = spark_df.groupby('hour').mean('lv activepower (kw)').sort('avg(lv activepower (kw))').toPandas()\n",
    "sns.barplot(x='hour', y='avg(lv activepower (kw))', data=hourly)\n",
    "plt.title('Hours and Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa67c59-a101-4409-9300-c2d810c02c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Compute the correlation between the features of the dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "sample_df[columns].corr()\n",
    "plt.clf()\n",
    "sns.pairplot(sample_df[columns], markers='*');\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d0527-3ff8-4197-9f51-ded9e2a7284c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Finding the average power production for 5 m/s wind speed increments\n",
    "avg_power = []\n",
    "wind_speed = []\n",
    "\n",
    "for i in [0, 5, 10, 15, 20]:\n",
    "    avg_value = spark_df.filter((spark_df['wind speed (m/s)'] > i) \n",
    "                                & (spark_df['wind speed (m/s)'] <= i+5))\\\n",
    "                                .agg({'lv activepower (kw)':'mean'}).collect()[0][0] \n",
    "    avg_power.append(avg_value)\n",
    "    wind_speed.append(str(i) + '-' + str(i+5))\n",
    "\n",
    "plt.clf()\n",
    "sns.barplot(x=wind_speed, y=avg_power, color='orange')\n",
    "plt.title('Avg Power Production for 5 m/s Wind Speed Increments')\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5880755-5a80-4aaa-b53f-7830f1023db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Creating the polar diagram\n",
    "from math import radians\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "# The circle position indicates wind direction\n",
    "# The further from the circle center the higher the wind speed\n",
    "# The circle size indicates active power\n",
    "sns.scatterplot(x=[radians(x) for x in sample_df['wind direction (deg)']], \n",
    "                y=sample_df['wind speed (m/s)'],\n",
    "                size=sample_df['lv activepower (kw)'],\n",
    "                hue=sample_df['lv activepower (kw)'],\n",
    "                alpha=0.7, legend=None)\n",
    "\n",
    "# Setting the polar diagram's top to represent North \n",
    "ax.set_theta_zero_location('N')\n",
    "# Setting -1 to start the wind direction clockwise\n",
    "ax.set_theta_direction(-1)\n",
    "# Setting wind speed labels in a better position to see\n",
    "ax.set_rlabel_position(110)\n",
    "\n",
    "plt.title('Wind Speed - Wind Direction - Power Production Diagram')\n",
    "plt.ylabel(None);\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7626d0-b8c9-4718-8a9a-89031e0a2c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Plot the real power production over the theoritical\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='wind speed (m/s)', y='lv activepower (kw)', color='orange', label='Real Production', alpha=0.5, data=sample_df)\n",
    "sns.lineplot(x='wind speed (m/s)', y='theoretical_power_curve (kwh)', color='blue', label='Theoritical Production', data=sample_df)\n",
    "plt.title('Wind Speed and Power Production Chart')\n",
    "plt.ylabel('Power Production (kw)');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f72f3c-c667-4725-a047-0ca8735607ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Filter the big data where the real and theoritical power productions are equal to 0\n",
    "zero_theo_power = spark_df.filter((spark_df['lv activepower (kw)'] == 0)\n",
    "                                  & (spark_df['theoretical_power_curve (kwh)'] == 0)).toPandas()\n",
    "\n",
    "print(zero_theo_power[['wind speed (m/s)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac3b95-4aaa-4277-bb21-b17875ccd752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "# Examine the wind speed distribution for 0 power production\n",
    "zero_theo_power['wind speed (m/s)'].hist()\n",
    "plt.title('Wind Speed Distribution for 0 Power Production')\n",
    "plt.xlabel('Wind speed (m/s)')\n",
    "plt.ylabel('Counts for 0 Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eeccb6-4ff5-4e45-acda-0fa76fb067d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Observations for the wind speed > 3m/s and power production = 0, \n",
    "# while theoritically there should be power production\n",
    "zero_power = spark_df.filter((spark_df['lv activepower (kw)'] == 0)\n",
    "                            & (spark_df['theoretical_power_curve (kwh)'] != 0)\n",
    "                            & (spark_df['wind speed (m/s)'] > 3)).toPandas()\n",
    "print(zero_power.head())\n",
    "print('No of Observations (while Wind Speed > 3 m/s and Power Production = 0): ', len(zero_power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673591c3-0777-46a4-9329-a0bd7c7033b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "plt.clf()\n",
    "zero_power['wind speed (m/s)'].plot.hist(bins=8)\n",
    "plt.xlabel('Wind Speed (m/s)')\n",
    "plt.ylabel('Counts for Zero Production')\n",
    "plt.title('Wind Speed Counts for Zero Power Production')\n",
    "plt.xticks(ticks=np.arange(4,18,2));\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74434df-c123-4c04-9c4c-882bd7a790c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# The number of the examples that show a 0 power production\n",
    "# while theoritically there should be power production\n",
    "print(\"The number of the examples that show a 0 power production\"\n",
    "      \" while theoritically there should be power production:\", zero_power['month'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a596bd6-aac0-4e5d-adb7-a2d586e1db40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Excluding the observations meeting the filter criterias \n",
    "spark_df = spark_df.filter(~((spark_df['lv activepower (kw)'] == 0)\n",
    "                            & (spark_df['theoretical_power_curve (kwh)'] != 0)\n",
    "                            & (spark_df['wind speed (m/s)'] > 3)))\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2d2af-94d7-4c7d-ba84-7188cf94e42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "columns = ['wind speed (m/s)', 'wind direction (deg)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']\n",
    "i=1\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20, 5))\n",
    "for each in columns:\n",
    "    df = spark_df.select(each).toPandas()\n",
    "    plt.subplot(1, 4, i)\n",
    "    #plt.boxplot(df)\n",
    "    sns.boxplot(x=df[each])\n",
    "    # plt.title(each)\n",
    "    i += 1\n",
    "    \n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd46aa-9e6c-4b4d-b917-84cf81428b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Let's find and exclude possible outliers.\n",
    "# Create a pandas df for visualization\n",
    "wind_speed = spark_df.select('wind speed (m/s)').toPandas()\n",
    "\n",
    "# Defining the quantiles and interquantile range\n",
    "Q1 = wind_speed['wind speed (m/s)'].quantile(0.25)\n",
    "Q3 = wind_speed['wind speed (m/s)'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "# Defining the lower and upper threshold values\n",
    "lower = Q1 - 1.5*IQR\n",
    "upper = Q3 + 1.5*IQR\n",
    "\n",
    "print('Quantile (0.25): ', Q1, '  Quantile (0.75): ', Q3)\n",
    "print('Lower threshold: ', lower, ' Upper threshold: ', upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc873f-cb57-43a5-9f4b-97cfb1fe37d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "# Fancy indexing for outliers\n",
    "outlier_tf = (wind_speed['wind speed (m/s)'] < lower) | (wind_speed['wind speed (m/s)'] > upper)\n",
    "\n",
    "print('Total Number of Outliers: ', len(wind_speed['wind speed (m/s)'][outlier_tf]))\n",
    "print('--'*15)\n",
    "print('Some Examples of Outliers:')\n",
    "print(wind_speed['wind speed (m/s)'][outlier_tf].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59088229-0fa5-4cd6-92b8-28fd9e570754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "(spark_df.select('wind speed (m/s)', 'lv activepower (kw)')\n",
    "         .filter(spark_df['wind speed (m/s)'] >= 19)\n",
    "         .agg({'lv activepower (kw)':'mean'}).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad694feb-9bd4-4d14-b8eb-6445801afd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "from pyspark.sql import functions as F\n",
    "spark_df = spark_df.withColumn('wind speed (m/s)', \n",
    "                               F.when(F.col('wind speed (m/s)') > 19.447, 19)\n",
    "                               .otherwise(F.col('wind speed (m/s)')))\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286a981-17f6-44d7-a0eb-a4ccf3c51cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# High level power production\n",
    "spark_df.filter(((spark_df['month'] == 3) | (spark_df['month'] == 8) | (spark_df['month'] == 11)) \n",
    "                & ((spark_df['hour'] >= 16) | (spark_df['hour'] <= 24)) \n",
    "                & ((spark_df['wind direction (deg)'] > 0) | (spark_df['wind direction (deg)'] < 90))\n",
    "                & ((spark_df['wind direction (deg)'] > 180) | (spark_df['wind direction (deg)'] < 225))\n",
    "               ).agg({'lv activepower (kw)':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995200ac-6701-4fef-ad1c-2029d4c2d67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Low level power production\n",
    "spark_df.filter((spark_df['month'] == 7) \n",
    "                & ((spark_df['hour'] >= 9) | (spark_df['hour'] <= 11)) \n",
    "                & ((spark_df['wind direction (deg)'] > 90) | (spark_df['wind direction (deg)'] < 160))\n",
    "               ).agg({'lv activepower (kw)':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a81598-293f-44c0-92f1-544efa52b1bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training a GBT Regressor\n",
    "\n",
    "You are now ready to train our GBT regresson. To begin, you'll carefully specify\n",
    "the features and the label for our model. Then, we'll split the dataset into training\n",
    "and test subsets to ensure robust evaluation of our model's performance.\n",
    "Finally, we'll initiate the training process, allowing our GBT regressor to learn\n",
    "from the training data and make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487057c-6032-41ec-b2e4-fe28dd297bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Converting lv activepower (kw) variable as label\n",
    "spark_df = spark_df.withColumn('label', spark_df['lv activepower (kw)'])\n",
    "\n",
    "# Preparing the independent variables (Features) and fefining the variables to be used\n",
    "variables = ['month', 'hour', 'wind speed (m/s)', 'wind direction (deg)']\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "va_df = vectorAssembler.transform(spark_df)\n",
    "\n",
    "# Combining features and label column\n",
    "final_df = va_df.select('features', 'label')\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02140c44-46ce-4ad0-9481-33c6b1b6230b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Split the dataset:\n",
    "# 80% for training\n",
    "# 20% for testing\n",
    "splits = final_df.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "print('Train dataset: ', train_df.count())\n",
    "print('Test dataset : ', test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330b4e2-f27c-4cce-9027-65c7ed80f4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Creating the gbm regressor object\n",
    "gbm = GBTRegressor(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Training the model with train data\n",
    "gbm_model = gbm.fit(train_df)\n",
    "\n",
    "# Predicting using the test data\n",
    "y_pred = gbm_model.transform(test_df)\n",
    "\n",
    "# Initial look at the target and predicted values\n",
    "y_pred.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0b106-149e-43a3-95a2-f868b4fde8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "gbm_model.write().overwrite().save(\"file:///mounts/shared-volume/user/spark/GBM.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac402d0-e52c-4cda-8a6a-32a218154316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "gbm_model_dtap = GBTRegressionModel.load(\"file:///mounts/shared-volume/user/spark/GBM.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bd4cd-74b0-40f7-a239-759e766cc925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Initial model success\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "print('R2:\\t', evaluator.evaluate(y_pred, {evaluator.metricName: 'r2'}))\n",
    "print('MAE:\\t', evaluator.evaluate(y_pred, {evaluator.metricName: 'mae'}))\n",
    "print('RMSE:\\t', evaluator.evaluate(y_pred, {evaluator.metricName: 'rmse'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4aa810-6839-4240-937e-c353a3719a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Converting sample_df back to Spark dataframe\n",
    "eva_df = spark.createDataFrame(sample_df)\n",
    "\n",
    "# Converting lv activepower (kw) variable as label\n",
    "eva_df = eva_df.withColumn('label', eva_df['lv activepower (kw)'])\n",
    "\n",
    "# Defining the variables to be used\n",
    "variables = ['month', 'hour', 'wind speed (m/s)', 'wind direction (deg)']\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "vec_df = vectorAssembler.transform(eva_df)\n",
    "\n",
    "# Combining features and label column\n",
    "vec_df = vec_df.select('features', 'label')\n",
    "\n",
    "# Using ML model to predict\n",
    "preds = gbm_model.transform(vec_df)\n",
    "preds_df = preds.select('label','prediction').toPandas()\n",
    "\n",
    "# Compining dataframes to compare\n",
    "frames = [sample_df[['wind speed (m/s)', 'theoretical_power_curve (kwh)']], preds_df]\n",
    "sample_data = pd.concat(frames, axis=1)\n",
    "\n",
    "plt.clf()\n",
    "# Visualizing real, theoritical and predicted power production\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x='wind speed (m/s)', y='label',alpha=0.5, label= 'Real Power', data=sample_data)\n",
    "sns.scatterplot(x='wind speed (m/s)', y='prediction', alpha=0.7, label='Predicted Power', marker='o', data=sample_data)\n",
    "sns.lineplot(x='wind speed (m/s)', y='theoretical_power_curve (kwh)', label='Theoritical Power',color='purple', data=sample_data)\n",
    "plt.title('Wind Turbine Power Production Prediction')\n",
    "plt.ylabel('Power Production (kw)')\n",
    "plt.legend();\n",
    "\n",
    "%matplot plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
